{"cells":[{"cell_type":"code","execution_count":64,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4116,"status":"ok","timestamp":1687891804545,"user":{"displayName":"Milad Mahaki","userId":"06106732680968882418"},"user_tz":-210},"id":"ky78QJ-u_r-L","outputId":"cc11f3bc-811f-4b3f-ee2a-d80473746d2a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","execution_count":65,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1687891805849,"user":{"displayName":"Milad Mahaki","userId":"06106732680968882418"},"user_tz":-210},"id":"qhecyK14zfeW","outputId":"b63f3422-7e3f-4f15-e4ef-33b2f8be6a15"},"outputs":[{"name":"stdout","output_type":"stream","text":["[Errno 2] No such file or directory: 'gdrive/MyDrive/'\n","/content/gdrive/MyDrive/lightweighted-cnn/train/output\n"]}],"source":["cd gdrive/MyDrive/"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1687888515969,"user":{"displayName":"Milad Mahaki","userId":"06106732680968882418"},"user_tz":-210},"id":"scTKH4_j-Vsq","outputId":"4cc496e7-6503-4853-de1d-f08a4a93199c"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/gdrive/MyDrive/lightweighted-cnn\n"]}],"source":["cd ../"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11955,"status":"ok","timestamp":1687888561631,"user":{"displayName":"Milad Mahaki","userId":"06106732680968882418"},"user_tz":-210},"id":"yV8qFpgBybjX","outputId":"ea3a5efb-a362-4c56-aac5-2d71461e9d47"},"outputs":[{"name":"stdout","output_type":"stream","text":["Updating files: 100% (974/974), done.\n","HEAD is now at 4b96eae add gitignore\n","From https://github.com/happyb321d/lightweighted-cnn\n"," * branch            HEAD       -> FETCH_HEAD\n","Updating 4b96eae..9d04b47\n","Fast-forward\n"," .gitignore                   |  1 \u001b[32m+\u001b[m\n"," train/helper/data_helpers.py | 12 \u001b[32m++++++\u001b[m\u001b[31m------\u001b[m\n"," 2 files changed, 7 insertions(+), 6 deletions(-)\n"]}],"source":["!git reset --hard\n","!git pull https://github.com/happyb321d/lightweighted-cnn\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2800,"status":"ok","timestamp":1687888620803,"user":{"displayName":"Milad Mahaki","userId":"06106732680968882418"},"user_tz":-210},"id":"O7zjPm87A3Je","outputId":"a15051ff-1eea-4ff4-97dc-667e1300acf9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","python3.6 is already the newest version (3.6.15-1+focal3).\n","0 upgraded, 0 newly installed, 0 to remove and 13 not upgraded.\n"]}],"source":["!apt-get install python3.6\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1542,"status":"ok","timestamp":1687888625069,"user":{"displayName":"Milad Mahaki","userId":"06106732680968882418"},"user_tz":-210},"id":"ONhdtbYLCp7d","outputId":"9a8ba0a8-2f68-4f8b-f2d7-1eaab24571c5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","python3.6-distutils is already the newest version (3.6.15-1+focal3).\n","0 upgraded, 0 newly installed, 0 to remove and 13 not upgraded.\n"]}],"source":["!sudo apt-get install python3.6-distutils"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":597,"status":"ok","timestamp":1687888632968,"user":{"displayName":"Milad Mahaki","userId":"06106732680968882418"},"user_tz":-210},"id":"gpKisFFrG7v8","outputId":"7a7a9488-3c27-4840-ef08-fcabfa41c250"},"outputs":[{"name":"stdout","output_type":"stream","text":["  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100 2108k  100 2108k    0     0  22.6M      0 --:--:-- --:--:-- --:--:-- 22.8M\n"]}],"source":["!curl https://bootstrap.pypa.io/pip/3.6/get-pip.py -o get-pip.py\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4870,"status":"ok","timestamp":1687888638567,"user":{"displayName":"Milad Mahaki","userId":"06106732680968882418"},"user_tz":-210},"id":"Uk00mHWkHFyz","outputId":"cafe7faf-2577-4b78-ef1a-d858d0b99c5d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting pip<22.0\n","  Using cached pip-21.3.1-py3-none-any.whl (1.7 MB)\n","Installing collected packages: pip\n","  Attempting uninstall: pip\n","    Found existing installation: pip 21.3.1\n","    Uninstalling pip-21.3.1:\n","      Successfully uninstalled pip-21.3.1\n","Successfully installed pip-21.3.1\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"]}],"source":["!python3.6 get-pip.py"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":861,"status":"ok","timestamp":1687888639417,"user":{"displayName":"Milad Mahaki","userId":"06106732680968882418"},"user_tz":-210},"id":"G1XZuJcHJpOf","outputId":"ec7ed470-0ddf-4301-e8ba-49664e8ca73a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: tensorflow==1.14.0 in /usr/local/lib/python3.6/dist-packages (1.14.0)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.48.2)\n","Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.2.0)\n","Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (3.19.6)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.1.2)\n","Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.5.4)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.1.0)\n","Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.14.0)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.37.1)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.15.0)\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.4.0)\n","Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.0.8)\n","Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.19.5)\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.8.1)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.16.0)\n","Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.14.0)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14.0) (3.1.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.3.7)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (59.6.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (2.0.3)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (4.8.3)\n","Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from werkzeug>=0.11.15->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (0.8)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.6/dist-packages (from h5py->keras-applications>=1.0.6->tensorflow==1.14.0) (1.5.2)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (4.1.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.6.0)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"]}],"source":["!pip3.6 install tensorflow==1.14.0"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":668,"status":"ok","timestamp":1687888642599,"user":{"displayName":"Milad Mahaki","userId":"06106732680968882418"},"user_tz":-210},"id":"f7XlgaFqKHvc","outputId":"e5950893-8a1a-4c70-cd4a-6efaa8875eb6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (0.24.2)\n","Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.19.5)\n","Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.5.4)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (3.1.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.1.1)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"]}],"source":["!pip3.6 install scikit-learn"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!pip3.6 install keras"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lkG0X-7vKxee"},"outputs":[],"source":["import tensorflow.compat.v1 as tf\n","tf.disable_v2_behavior()\n","# print(tf.__version__)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"CeC0PpNiNvdv","outputId":"7fc8866a-2525-4e29-f46f-e00f560c9d84"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting pyyaml\n","  Downloading PyYAML-6.0-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (603 kB)\n","\u001b[?25l\r\r     |▌                               | 10 kB 26.1 MB/s eta 0:00:01\r     |█                               | 20 kB 19.8 MB/s eta 0:00:01\r     |█▋                              | 30 kB 26.0 MB/s eta 0:00:01\r     |██▏                             | 40 kB 13.6 MB/s eta 0:00:01\r     |██▊                             | 51 kB 16.1 MB/s eta 0:00:01\r     |███▎                            | 61 kB 18.6 MB/s eta 0:00:01\r     |███▉                            | 71 kB 15.0 MB/s eta 0:00:01\r     |████▍                           | 81 kB 16.6 MB/s eta 0:00:01\r     |████▉                           | 92 kB 16.8 MB/s eta 0:00:01\r     |█████▍                          | 102 kB 17.3 MB/s eta 0:00:01\r     |██████                          | 112 kB 17.3 MB/s eta 0:00:01\r     |██████▌                         | 122 kB 17.3 MB/s eta 0:00:01\r     |███████                         | 133 kB 17.3 MB/s eta 0:00:01\r     |███████▋                        | 143 kB 17.3 MB/s eta 0:00:01\r     |████████▏                       | 153 kB 17.3 MB/s eta 0:00:01\r     |████████▊                       | 163 kB 17.3 MB/s eta 0:00:01\r     |█████████▎                      | 174 kB 17.3 MB/s eta 0:00:01\r     |█████████▊                      | 184 kB 17.3 MB/s eta 0:00:01\r     |██████████▎                     | 194 kB 17.3 MB/s eta 0:00:01\r     |██████████▉                     | 204 kB 17.3 MB/s eta 0:00:01\r     |███████████▍                    | 215 kB 17.3 MB/s eta 0:00:01\r     |████████████                    | 225 kB 17.3 MB/s eta 0:00:01\r     |████████████▌                   | 235 kB 17.3 MB/s eta 0:00:01\r     |█████████████                   | 245 kB 17.3 MB/s eta 0:00:01\r     |█████████████▋                  | 256 kB 17.3 MB/s eta 0:00:01\r     |██████████████                  | 266 kB 17.3 MB/s eta 0:00:01\r     |██████████████▋                 | 276 kB 17.3 MB/s eta 0:00:01\r     |███████████████▏                | 286 kB 17.3 MB/s eta 0:00:01\r     |███████████████▊                | 296 kB 17.3 MB/s eta 0:00:01\r     |████████████████▎               | 307 kB 17.3 MB/s eta 0:00:01\r     |████████████████▉               | 317 kB 17.3 MB/s eta 0:00:01\r     |█████████████████▍              | 327 kB 17.3 MB/s eta 0:00:01\r     |██████████████████              | 337 kB 17.3 MB/s eta 0:00:01\r     |██████████████████▌             | 348 kB 17.3 MB/s eta 0:00:01\r     |███████████████████             | 358 kB 17.3 MB/s eta 0:00:01\r     |███████████████████▌            | 368 kB 17.3 MB/s eta 0:00:01\r     |████████████████████            | 378 kB 17.3 MB/s eta 0:00:01\r     |████████████████████▋           | 389 kB 17.3 MB/s eta 0:00:01\r     |█████████████████████▏          | 399 kB 17.3 MB/s eta 0:00:01\r     |█████████████████████▊          | 409 kB 17.3 MB/s eta 0:00:01\r     |██████████████████████▎         | 419 kB 17.3 MB/s eta 0:00:01\r     |██████████████████████▉         | 430 kB 17.3 MB/s eta 0:00:01\r     |███████████████████████▎        | 440 kB 17.3 MB/s eta 0:00:01\r     |███████████████████████▉        | 450 kB 17.3 MB/s eta 0:00:01\r     |████████████████████████▍       | 460 kB 17.3 MB/s eta 0:00:01\r     |█████████████████████████       | 471 kB 17.3 MB/s eta 0:00:01\r     |█████████████████████████▌      | 481 kB 17.3 MB/s eta 0:00:01\r     |██████████████████████████      | 491 kB 17.3 MB/s eta 0:00:01\r     |██████████████████████████▋     | 501 kB 17.3 MB/s eta 0:00:01\r     |███████████████████████████▏    | 512 kB 17.3 MB/s eta 0:00:01\r     |███████████████████████████▊    | 522 kB 17.3 MB/s eta 0:00:01\r     |████████████████████████████▏   | 532 kB 17.3 MB/s eta 0:00:01\r     |████████████████████████████▊   | 542 kB 17.3 MB/s eta 0:00:01\r     |█████████████████████████████▎  | 552 kB 17.3 MB/s eta 0:00:01\r     |█████████████████████████████▉  | 563 kB 17.3 MB/s eta 0:00:01\r     |██████████████████████████████▍ | 573 kB 17.3 MB/s eta 0:00:01\r     |███████████████████████████████ | 583 kB 17.3 MB/s eta 0:00:01\r     |███████████████████████████████▌| 593 kB 17.3 MB/s eta 0:00:01\r     |████████████████████████████████| 603 kB 17.3 MB/s            \n","\u001b[?25hInstalling collected packages: pyyaml\n","Successfully installed pyyaml-6.0\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"]}],"source":["!pip3.6 install pyyaml"]},{"cell_type":"code","execution_count":66,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1687891816384,"user":{"displayName":"Milad Mahaki","userId":"06106732680968882418"},"user_tz":-210},"id":"2rw0iYdU1ZyQ","outputId":"0a8c6efc-204c-44c8-f967-c9bcc8a15abb"},"outputs":[{"name":"stdout","output_type":"stream","text":["[Errno 2] No such file or directory: 'train'\n","/content/gdrive/MyDrive/lightweighted-cnn/train/output\n"]}],"source":["cd train"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":990477,"status":"ok","timestamp":1687889641143,"user":{"displayName":"Milad Mahaki","userId":"06106732680968882418"},"user_tz":-210},"id":"ribTiwheKJNe","outputId":"5b0d1541-28ef-4105-bf3d-d5803649ccd4"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n","2023-06-27T18:00:49.027624: step 1122, loss 0.340561, acc 0.9375, learning_rate 0.00190639\n","2023-06-27T18:00:49.208928: step 1123, loss 0.140786, acc 0.9375, learning_rate 0.00190515\n","2023-06-27T18:00:49.398451: step 1124, loss 0.180548, acc 0.90625, learning_rate 0.00190391\n","2023-06-27T18:00:49.594075: step 1125, loss 0.287182, acc 0.90625, learning_rate 0.00190268\n","2023-06-27T18:00:49.761024: step 1126, loss 0.235218, acc 0.9375, learning_rate 0.00190144\n","2023-06-27T18:00:49.984621: step 1127, loss 0.402662, acc 0.84375, learning_rate 0.0019002\n","2023-06-27T18:00:50.205329: step 1128, loss 0.391083, acc 0.84375, learning_rate 0.00189897\n","2023-06-27T18:00:50.406111: step 1129, loss 0.253107, acc 0.875, learning_rate 0.00189774\n","2023-06-27T18:00:50.598913: step 1130, loss 0.560943, acc 0.8125, learning_rate 0.0018965\n","2023-06-27T18:00:50.776795: step 1131, loss 0.396001, acc 0.84375, learning_rate 0.00189527\n","2023-06-27T18:00:50.957615: step 1132, loss 0.313284, acc 0.875, learning_rate 0.00189404\n","2023-06-27T18:00:51.082368: step 1133, loss 0.212892, acc 0.875, learning_rate 0.00189281\n","2023-06-27T18:00:51.197260: step 1134, loss 0.45352, acc 0.8125, learning_rate 0.00189158\n","2023-06-27T18:00:51.307249: step 1135, loss 0.527631, acc 0.75, learning_rate 0.00189035\n","2023-06-27T18:00:51.419565: step 1136, loss 0.408804, acc 0.84375, learning_rate 0.00188913\n","2023-06-27T18:00:51.538276: step 1137, loss 0.370364, acc 0.875, learning_rate 0.0018879\n","2023-06-27T18:00:51.664112: step 1138, loss 0.500249, acc 0.6875, learning_rate 0.00188667\n","2023-06-27T18:00:51.783847: step 1139, loss 0.340445, acc 0.8125, learning_rate 0.00188545\n","2023-06-27T18:00:51.903931: step 1140, loss 0.56867, acc 0.71875, learning_rate 0.00188422\n","2023-06-27T18:00:52.029884: step 1141, loss 0.382585, acc 0.90625, learning_rate 0.001883\n","2023-06-27T18:00:52.142848: step 1142, loss 0.410664, acc 0.875, learning_rate 0.00188178\n","2023-06-27T18:00:52.267785: step 1143, loss 0.464909, acc 0.8125, learning_rate 0.00188055\n","2023-06-27T18:00:52.387225: step 1144, loss 0.503975, acc 0.875, learning_rate 0.00187933\n","2023-06-27T18:00:52.500207: step 1145, loss 0.397223, acc 0.84375, learning_rate 0.00187811\n","2023-06-27T18:00:52.615784: step 1146, loss 0.27365, acc 0.90625, learning_rate 0.00187689\n","2023-06-27T18:00:52.737710: step 1147, loss 0.312855, acc 0.875, learning_rate 0.00187568\n","2023-06-27T18:00:52.856303: step 1148, loss 0.319985, acc 0.8125, learning_rate 0.00187446\n","2023-06-27T18:00:52.974114: step 1149, loss 0.333804, acc 0.90625, learning_rate 0.00187324\n","2023-06-27T18:00:53.096820: step 1150, loss 0.437986, acc 0.75, learning_rate 0.00187203\n","2023-06-27T18:00:53.208092: step 1151, loss 0.422067, acc 0.875, learning_rate 0.00187081\n","2023-06-27T18:00:53.328303: step 1152, loss 0.31549, acc 0.875, learning_rate 0.0018696\n","2023-06-27T18:00:53.450247: step 1153, loss 0.49341, acc 0.78125, learning_rate 0.00186838\n","2023-06-27T18:00:53.567881: step 1154, loss 0.364798, acc 0.78125, learning_rate 0.00186717\n","2023-06-27T18:00:53.676543: step 1155, loss 0.311814, acc 0.875, learning_rate 0.00186596\n","2023-06-27T18:00:53.792022: step 1156, loss 0.200352, acc 0.90625, learning_rate 0.00186475\n","2023-06-27T18:00:53.908583: step 1157, loss 0.558446, acc 0.8125, learning_rate 0.00186354\n","2023-06-27T18:00:54.026474: step 1158, loss 0.456218, acc 0.78125, learning_rate 0.00186233\n","2023-06-27T18:00:54.152041: step 1159, loss 0.313527, acc 0.875, learning_rate 0.00186112\n","2023-06-27T18:00:54.268712: step 1160, loss 0.336683, acc 0.84375, learning_rate 0.00185991\n","2023-06-27T18:00:54.387176: step 1161, loss 0.329147, acc 0.875, learning_rate 0.00185871\n","2023-06-27T18:00:54.503965: step 1162, loss 0.864365, acc 0.71875, learning_rate 0.0018575\n","2023-06-27T18:00:54.624794: step 1163, loss 0.375569, acc 0.90625, learning_rate 0.00185629\n","2023-06-27T18:00:54.746346: step 1164, loss 0.306452, acc 0.90625, learning_rate 0.00185509\n","2023-06-27T18:00:54.861705: step 1165, loss 0.219276, acc 0.90625, learning_rate 0.00185389\n","2023-06-27T18:00:54.975133: step 1166, loss 0.177526, acc 0.9375, learning_rate 0.00185268\n","2023-06-27T18:00:55.090702: step 1167, loss 0.00742812, acc 1, learning_rate 0.00185148\n","2023-06-27T18:00:55.215361: step 1168, loss 0.21803, acc 0.9375, learning_rate 0.00185028\n","2023-06-27T18:00:55.337677: step 1169, loss 0.449235, acc 0.8125, learning_rate 0.00184908\n","2023-06-27T18:00:55.462082: step 1170, loss 0.0723384, acc 1, learning_rate 0.00184788\n","2023-06-27T18:00:55.580480: step 1171, loss 0.122753, acc 0.96875, learning_rate 0.00184668\n","2023-06-27T18:00:55.694374: step 1172, loss 0.154045, acc 0.96875, learning_rate 0.00184548\n","2023-06-27T18:00:55.812326: step 1173, loss 0.326931, acc 0.84375, learning_rate 0.00184429\n","2023-06-27T18:00:55.940344: step 1174, loss 0.122891, acc 1, learning_rate 0.00184309\n","2023-06-27T18:00:56.056560: step 1175, loss 0.140764, acc 0.9375, learning_rate 0.0018419\n","2023-06-27T18:00:56.187744: step 1176, loss 0.126031, acc 1, learning_rate 0.0018407\n","2023-06-27T18:00:56.304984: step 1177, loss 0.160123, acc 0.96875, learning_rate 0.00183951\n","2023-06-27T18:00:56.423173: step 1178, loss 0.38039, acc 0.875, learning_rate 0.00183832\n","2023-06-27T18:00:56.533545: step 1179, loss 0.226268, acc 0.90625, learning_rate 0.00183712\n","2023-06-27T18:00:56.657595: step 1180, loss 0.194891, acc 0.9375, learning_rate 0.00183593\n","2023-06-27T18:00:56.788359: step 1181, loss 0.153831, acc 0.9375, learning_rate 0.00183474\n","2023-06-27T18:00:56.899256: step 1182, loss 0.257361, acc 0.875, learning_rate 0.00183355\n","2023-06-27T18:00:57.029624: step 1183, loss 0.21364, acc 0.90625, learning_rate 0.00183236\n","2023-06-27T18:00:57.154530: step 1184, loss 0.18873, acc 0.90625, learning_rate 0.00183118\n","2023-06-27T18:00:57.272985: step 1185, loss 0.244699, acc 0.875, learning_rate 0.00182999\n","2023-06-27T18:00:57.388925: step 1186, loss 0.181658, acc 0.90625, learning_rate 0.0018288\n","2023-06-27T18:00:57.503135: step 1187, loss 0.170552, acc 0.90625, learning_rate 0.00182762\n","2023-06-27T18:00:57.620572: step 1188, loss 0.265132, acc 0.90625, learning_rate 0.00182643\n","2023-06-27T18:00:57.745474: step 1189, loss 0.225655, acc 0.90625, learning_rate 0.00182525\n","2023-06-27T18:00:57.857653: step 1190, loss 0.143233, acc 0.96875, learning_rate 0.00182407\n","2023-06-27T18:00:57.968369: step 1191, loss 0.249991, acc 0.84375, learning_rate 0.00182288\n","2023-06-27T18:00:58.079773: step 1192, loss 0.440915, acc 0.90625, learning_rate 0.0018217\n","2023-06-27T18:00:58.194922: step 1193, loss 0.154444, acc 0.96875, learning_rate 0.00182052\n","2023-06-27T18:00:58.313645: step 1194, loss 0.366992, acc 0.8125, learning_rate 0.00181934\n","2023-06-27T18:00:58.440566: step 1195, loss 0.292283, acc 0.875, learning_rate 0.00181816\n","2023-06-27T18:00:58.575794: step 1196, loss 0.101103, acc 1, learning_rate 0.00181698\n","2023-06-27T18:00:58.699358: step 1197, loss 0.237305, acc 0.9375, learning_rate 0.00181581\n","2023-06-27T18:00:58.821933: step 1198, loss 0.100013, acc 1, learning_rate 0.00181463\n","2023-06-27T18:00:58.941848: step 1199, loss 0.286103, acc 0.90625, learning_rate 0.00181345\n","\n","Evaluation:\n","2023-06-27T18:00:59.706529: step 1200, loss 0.532801, acc 0.79524\n","\n","Saved model checkpoint to /content/gdrive/MyDrive/lightweighted-cnn/train/runs/1687888658/checkpoints/model-1200\n","\n","2023-06-27T18:00:59.923832: step 1200, loss 0.371999, acc 0.84375, learning_rate 0.00181228\n","2023-06-27T18:01:00.053344: step 1201, loss 0.134578, acc 0.96875, learning_rate 0.00181111\n","2023-06-27T18:01:00.174616: step 1202, loss 0.279396, acc 0.875, learning_rate 0.00180993\n","2023-06-27T18:01:00.300094: step 1203, loss 0.270553, acc 0.84375, learning_rate 0.00180876\n","2023-06-27T18:01:00.420599: step 1204, loss 0.290903, acc 0.90625, learning_rate 0.00180759\n","2023-06-27T18:01:00.548468: step 1205, loss 0.280841, acc 0.90625, learning_rate 0.00180642\n","2023-06-27T18:01:00.668904: step 1206, loss 0.304358, acc 0.90625, learning_rate 0.00180525\n","2023-06-27T18:01:00.787560: step 1207, loss 0.187956, acc 0.9375, learning_rate 0.00180408\n","2023-06-27T18:01:00.906291: step 1208, loss 0.14466, acc 1, learning_rate 0.00180291\n","2023-06-27T18:01:01.079112: step 1209, loss 0.247142, acc 0.9375, learning_rate 0.00180174\n","2023-06-27T18:01:01.266662: step 1210, loss 0.118751, acc 0.96875, learning_rate 0.00180057\n","2023-06-27T18:01:01.464137: step 1211, loss 0.316488, acc 0.84375, learning_rate 0.00179941\n","2023-06-27T18:01:01.671165: step 1212, loss 0.1964, acc 0.9375, learning_rate 0.00179824\n","2023-06-27T18:01:01.870781: step 1213, loss 0.314542, acc 0.875, learning_rate 0.00179708\n","2023-06-27T18:01:02.073528: step 1214, loss 0.202992, acc 0.90625, learning_rate 0.00179591\n","2023-06-27T18:01:02.279254: step 1215, loss 0.281628, acc 0.8125, learning_rate 0.00179475\n","2023-06-27T18:01:02.474274: step 1216, loss 0.234176, acc 0.875, learning_rate 0.00179359\n","2023-06-27T18:01:02.674471: step 1217, loss 0.435202, acc 0.84375, learning_rate 0.00179243\n","2023-06-27T18:01:02.863591: step 1218, loss 0.215827, acc 0.875, learning_rate 0.00179127\n","2023-06-27T18:01:03.059875: step 1219, loss 0.15718, acc 0.9375, learning_rate 0.00179011\n","2023-06-27T18:01:03.250418: step 1220, loss 0.212868, acc 0.90625, learning_rate 0.00178895\n","2023-06-27T18:01:03.444072: step 1221, loss 0.256672, acc 0.875, learning_rate 0.00178779\n","2023-06-27T18:01:03.658943: step 1222, loss 0.164381, acc 0.90625, learning_rate 0.00178663\n","2023-06-27T18:01:03.863002: step 1223, loss 0.449535, acc 0.8125, learning_rate 0.00178548\n","2023-06-27T18:01:04.083019: step 1224, loss 0.30755, acc 0.875, learning_rate 0.00178432\n","2023-06-27T18:01:04.293413: step 1225, loss 0.186743, acc 0.9375, learning_rate 0.00178317\n","2023-06-27T18:01:04.495059: step 1226, loss 0.25095, acc 0.9375, learning_rate 0.00178201\n","2023-06-27T18:01:04.697697: step 1227, loss 0.244194, acc 0.90625, learning_rate 0.00178086\n","2023-06-27T18:01:04.885884: step 1228, loss 0.130994, acc 0.96875, learning_rate 0.00177971\n","2023-06-27T18:01:05.127825: step 1229, loss 0.318334, acc 0.875, learning_rate 0.00177855\n","2023-06-27T18:01:05.335633: step 1230, loss 0.386961, acc 0.84375, learning_rate 0.0017774\n","2023-06-27T18:01:05.542142: step 1231, loss 0.128781, acc 0.9375, learning_rate 0.00177625\n","2023-06-27T18:01:05.730230: step 1232, loss 0.118392, acc 0.96875, learning_rate 0.0017751\n","2023-06-27T18:01:05.923303: step 1233, loss 0.196056, acc 0.90625, learning_rate 0.00177395\n","2023-06-27T18:01:06.118178: step 1234, loss 0.125501, acc 1, learning_rate 0.00177281\n","2023-06-27T18:01:06.306666: step 1235, loss 0.181827, acc 0.9375, learning_rate 0.00177166\n","2023-06-27T18:01:06.496567: step 1236, loss 0.118389, acc 0.96875, learning_rate 0.00177051\n","2023-06-27T18:01:06.699966: step 1237, loss 0.355842, acc 0.8125, learning_rate 0.00176937\n","2023-06-27T18:01:06.892760: step 1238, loss 0.209464, acc 0.875, learning_rate 0.00176822\n","2023-06-27T18:01:07.086054: step 1239, loss 0.151843, acc 0.96875, learning_rate 0.00176708\n","2023-06-27T18:01:07.274894: step 1240, loss 0.224873, acc 0.90625, learning_rate 0.00176594\n","2023-06-27T18:01:07.457743: step 1241, loss 0.191545, acc 0.9375, learning_rate 0.00176479\n","2023-06-27T18:01:07.648330: step 1242, loss 0.377186, acc 0.875, learning_rate 0.00176365\n","2023-06-27T18:01:07.831750: step 1243, loss 0.452482, acc 0.875, learning_rate 0.00176251\n","2023-06-27T18:01:08.025497: step 1244, loss 0.329077, acc 0.9375, learning_rate 0.00176137\n","2023-06-27T18:01:08.206886: step 1245, loss 0.223121, acc 0.9375, learning_rate 0.00176023\n","2023-06-27T18:01:08.419240: step 1246, loss 0.207446, acc 0.90625, learning_rate 0.00175909\n","2023-06-27T18:01:08.609792: step 1247, loss 0.390267, acc 0.875, learning_rate 0.00175796\n","2023-06-27T18:01:08.801660: step 1248, loss 0.124488, acc 0.9375, learning_rate 0.00175682\n","2023-06-27T18:01:08.990021: step 1249, loss 0.0829558, acc 1, learning_rate 0.00175568\n","2023-06-27T18:01:09.181145: step 1250, loss 0.216018, acc 0.9375, learning_rate 0.00175455\n","2023-06-27T18:01:09.359460: step 1251, loss 0.292647, acc 0.84375, learning_rate 0.00175341\n","2023-06-27T18:01:09.529030: step 1252, loss 0.328815, acc 0.875, learning_rate 0.00175228\n","2023-06-27T18:01:09.717766: step 1253, loss 0.155527, acc 0.90625, learning_rate 0.00175115\n","2023-06-27T18:01:09.902624: step 1254, loss 0.298065, acc 0.90625, learning_rate 0.00175001\n","2023-06-27T18:01:10.072592: step 1255, loss 0.110787, acc 0.96875, learning_rate 0.00174888\n","2023-06-27T18:01:10.265955: step 1256, loss 0.204708, acc 0.90625, learning_rate 0.00174775\n","2023-06-27T18:01:10.463421: step 1257, loss 0.348068, acc 0.8125, learning_rate 0.00174662\n","2023-06-27T18:01:10.645295: step 1258, loss 0.502095, acc 0.84375, learning_rate 0.00174549\n","2023-06-27T18:01:10.832795: step 1259, loss 0.217923, acc 0.9375, learning_rate 0.00174436\n","2023-06-27T18:01:11.020373: step 1260, loss 0.18866, acc 0.96875, learning_rate 0.00174324\n","2023-06-27T18:01:11.212141: step 1261, loss 0.0787511, acc 0.96875, learning_rate 0.00174211\n","2023-06-27T18:01:11.410822: step 1262, loss 0.2671, acc 0.84375, learning_rate 0.00174098\n","2023-06-27T18:01:11.593138: step 1263, loss 0.225666, acc 0.9375, learning_rate 0.00173986\n","2023-06-27T18:01:11.771222: step 1264, loss 0.1497, acc 0.9375, learning_rate 0.00173873\n","2023-06-27T18:01:11.929960: step 1265, loss 0.152039, acc 0.9375, learning_rate 0.00173761\n","2023-06-27T18:01:12.042991: step 1266, loss 0.293864, acc 0.875, learning_rate 0.00173649\n","2023-06-27T18:01:12.158348: step 1267, loss 0.274163, acc 0.875, learning_rate 0.00173537\n","2023-06-27T18:01:12.282631: step 1268, loss 0.142658, acc 0.90625, learning_rate 0.00173424\n","2023-06-27T18:01:12.394700: step 1269, loss 0.154522, acc 0.96875, learning_rate 0.00173312\n","2023-06-27T18:01:12.512949: step 1270, loss 0.0980819, acc 1, learning_rate 0.001732\n","2023-06-27T18:01:12.646497: step 1271, loss 0.138462, acc 0.9375, learning_rate 0.00173088\n","2023-06-27T18:01:12.766285: step 1272, loss 0.177559, acc 0.90625, learning_rate 0.00172977\n","2023-06-27T18:01:12.892665: step 1273, loss 0.352285, acc 0.84375, learning_rate 0.00172865\n","2023-06-27T18:01:13.004330: step 1274, loss 0.348602, acc 0.84375, learning_rate 0.00172753\n","2023-06-27T18:01:13.114019: step 1275, loss 0.240743, acc 0.875, learning_rate 0.00172642\n","2023-06-27T18:01:13.235859: step 1276, loss 0.215254, acc 0.90625, learning_rate 0.0017253\n","2023-06-27T18:01:13.353458: step 1277, loss 0.266419, acc 0.90625, learning_rate 0.00172419\n","2023-06-27T18:01:13.467583: step 1278, loss 0.107022, acc 1, learning_rate 0.00172307\n","2023-06-27T18:01:13.594310: step 1279, loss 0.310611, acc 0.875, learning_rate 0.00172196\n","2023-06-27T18:01:13.714955: step 1280, loss 0.214621, acc 0.875, learning_rate 0.00172085\n","2023-06-27T18:01:13.835075: step 1281, loss 0.216989, acc 0.90625, learning_rate 0.00171974\n","2023-06-27T18:01:13.947025: step 1282, loss 0.13629, acc 0.96875, learning_rate 0.00171862\n","2023-06-27T18:01:14.060276: step 1283, loss 0.359493, acc 0.875, learning_rate 0.00171751\n","2023-06-27T18:01:14.173190: step 1284, loss 0.480746, acc 0.875, learning_rate 0.00171641\n","2023-06-27T18:01:14.300286: step 1285, loss 0.189021, acc 0.90625, learning_rate 0.0017153\n","2023-06-27T18:01:14.411165: step 1286, loss 0.144132, acc 1, learning_rate 0.00171419\n","2023-06-27T18:01:14.527751: step 1287, loss 0.469228, acc 0.875, learning_rate 0.00171308\n","2023-06-27T18:01:14.649087: step 1288, loss 0.131472, acc 0.96875, learning_rate 0.00171198\n","2023-06-27T18:01:14.764824: step 1289, loss 0.128671, acc 0.96875, learning_rate 0.00171087\n","2023-06-27T18:01:14.888543: step 1290, loss 0.130667, acc 0.9375, learning_rate 0.00170977\n","2023-06-27T18:01:15.006155: step 1291, loss 0.242963, acc 0.90625, learning_rate 0.00170866\n","2023-06-27T18:01:15.116041: step 1292, loss 0.226738, acc 0.875, learning_rate 0.00170756\n","2023-06-27T18:01:15.226256: step 1293, loss 0.21698, acc 0.90625, learning_rate 0.00170646\n","2023-06-27T18:01:15.349920: step 1294, loss 0.293957, acc 0.90625, learning_rate 0.00170536\n","2023-06-27T18:01:15.477484: step 1295, loss 0.248076, acc 0.90625, learning_rate 0.00170425\n","2023-06-27T18:01:15.597349: step 1296, loss 0.0973469, acc 1, learning_rate 0.00170315\n","2023-06-27T18:01:15.717886: step 1297, loss 0.224366, acc 0.9375, learning_rate 0.00170206\n","2023-06-27T18:01:15.840432: step 1298, loss 0.314757, acc 0.84375, learning_rate 0.00170096\n","2023-06-27T18:01:15.954135: step 1299, loss 0.135512, acc 0.96875, learning_rate 0.00169986\n","\n","Evaluation:\n","2023-06-27T18:01:16.705731: step 1300, loss 0.563553, acc 0.78988\n","\n","Saved model checkpoint to /content/gdrive/MyDrive/lightweighted-cnn/train/runs/1687888658/checkpoints/model-1300\n","\n","2023-06-27T18:01:16.928249: step 1300, loss 0.184257, acc 0.9375, learning_rate 0.00169876\n","2023-06-27T18:01:17.045759: step 1301, loss 0.0947507, acc 0.9375, learning_rate 0.00169767\n","2023-06-27T18:01:17.155758: step 1302, loss 0.228618, acc 0.90625, learning_rate 0.00169657\n","2023-06-27T18:01:17.268355: step 1303, loss 0.0716321, acc 0.96875, learning_rate 0.00169548\n","2023-06-27T18:01:17.390843: step 1304, loss 0.21673, acc 0.90625, learning_rate 0.00169438\n","2023-06-27T18:01:17.506045: step 1305, loss 0.348287, acc 0.9375, learning_rate 0.00169329\n","2023-06-27T18:01:17.633869: step 1306, loss 0.253613, acc 0.90625, learning_rate 0.0016922\n","2023-06-27T18:01:17.752304: step 1307, loss 0.153814, acc 0.9375, learning_rate 0.0016911\n","2023-06-27T18:01:17.869773: step 1308, loss 0.129659, acc 0.96875, learning_rate 0.00169001\n","2023-06-27T18:01:17.994720: step 1309, loss 0.161659, acc 0.9375, learning_rate 0.00168892\n","2023-06-27T18:01:18.116591: step 1310, loss 0.309865, acc 0.90625, learning_rate 0.00168783\n","2023-06-27T18:01:18.228221: step 1311, loss 0.184892, acc 0.90625, learning_rate 0.00168674\n","2023-06-27T18:01:18.350900: step 1312, loss 0.237505, acc 0.9375, learning_rate 0.00168566\n","2023-06-27T18:01:18.466771: step 1313, loss 0.299979, acc 0.84375, learning_rate 0.00168457\n","2023-06-27T18:01:18.580957: step 1314, loss 0.205, acc 0.90625, learning_rate 0.00168348\n","2023-06-27T18:01:18.698448: step 1315, loss 0.182777, acc 0.96875, learning_rate 0.0016824\n","2023-06-27T18:01:18.816424: step 1316, loss 0.459372, acc 0.75, learning_rate 0.00168131\n","2023-06-27T18:01:18.939285: step 1317, loss 0.239435, acc 0.875, learning_rate 0.00168023\n","2023-06-27T18:01:19.048654: step 1318, loss 0.49247, acc 0.8125, learning_rate 0.00167914\n","2023-06-27T18:01:19.165369: step 1319, loss 0.216154, acc 0.9375, learning_rate 0.00167806\n","2023-06-27T18:01:19.285447: step 1320, loss 0.216627, acc 0.9375, learning_rate 0.00167698\n","2023-06-27T18:01:19.393735: step 1321, loss 0.500651, acc 0.78125, learning_rate 0.0016759\n","2023-06-27T18:01:19.514382: step 1322, loss 0.327737, acc 0.875, learning_rate 0.00167482\n","2023-06-27T18:01:19.632154: step 1323, loss 0.345846, acc 0.9375, learning_rate 0.00167374\n","2023-06-27T18:01:19.743710: step 1324, loss 0.278363, acc 0.84375, learning_rate 0.00167266\n","2023-06-27T18:01:19.861646: step 1325, loss 0.1085, acc 0.9375, learning_rate 0.00167158\n","2023-06-27T18:01:19.997488: step 1326, loss 0.170792, acc 0.96875, learning_rate 0.0016705\n","2023-06-27T18:01:20.114118: step 1327, loss 0.320455, acc 0.875, learning_rate 0.00166942\n","2023-06-27T18:01:20.230041: step 1328, loss 0.54311, acc 0.84375, learning_rate 0.00166835\n","2023-06-27T18:01:20.343978: step 1329, loss 0.169098, acc 0.9375, learning_rate 0.00166727\n","2023-06-27T18:01:20.449857: step 1330, loss 0.219834, acc 0.96875, learning_rate 0.0016662\n","2023-06-27T18:01:20.564135: step 1331, loss 0.424051, acc 0.75, learning_rate 0.00166512\n","2023-06-27T18:01:20.681201: step 1332, loss 0.16129, acc 0.96875, learning_rate 0.00166405\n","2023-06-27T18:01:20.796995: step 1333, loss 0.23836, acc 0.9375, learning_rate 0.00166298\n","2023-06-27T18:01:20.915628: step 1334, loss 0.341357, acc 0.875, learning_rate 0.00166191\n","2023-06-27T18:01:21.042400: step 1335, loss 0.230085, acc 0.90625, learning_rate 0.00166083\n","2023-06-27T18:01:21.149428: step 1336, loss 0.240658, acc 0.9375, learning_rate 0.00165976\n","2023-06-27T18:01:21.260833: step 1337, loss 0.290667, acc 0.90625, learning_rate 0.0016587\n","2023-06-27T18:01:21.380690: step 1338, loss 0.115726, acc 0.9375, learning_rate 0.00165763\n","2023-06-27T18:01:21.494482: step 1339, loss 0.157264, acc 0.9375, learning_rate 0.00165656\n","2023-06-27T18:01:21.603912: step 1340, loss 0.197648, acc 0.875, learning_rate 0.00165549\n","2023-06-27T18:01:21.722844: step 1341, loss 0.310123, acc 0.84375, learning_rate 0.00165442\n","2023-06-27T18:01:21.835420: step 1342, loss 0.274151, acc 0.90625, learning_rate 0.00165336\n","2023-06-27T18:01:21.992176: step 1343, loss 0.145616, acc 0.9375, learning_rate 0.00165229\n","2023-06-27T18:01:22.214871: step 1344, loss 0.142102, acc 0.9375, learning_rate 0.00165123\n","2023-06-27T18:01:22.422727: step 1345, loss 0.238494, acc 0.9375, learning_rate 0.00165016\n","2023-06-27T18:01:22.618980: step 1346, loss 0.1456, acc 0.96875, learning_rate 0.0016491\n","2023-06-27T18:01:22.824896: step 1347, loss 0.20901, acc 0.875, learning_rate 0.00164804\n","2023-06-27T18:01:23.015026: step 1348, loss 0.194324, acc 0.9375, learning_rate 0.00164698\n","2023-06-27T18:01:23.212837: step 1349, loss 0.401467, acc 0.875, learning_rate 0.00164592\n","2023-06-27T18:01:23.411952: step 1350, loss 0.200206, acc 0.90625, learning_rate 0.00164486\n","2023-06-27T18:01:23.618878: step 1351, loss 0.0577624, acc 0.96875, learning_rate 0.0016438\n","2023-06-27T18:01:23.803351: step 1352, loss 0.543059, acc 0.875, learning_rate 0.00164274\n","2023-06-27T18:01:23.992590: step 1353, loss 0.299122, acc 0.875, learning_rate 0.00164168\n","2023-06-27T18:01:24.178491: step 1354, loss 0.147041, acc 0.96875, learning_rate 0.00164062\n","2023-06-27T18:01:24.380986: step 1355, loss 0.163193, acc 0.9375, learning_rate 0.00163957\n","2023-06-27T18:01:24.595113: step 1356, loss 0.287275, acc 0.875, learning_rate 0.00163851\n","2023-06-27T18:01:24.781235: step 1357, loss 0.196982, acc 0.90625, learning_rate 0.00163746\n","2023-06-27T18:01:25.001296: step 1358, loss 0.337247, acc 0.875, learning_rate 0.0016364\n","2023-06-27T18:01:25.216002: step 1359, loss 0.316826, acc 0.875, learning_rate 0.00163535\n","2023-06-27T18:01:25.410089: step 1360, loss 0.224259, acc 0.90625, learning_rate 0.0016343\n","2023-06-27T18:01:25.615826: step 1361, loss 0.0786718, acc 1, learning_rate 0.00163324\n","2023-06-27T18:01:25.784202: step 1362, loss 0.0570043, acc 1, learning_rate 0.00163219\n","2023-06-27T18:01:25.974751: step 1363, loss 0.347294, acc 0.84375, learning_rate 0.00163114\n","2023-06-27T18:01:26.168656: step 1364, loss 0.293696, acc 0.90625, learning_rate 0.00163009\n","2023-06-27T18:01:26.344447: step 1365, loss 0.379382, acc 0.84375, learning_rate 0.00162904\n","2023-06-27T18:01:26.515817: step 1366, loss 0.38368, acc 0.875, learning_rate 0.00162799\n","2023-06-27T18:01:26.696825: step 1367, loss 0.326918, acc 0.90625, learning_rate 0.00162695\n","2023-06-27T18:01:26.869271: step 1368, loss 0.197282, acc 0.90625, learning_rate 0.0016259\n","2023-06-27T18:01:27.045104: step 1369, loss 0.290217, acc 0.90625, learning_rate 0.00162485\n","2023-06-27T18:01:27.239407: step 1370, loss 0.198305, acc 0.90625, learning_rate 0.00162381\n","2023-06-27T18:01:27.424013: step 1371, loss 0.180621, acc 0.875, learning_rate 0.00162276\n","2023-06-27T18:01:27.595116: step 1372, loss 0.226988, acc 0.90625, learning_rate 0.00162172\n","2023-06-27T18:01:27.785733: step 1373, loss 0.105248, acc 0.96875, learning_rate 0.00162068\n","2023-06-27T18:01:27.970487: step 1374, loss 0.230052, acc 0.90625, learning_rate 0.00161963\n","2023-06-27T18:01:28.165038: step 1375, loss 0.312561, acc 0.875, learning_rate 0.00161859\n","2023-06-27T18:01:28.360621: step 1376, loss 0.197362, acc 0.90625, learning_rate 0.00161755\n","2023-06-27T18:01:28.565685: step 1377, loss 0.191783, acc 0.9375, learning_rate 0.00161651\n","2023-06-27T18:01:28.772463: step 1378, loss 0.303271, acc 0.875, learning_rate 0.00161547\n","2023-06-27T18:01:28.960634: step 1379, loss 0.146296, acc 0.9375, learning_rate 0.00161443\n","2023-06-27T18:01:29.137653: step 1380, loss 0.339014, acc 0.90625, learning_rate 0.00161339\n","2023-06-27T18:01:29.326400: step 1381, loss 0.168133, acc 0.9375, learning_rate 0.00161235\n","2023-06-27T18:01:29.511334: step 1382, loss 0.313198, acc 0.90625, learning_rate 0.00161132\n","2023-06-27T18:01:29.676034: step 1383, loss 0.291501, acc 0.875, learning_rate 0.00161028\n","2023-06-27T18:01:29.862336: step 1384, loss 0.194197, acc 0.90625, learning_rate 0.00160924\n","2023-06-27T18:01:30.043291: step 1385, loss 0.191754, acc 0.90625, learning_rate 0.00160821\n","2023-06-27T18:01:30.209899: step 1386, loss 0.14229, acc 0.90625, learning_rate 0.00160717\n","2023-06-27T18:01:30.382246: step 1387, loss 0.276994, acc 0.84375, learning_rate 0.00160614\n","2023-06-27T18:01:30.602026: step 1388, loss 0.18669, acc 0.875, learning_rate 0.00160511\n","2023-06-27T18:01:30.787585: step 1389, loss 0.160616, acc 0.9375, learning_rate 0.00160408\n","2023-06-27T18:01:30.967005: step 1390, loss 0.237649, acc 0.875, learning_rate 0.00160305\n","2023-06-27T18:01:31.131988: step 1391, loss 0.335503, acc 0.875, learning_rate 0.00160201\n","2023-06-27T18:01:31.303248: step 1392, loss 0.202857, acc 0.9375, learning_rate 0.00160098\n","2023-06-27T18:01:31.500856: step 1393, loss 0.372896, acc 0.875, learning_rate 0.00159996\n","2023-06-27T18:01:31.685062: step 1394, loss 0.225714, acc 0.9375, learning_rate 0.00159893\n","2023-06-27T18:01:31.867347: step 1395, loss 0.0756641, acc 1, learning_rate 0.0015979\n","2023-06-27T18:01:32.050592: step 1396, loss 0.197953, acc 0.875, learning_rate 0.00159687\n","2023-06-27T18:01:32.221134: step 1397, loss 0.112615, acc 0.9375, learning_rate 0.00159585\n","2023-06-27T18:01:32.392957: step 1398, loss 0.269692, acc 0.875, learning_rate 0.00159482\n","2023-06-27T18:01:32.554377: step 1399, loss 0.101423, acc 1, learning_rate 0.00159379\n","\n","Evaluation:\n","2023-06-27T18:01:33.334434: step 1400, loss 0.578889, acc 0.787736\n","\n","Saved model checkpoint to /content/gdrive/MyDrive/lightweighted-cnn/train/runs/1687888658/checkpoints/model-1400\n","\n","2023-06-27T18:01:33.566259: step 1400, loss 0.486557, acc 0.8125, learning_rate 0.00159277\n","2023-06-27T18:01:33.678907: step 1401, loss 0.263088, acc 0.84375, learning_rate 0.00159175\n","2023-06-27T18:01:33.788130: step 1402, loss 0.201398, acc 0.90625, learning_rate 0.00159072\n","2023-06-27T18:01:33.899531: step 1403, loss 0.451309, acc 0.90625, learning_rate 0.0015897\n","2023-06-27T18:01:34.010766: step 1404, loss 0.0841254, acc 1, learning_rate 0.00158868\n","2023-06-27T18:01:34.127232: step 1405, loss 0.214411, acc 0.9375, learning_rate 0.00158766\n","2023-06-27T18:01:34.251764: step 1406, loss 0.29705, acc 0.875, learning_rate 0.00158664\n","2023-06-27T18:01:34.374946: step 1407, loss 0.117654, acc 0.96875, learning_rate 0.00158562\n","2023-06-27T18:01:34.487312: step 1408, loss 0.355744, acc 0.875, learning_rate 0.0015846\n","2023-06-27T18:01:34.624898: step 1409, loss 0.24763, acc 0.9375, learning_rate 0.00158358\n","2023-06-27T18:01:34.735387: step 1410, loss 0.197624, acc 0.96875, learning_rate 0.00158257\n","2023-06-27T18:01:34.858213: step 1411, loss 0.328447, acc 0.84375, learning_rate 0.00158155\n","2023-06-27T18:01:34.965835: step 1412, loss 0.239538, acc 0.90625, learning_rate 0.00158053\n","2023-06-27T18:01:35.077219: step 1413, loss 0.191185, acc 0.96875, learning_rate 0.00157952\n","2023-06-27T18:01:35.197281: step 1414, loss 0.329825, acc 0.84375, learning_rate 0.0015785\n","2023-06-27T18:01:35.309125: step 1415, loss 0.378132, acc 0.875, learning_rate 0.00157749\n","2023-06-27T18:01:35.422709: step 1416, loss 0.304577, acc 0.84375, learning_rate 0.00157648\n","2023-06-27T18:01:35.546649: step 1417, loss 0.128392, acc 0.9375, learning_rate 0.00157546\n","2023-06-27T18:01:35.674530: step 1418, loss 0.132267, acc 1, learning_rate 0.00157445\n","2023-06-27T18:01:35.790835: step 1419, loss 0.322383, acc 0.875, learning_rate 0.00157344\n","2023-06-27T18:01:35.901087: step 1420, loss 0.402144, acc 0.90625, learning_rate 0.00157243\n","2023-06-27T18:01:36.015476: step 1421, loss 0.162804, acc 0.9375, learning_rate 0.00157142\n","2023-06-27T18:01:36.131110: step 1422, loss 0.274535, acc 0.875, learning_rate 0.00157041\n","2023-06-27T18:01:36.238846: step 1423, loss 0.373129, acc 0.84375, learning_rate 0.0015694\n","2023-06-27T18:01:36.380959: step 1424, loss 0.11219, acc 0.9375, learning_rate 0.0015684\n","2023-06-27T18:01:36.494485: step 1425, loss 0.228589, acc 0.875, learning_rate 0.00156739\n","2023-06-27T18:01:36.618713: step 1426, loss 0.309324, acc 0.90625, learning_rate 0.00156638\n","2023-06-27T18:01:36.732591: step 1427, loss 0.163666, acc 0.9375, learning_rate 0.00156538\n","2023-06-27T18:01:36.844060: step 1428, loss 0.213253, acc 0.90625, learning_rate 0.00156437\n","2023-06-27T18:01:36.958130: step 1429, loss 0.174279, acc 0.9375, learning_rate 0.00156337\n","2023-06-27T18:01:37.073431: step 1430, loss 0.335097, acc 0.875, learning_rate 0.00156236\n","2023-06-27T18:01:37.193232: step 1431, loss 0.1811, acc 0.9375, learning_rate 0.00156136\n","2023-06-27T18:01:37.307296: step 1432, loss 0.248132, acc 0.90625, learning_rate 0.00156036\n","2023-06-27T18:01:37.413288: step 1433, loss 0.261138, acc 0.9375, learning_rate 0.00155936\n","2023-06-27T18:01:37.531540: step 1434, loss 0.143675, acc 0.96875, learning_rate 0.00155836\n","2023-06-27T18:01:37.653123: step 1435, loss 0.289847, acc 0.875, learning_rate 0.00155736\n","2023-06-27T18:01:37.767582: step 1436, loss 0.0777728, acc 1, learning_rate 0.00155636\n","2023-06-27T18:01:37.883652: step 1437, loss 0.446349, acc 0.8125, learning_rate 0.00155536\n","2023-06-27T18:01:37.999871: step 1438, loss 0.0546997, acc 1, learning_rate 0.00155436\n","2023-06-27T18:01:38.123108: step 1439, loss 0.206332, acc 0.90625, learning_rate 0.00155336\n","2023-06-27T18:01:38.242402: step 1440, loss 0.233063, acc 0.90625, learning_rate 0.00155237\n","2023-06-27T18:01:38.367446: step 1441, loss 0.351836, acc 0.875, learning_rate 0.00155137\n","2023-06-27T18:01:38.486316: step 1442, loss 0.222759, acc 0.9375, learning_rate 0.00155038\n","2023-06-27T18:01:38.600873: step 1443, loss 0.176777, acc 0.9375, learning_rate 0.00154938\n","2023-06-27T18:01:38.722240: step 1444, loss 0.401007, acc 0.84375, learning_rate 0.00154839\n","2023-06-27T18:01:38.848280: step 1445, loss 0.144355, acc 0.96875, learning_rate 0.0015474\n","2023-06-27T18:01:38.964737: step 1446, loss 0.108276, acc 0.9375, learning_rate 0.0015464\n","2023-06-27T18:01:39.099843: step 1447, loss 0.216261, acc 0.9375, learning_rate 0.00154541\n","2023-06-27T18:01:39.209042: step 1448, loss 0.220258, acc 0.9375, learning_rate 0.00154442\n","2023-06-27T18:01:39.321602: step 1449, loss 0.0257044, acc 1, learning_rate 0.00154343\n","2023-06-27T18:01:39.441768: step 1450, loss 0.190745, acc 0.90625, learning_rate 0.00154244\n","2023-06-27T18:01:39.556136: step 1451, loss 0.191539, acc 0.9375, learning_rate 0.00154145\n","2023-06-27T18:01:39.670592: step 1452, loss 0.138522, acc 0.9375, learning_rate 0.00154046\n","2023-06-27T18:01:39.800434: step 1453, loss 0.188984, acc 0.90625, learning_rate 0.00153947\n","2023-06-27T18:01:39.921903: step 1454, loss 0.169616, acc 0.96875, learning_rate 0.00153849\n","2023-06-27T18:01:40.084704: step 1455, loss 0.31069, acc 0.9375, learning_rate 0.0015375\n","2023-06-27T18:01:40.204386: step 1456, loss 0.35042, acc 0.9375, learning_rate 0.00153651\n","2023-06-27T18:01:40.323155: step 1457, loss 0.189804, acc 0.9375, learning_rate 0.00153553\n","2023-06-27T18:01:40.442641: step 1458, loss 0.174835, acc 0.90625, learning_rate 0.00153455\n","2023-06-27T18:01:40.551938: step 1459, loss 0.211423, acc 0.9375, learning_rate 0.00153356\n","2023-06-27T18:01:40.670377: step 1460, loss 0.214868, acc 0.9375, learning_rate 0.00153258\n","2023-06-27T18:01:40.797725: step 1461, loss 0.237005, acc 0.9375, learning_rate 0.0015316\n","2023-06-27T18:01:40.921659: step 1462, loss 0.176764, acc 0.96875, learning_rate 0.00153061\n","2023-06-27T18:01:41.037018: step 1463, loss 0.169774, acc 0.9375, learning_rate 0.00152963\n","2023-06-27T18:01:41.162329: step 1464, loss 0.20046, acc 0.9375, learning_rate 0.00152865\n","2023-06-27T18:01:41.280758: step 1465, loss 0.285273, acc 0.90625, learning_rate 0.00152767\n","2023-06-27T18:01:41.391151: step 1466, loss 0.215393, acc 0.90625, learning_rate 0.00152669\n","2023-06-27T18:01:41.510420: step 1467, loss 0.274113, acc 0.84375, learning_rate 0.00152572\n","2023-06-27T18:01:41.628892: step 1468, loss 0.256018, acc 0.875, learning_rate 0.00152474\n","2023-06-27T18:01:41.765783: step 1469, loss 0.30095, acc 0.875, learning_rate 0.00152376\n","2023-06-27T18:01:41.886651: step 1470, loss 0.105277, acc 0.96875, learning_rate 0.00152279\n","2023-06-27T18:01:42.001013: step 1471, loss 0.241416, acc 0.9375, learning_rate 0.00152181\n","2023-06-27T18:01:42.121894: step 1472, loss 0.463568, acc 0.875, learning_rate 0.00152083\n","2023-06-27T18:01:42.238547: step 1473, loss 0.387078, acc 0.8125, learning_rate 0.00151986\n","2023-06-27T18:01:42.351829: step 1474, loss 0.36374, acc 0.90625, learning_rate 0.00151889\n","2023-06-27T18:01:42.475161: step 1475, loss 0.0712915, acc 0.96875, learning_rate 0.00151791\n","2023-06-27T18:01:42.586740: step 1476, loss 0.181558, acc 0.9375, learning_rate 0.00151694\n","2023-06-27T18:01:42.702790: step 1477, loss 0.187264, acc 0.9375, learning_rate 0.00151597\n","2023-06-27T18:01:42.888613: step 1478, loss 0.234289, acc 0.90625, learning_rate 0.001515\n","2023-06-27T18:01:43.096750: step 1479, loss 0.327454, acc 0.875, learning_rate 0.00151403\n","2023-06-27T18:01:43.296968: step 1480, loss 0.267906, acc 0.90625, learning_rate 0.00151306\n","2023-06-27T18:01:43.497350: step 1481, loss 0.263457, acc 0.875, learning_rate 0.00151209\n","2023-06-27T18:01:43.711679: step 1482, loss 0.103412, acc 0.96875, learning_rate 0.00151112\n","2023-06-27T18:01:43.893419: step 1483, loss 0.105451, acc 1, learning_rate 0.00151015\n","2023-06-27T18:01:44.089593: step 1484, loss 0.294759, acc 0.90625, learning_rate 0.00150919\n","2023-06-27T18:01:44.283555: step 1485, loss 0.165757, acc 0.96875, learning_rate 0.00150822\n","2023-06-27T18:01:44.486677: step 1486, loss 0.359869, acc 0.84375, learning_rate 0.00150726\n","2023-06-27T18:01:44.703345: step 1487, loss 0.262418, acc 0.90625, learning_rate 0.00150629\n","2023-06-27T18:01:44.908226: step 1488, loss 0.224, acc 0.875, learning_rate 0.00150533\n","2023-06-27T18:01:45.120038: step 1489, loss 0.251727, acc 0.90625, learning_rate 0.00150436\n","2023-06-27T18:01:45.323193: step 1490, loss 0.0967548, acc 0.96875, learning_rate 0.0015034\n","2023-06-27T18:01:45.516397: step 1491, loss 0.537043, acc 0.71875, learning_rate 0.00150244\n","2023-06-27T18:01:45.718498: step 1492, loss 0.378218, acc 0.84375, learning_rate 0.00150148\n","2023-06-27T18:01:45.908256: step 1493, loss 0.294419, acc 0.84375, learning_rate 0.00150051\n","2023-06-27T18:01:46.122530: step 1494, loss 0.295008, acc 0.90625, learning_rate 0.00149955\n","2023-06-27T18:01:46.324823: step 1495, loss 0.105683, acc 1, learning_rate 0.00149859\n","2023-06-27T18:01:46.533506: step 1496, loss 0.17578, acc 0.90625, learning_rate 0.00149763\n","2023-06-27T18:01:46.725375: step 1497, loss 0.291341, acc 0.875, learning_rate 0.00149668\n","2023-06-27T18:01:46.920530: step 1498, loss 0.257038, acc 0.875, learning_rate 0.00149572\n","2023-06-27T18:01:47.116620: step 1499, loss 0.133978, acc 0.9375, learning_rate 0.00149476\n","\n","Evaluation:\n","2023-06-27T18:01:48.465499: step 1500, loss 0.575785, acc 0.792238\n","\n","Saved model checkpoint to /content/gdrive/MyDrive/lightweighted-cnn/train/runs/1687888658/checkpoints/model-1500\n","\n","2023-06-27T18:01:48.807877: step 1500, loss 0.197039, acc 0.90625, learning_rate 0.00149381\n","2023-06-27T18:01:49.006581: step 1501, loss 0.219969, acc 0.9375, learning_rate 0.00149285\n","2023-06-27T18:01:49.208878: step 1502, loss 0.11335, acc 0.90625, learning_rate 0.00149189\n","2023-06-27T18:01:49.394446: step 1503, loss 0.378984, acc 0.90625, learning_rate 0.00149094\n","2023-06-27T18:01:49.591080: step 1504, loss 0.197456, acc 0.96875, learning_rate 0.00148999\n","2023-06-27T18:01:49.775765: step 1505, loss 0.305909, acc 0.9375, learning_rate 0.00148903\n","2023-06-27T18:01:49.966244: step 1506, loss 0.101242, acc 0.96875, learning_rate 0.00148808\n","2023-06-27T18:01:50.176156: step 1507, loss 0.406832, acc 0.78125, learning_rate 0.00148713\n","2023-06-27T18:01:50.363098: step 1508, loss 0.207763, acc 0.875, learning_rate 0.00148618\n","2023-06-27T18:01:50.546437: step 1509, loss 0.114115, acc 0.96875, learning_rate 0.00148523\n","2023-06-27T18:01:50.733524: step 1510, loss 0.302517, acc 0.8125, learning_rate 0.00148428\n","2023-06-27T18:01:50.914048: step 1511, loss 0.151027, acc 0.96875, learning_rate 0.00148333\n","2023-06-27T18:01:51.115592: step 1512, loss 0.179921, acc 0.96875, learning_rate 0.00148238\n","2023-06-27T18:01:51.292154: step 1513, loss 0.271542, acc 0.875, learning_rate 0.00148143\n","2023-06-27T18:01:51.496795: step 1514, loss 0.19328, acc 0.9375, learning_rate 0.00148048\n","2023-06-27T18:01:51.685342: step 1515, loss 0.124954, acc 0.96875, learning_rate 0.00147954\n","2023-06-27T18:01:51.877269: step 1516, loss 0.292823, acc 0.90625, learning_rate 0.00147859\n","2023-06-27T18:01:52.064787: step 1517, loss 0.0850926, acc 1, learning_rate 0.00147765\n","2023-06-27T18:01:52.254893: step 1518, loss 0.389062, acc 0.90625, learning_rate 0.0014767\n","2023-06-27T18:01:52.437650: step 1519, loss 0.210392, acc 0.90625, learning_rate 0.00147576\n","2023-06-27T18:01:52.611387: step 1520, loss 0.451412, acc 0.875, learning_rate 0.00147481\n","2023-06-27T18:01:52.779032: step 1521, loss 0.386179, acc 0.84375, learning_rate 0.00147387\n","2023-06-27T18:01:52.968456: step 1522, loss 0.365399, acc 0.84375, learning_rate 0.00147293\n","2023-06-27T18:01:53.169904: step 1523, loss 0.338361, acc 0.875, learning_rate 0.00147199\n","2023-06-27T18:01:53.350656: step 1524, loss 0.343032, acc 0.875, learning_rate 0.00147105\n","2023-06-27T18:01:53.534223: step 1525, loss 0.130633, acc 0.9375, learning_rate 0.00147011\n","2023-06-27T18:01:53.720074: step 1526, loss 0.271318, acc 0.9375, learning_rate 0.00146917\n","2023-06-27T18:01:53.835608: step 1527, loss 0.169085, acc 0.9375, learning_rate 0.00146823\n","2023-06-27T18:01:53.959046: step 1528, loss 0.232042, acc 0.9375, learning_rate 0.00146729\n","2023-06-27T18:01:54.075786: step 1529, loss 0.177273, acc 0.9375, learning_rate 0.00146635\n","2023-06-27T18:01:54.212734: step 1530, loss 0.345663, acc 0.84375, learning_rate 0.00146542\n","2023-06-27T18:01:54.326740: step 1531, loss 0.216346, acc 0.9375, learning_rate 0.00146448\n","2023-06-27T18:01:54.446031: step 1532, loss 0.145344, acc 0.9375, learning_rate 0.00146354\n","2023-06-27T18:01:54.562537: step 1533, loss 0.104385, acc 0.9375, learning_rate 0.00146261\n","2023-06-27T18:01:54.679120: step 1534, loss 0.318555, acc 0.90625, learning_rate 0.00146167\n","2023-06-27T18:01:54.811692: step 1535, loss 0.177933, acc 0.90625, learning_rate 0.00146074\n","2023-06-27T18:01:54.921737: step 1536, loss 0.0960174, acc 0.96875, learning_rate 0.00145981\n","2023-06-27T18:01:55.072386: step 1537, loss 0.239793, acc 0.90625, learning_rate 0.00145888\n","2023-06-27T18:01:55.186377: step 1538, loss 0.327393, acc 0.84375, learning_rate 0.00145794\n","2023-06-27T18:01:55.316894: step 1539, loss 0.161597, acc 0.9375, learning_rate 0.00145701\n","2023-06-27T18:01:55.441394: step 1540, loss 0.1734, acc 0.9375, learning_rate 0.00145608\n","2023-06-27T18:01:55.558200: step 1541, loss 0.385649, acc 0.875, learning_rate 0.00145515\n","2023-06-27T18:01:55.678081: step 1542, loss 0.264092, acc 0.875, learning_rate 0.00145422\n","2023-06-27T18:01:55.798299: step 1543, loss 0.220825, acc 0.90625, learning_rate 0.00145329\n","2023-06-27T18:01:55.914768: step 1544, loss 0.357608, acc 0.9375, learning_rate 0.00145237\n","2023-06-27T18:01:56.025645: step 1545, loss 0.427528, acc 0.84375, learning_rate 0.00145144\n","2023-06-27T18:01:56.153571: step 1546, loss 0.15004, acc 0.96875, learning_rate 0.00145051\n","2023-06-27T18:01:56.279391: step 1547, loss 0.137994, acc 0.96875, learning_rate 0.00144959\n","2023-06-27T18:01:56.391716: step 1548, loss 0.175426, acc 0.96875, learning_rate 0.00144866\n","2023-06-27T18:01:56.509744: step 1549, loss 0.351745, acc 0.96875, learning_rate 0.00144774\n","2023-06-27T18:01:56.628204: step 1550, loss 0.0654474, acc 1, learning_rate 0.00144681\n","2023-06-27T18:01:56.746194: step 1551, loss 0.148551, acc 0.9375, learning_rate 0.00144589\n","2023-06-27T18:01:56.870469: step 1552, loss 0.144304, acc 0.96875, learning_rate 0.00144496\n","2023-06-27T18:01:56.983181: step 1553, loss 0.37484, acc 0.84375, learning_rate 0.00144404\n","2023-06-27T18:01:57.096873: step 1554, loss 0.242484, acc 0.9375, learning_rate 0.00144312\n","2023-06-27T18:01:57.220746: step 1555, loss 0.136861, acc 0.96875, learning_rate 0.0014422\n","2023-06-27T18:01:57.363290: step 1556, loss 0.0809327, acc 1, learning_rate 0.00144128\n","2023-06-27T18:01:57.491212: step 1557, loss 0.185786, acc 0.9375, learning_rate 0.00144036\n","2023-06-27T18:01:57.613047: step 1558, loss 0.140485, acc 0.96875, learning_rate 0.00143944\n","2023-06-27T18:01:57.757212: step 1559, loss 0.504663, acc 0.75, learning_rate 0.00143852\n","2023-06-27T18:01:57.869820: step 1560, loss 0.336789, acc 0.84375, learning_rate 0.0014376\n","2023-06-27T18:01:57.981042: step 1561, loss 0.610156, acc 0.8125, learning_rate 0.00143669\n","2023-06-27T18:01:58.096670: step 1562, loss 0.295031, acc 0.90625, learning_rate 0.00143577\n","2023-06-27T18:01:58.222319: step 1563, loss 0.234983, acc 0.90625, learning_rate 0.00143485\n","2023-06-27T18:01:58.366871: step 1564, loss 0.0779422, acc 1, learning_rate 0.00143394\n","2023-06-27T18:01:58.487719: step 1565, loss 0.165958, acc 0.96875, learning_rate 0.00143302\n","2023-06-27T18:01:58.603376: step 1566, loss 0.229041, acc 0.96875, learning_rate 0.00143211\n","2023-06-27T18:01:58.728618: step 1567, loss 0.469371, acc 0.875, learning_rate 0.0014312\n","2023-06-27T18:01:58.840218: step 1568, loss 0.266202, acc 0.84375, learning_rate 0.00143028\n","2023-06-27T18:01:58.969549: step 1569, loss 0.131994, acc 1, learning_rate 0.00142937\n","2023-06-27T18:01:59.088736: step 1570, loss 0.391592, acc 0.90625, learning_rate 0.00142846\n","2023-06-27T18:01:59.211169: step 1571, loss 0.175101, acc 0.9375, learning_rate 0.00142755\n","2023-06-27T18:01:59.333585: step 1572, loss 0.249323, acc 0.875, learning_rate 0.00142664\n","2023-06-27T18:01:59.449730: step 1573, loss 0.163808, acc 0.9375, learning_rate 0.00142573\n","2023-06-27T18:01:59.568213: step 1574, loss 0.314293, acc 0.875, learning_rate 0.00142482\n","2023-06-27T18:01:59.690361: step 1575, loss 0.459029, acc 0.84375, learning_rate 0.00142391\n","2023-06-27T18:01:59.802736: step 1576, loss 0.177627, acc 0.90625, learning_rate 0.001423\n","2023-06-27T18:01:59.922884: step 1577, loss 0.544431, acc 0.8125, learning_rate 0.0014221\n","2023-06-27T18:02:00.041102: step 1578, loss 0.156547, acc 0.9375, learning_rate 0.00142119\n","2023-06-27T18:02:00.156816: step 1579, loss 0.0593764, acc 1, learning_rate 0.00142028\n","2023-06-27T18:02:00.282612: step 1580, loss 0.154263, acc 0.9375, learning_rate 0.00141938\n","2023-06-27T18:02:00.413972: step 1581, loss 0.373965, acc 0.84375, learning_rate 0.00141847\n","2023-06-27T18:02:00.534625: step 1582, loss 0.0965493, acc 0.96875, learning_rate 0.00141757\n","2023-06-27T18:02:00.669057: step 1583, loss 0.127261, acc 0.9375, learning_rate 0.00141667\n","2023-06-27T18:02:00.783529: step 1584, loss 0.269492, acc 0.875, learning_rate 0.00141576\n","2023-06-27T18:02:00.904443: step 1585, loss 0.195637, acc 0.90625, learning_rate 0.00141486\n","2023-06-27T18:02:01.015591: step 1586, loss 0.141604, acc 0.96875, learning_rate 0.00141396\n","2023-06-27T18:02:01.128288: step 1587, loss 0.121638, acc 1, learning_rate 0.00141306\n","2023-06-27T18:02:01.255426: step 1588, loss 0.12505, acc 0.9375, learning_rate 0.00141216\n","2023-06-27T18:02:01.378792: step 1589, loss 0.380557, acc 0.875, learning_rate 0.00141126\n","2023-06-27T18:02:01.498938: step 1590, loss 0.244932, acc 0.90625, learning_rate 0.00141036\n","2023-06-27T18:02:01.622610: step 1591, loss 0.313557, acc 0.84375, learning_rate 0.00140946\n","2023-06-27T18:02:01.742959: step 1592, loss 0.139964, acc 0.96875, learning_rate 0.00140856\n","2023-06-27T18:02:01.865694: step 1593, loss 0.157664, acc 0.90625, learning_rate 0.00140767\n","2023-06-27T18:02:01.978971: step 1594, loss 0.112053, acc 0.96875, learning_rate 0.00140677\n","2023-06-27T18:02:02.097247: step 1595, loss 0.119924, acc 0.9375, learning_rate 0.00140587\n","2023-06-27T18:02:02.222283: step 1596, loss 0.10084, acc 0.96875, learning_rate 0.00140498\n","2023-06-27T18:02:02.339625: step 1597, loss 0.274198, acc 0.90625, learning_rate 0.00140408\n","2023-06-27T18:02:02.473645: step 1598, loss 0.287061, acc 0.9375, learning_rate 0.00140319\n","2023-06-27T18:02:02.589635: step 1599, loss 0.263337, acc 0.875, learning_rate 0.00140229\n","\n","Evaluation:\n","2023-06-27T18:02:03.340749: step 1600, loss 0.56872, acc 0.797599\n","\n","Saved model checkpoint to /content/gdrive/MyDrive/lightweighted-cnn/train/runs/1687888658/checkpoints/model-1600\n","\n","2023-06-27T18:02:03.559159: step 1600, loss 0.232219, acc 0.9375, learning_rate 0.0014014\n","2023-06-27T18:02:03.691088: step 1601, loss 0.248073, acc 0.84375, learning_rate 0.00140051\n","2023-06-27T18:02:03.859859: step 1602, loss 0.192385, acc 0.875, learning_rate 0.00139962\n","2023-06-27T18:02:04.033092: step 1603, loss 0.204007, acc 0.9375, learning_rate 0.00139873\n","2023-06-27T18:02:04.251078: step 1604, loss 0.11613, acc 0.96875, learning_rate 0.00139784\n","2023-06-27T18:02:04.484061: step 1605, loss 0.399578, acc 0.875, learning_rate 0.00139695\n","2023-06-27T18:02:04.707894: step 1606, loss 0.485682, acc 0.84375, learning_rate 0.00139606\n","2023-06-27T18:02:04.920460: step 1607, loss 0.207881, acc 0.9375, learning_rate 0.00139517\n","2023-06-27T18:02:05.112019: step 1608, loss 0.483283, acc 0.84375, learning_rate 0.00139428\n","2023-06-27T18:02:05.308106: step 1609, loss 0.283509, acc 0.90625, learning_rate 0.00139339\n","2023-06-27T18:02:05.515349: step 1610, loss 0.108869, acc 0.96875, learning_rate 0.0013925\n","2023-06-27T18:02:05.721519: step 1611, loss 0.351616, acc 0.84375, learning_rate 0.00139162\n","2023-06-27T18:02:05.920132: step 1612, loss 0.310257, acc 0.875, learning_rate 0.00139073\n","2023-06-27T18:02:06.125374: step 1613, loss 0.288893, acc 0.90625, learning_rate 0.00138985\n","2023-06-27T18:02:06.342545: step 1614, loss 0.189408, acc 0.9375, learning_rate 0.00138896\n","2023-06-27T18:02:06.538536: step 1615, loss 0.345268, acc 0.8125, learning_rate 0.00138808\n","2023-06-27T18:02:06.738264: step 1616, loss 0.658743, acc 0.875, learning_rate 0.0013872\n","2023-06-27T18:02:06.949740: step 1617, loss 0.246658, acc 0.84375, learning_rate 0.00138631\n","2023-06-27T18:02:07.147842: step 1618, loss 0.158551, acc 0.9375, learning_rate 0.00138543\n","2023-06-27T18:02:07.337313: step 1619, loss 0.153813, acc 0.96875, learning_rate 0.00138455\n","2023-06-27T18:02:07.533798: step 1620, loss 0.466813, acc 0.90625, learning_rate 0.00138367\n","2023-06-27T18:02:07.743041: step 1621, loss 0.546712, acc 0.78125, learning_rate 0.00138279\n","2023-06-27T18:02:07.945271: step 1622, loss 0.365986, acc 0.78125, learning_rate 0.00138191\n","2023-06-27T18:02:08.111635: step 1623, loss 0.177371, acc 0.9375, learning_rate 0.00138103\n","2023-06-27T18:02:08.297618: step 1624, loss 0.143576, acc 0.90625, learning_rate 0.00138015\n","2023-06-27T18:02:08.486954: step 1625, loss 0.278435, acc 0.90625, learning_rate 0.00137927\n","2023-06-27T18:02:08.671672: step 1626, loss 0.282949, acc 0.90625, learning_rate 0.0013784\n","2023-06-27T18:02:08.861882: step 1627, loss 0.502213, acc 0.84375, learning_rate 0.00137752\n","2023-06-27T18:02:09.053019: step 1628, loss 0.176027, acc 0.9375, learning_rate 0.00137664\n","2023-06-27T18:02:09.243713: step 1629, loss 0.280329, acc 0.90625, learning_rate 0.00137577\n","2023-06-27T18:02:09.443747: step 1630, loss 0.273695, acc 0.875, learning_rate 0.00137489\n","2023-06-27T18:02:09.635881: step 1631, loss 0.0800306, acc 0.96875, learning_rate 0.00137402\n","2023-06-27T18:02:09.830330: step 1632, loss 0.152909, acc 0.96875, learning_rate 0.00137315\n","2023-06-27T18:02:10.060594: step 1633, loss 0.272448, acc 0.875, learning_rate 0.00137227\n","2023-06-27T18:02:10.272749: step 1634, loss 0.161378, acc 0.96875, learning_rate 0.0013714\n","2023-06-27T18:02:10.429725: step 1635, loss 0.123144, acc 0.96875, learning_rate 0.00137053\n","2023-06-27T18:02:10.610188: step 1636, loss 0.131534, acc 0.96875, learning_rate 0.00136966\n","2023-06-27T18:02:10.819727: step 1637, loss 0.270069, acc 0.84375, learning_rate 0.00136879\n","2023-06-27T18:02:10.998235: step 1638, loss 0.142379, acc 0.96875, learning_rate 0.00136792\n","2023-06-27T18:02:11.179219: step 1639, loss 0.239221, acc 0.90625, learning_rate 0.00136705\n","2023-06-27T18:02:11.351917: step 1640, loss 0.285269, acc 0.875, learning_rate 0.00136618\n","2023-06-27T18:02:11.534389: step 1641, loss 0.22226, acc 0.875, learning_rate 0.00136531\n","2023-06-27T18:02:11.708669: step 1642, loss 0.339551, acc 0.84375, learning_rate 0.00136444\n","2023-06-27T18:02:11.894135: step 1643, loss 0.230192, acc 0.90625, learning_rate 0.00136358\n","2023-06-27T18:02:12.078227: step 1644, loss 0.160255, acc 0.9375, learning_rate 0.00136271\n","2023-06-27T18:02:12.261788: step 1645, loss 0.357762, acc 0.875, learning_rate 0.00136184\n","2023-06-27T18:02:12.445126: step 1646, loss 0.211356, acc 0.9375, learning_rate 0.00136098\n","2023-06-27T18:02:12.624945: step 1647, loss 0.277398, acc 0.875, learning_rate 0.00136011\n","2023-06-27T18:02:12.799030: step 1648, loss 0.222223, acc 0.875, learning_rate 0.00135925\n","2023-06-27T18:02:12.966757: step 1649, loss 0.344599, acc 0.875, learning_rate 0.00135839\n","2023-06-27T18:02:13.138066: step 1650, loss 0.321145, acc 0.875, learning_rate 0.00135752\n","2023-06-27T18:02:13.323764: step 1651, loss 0.156776, acc 0.96875, learning_rate 0.00135666\n","2023-06-27T18:02:13.513433: step 1652, loss 0.22168, acc 0.90625, learning_rate 0.0013558\n","2023-06-27T18:02:13.698698: step 1653, loss 0.155373, acc 0.96875, learning_rate 0.00135494\n","2023-06-27T18:02:13.877487: step 1654, loss 0.284143, acc 0.90625, learning_rate 0.00135408\n","2023-06-27T18:02:14.054350: step 1655, loss 0.185342, acc 0.9375, learning_rate 0.00135322\n","2023-06-27T18:02:14.216515: step 1656, loss 0.170129, acc 0.9375, learning_rate 0.00135236\n","2023-06-27T18:02:14.397614: step 1657, loss 0.107271, acc 1, learning_rate 0.0013515\n","2023-06-27T18:02:14.582636: step 1658, loss 0.278826, acc 0.84375, learning_rate 0.00135064\n","2023-06-27T18:02:14.772560: step 1659, loss 0.366918, acc 0.90625, learning_rate 0.00134978\n","2023-06-27T18:02:14.907041: step 1660, loss 0.214807, acc 0.90625, learning_rate 0.00134893\n","2023-06-27T18:02:15.040917: step 1661, loss 0.156714, acc 0.90625, learning_rate 0.00134807\n","2023-06-27T18:02:15.157351: step 1662, loss 0.173774, acc 0.90625, learning_rate 0.00134721\n","2023-06-27T18:02:15.271229: step 1663, loss 0.160189, acc 0.90625, learning_rate 0.00134636\n","2023-06-27T18:02:15.388261: step 1664, loss 0.298985, acc 0.96875, learning_rate 0.0013455\n","2023-06-27T18:02:15.509321: step 1665, loss 0.279865, acc 0.84375, learning_rate 0.00134465\n","2023-06-27T18:02:15.623565: step 1666, loss 0.210059, acc 0.9375, learning_rate 0.0013438\n","2023-06-27T18:02:15.739782: step 1667, loss 0.365904, acc 0.8125, learning_rate 0.00134294\n","2023-06-27T18:02:15.860614: step 1668, loss 0.299372, acc 0.90625, learning_rate 0.00134209\n","2023-06-27T18:02:15.982546: step 1669, loss 0.265986, acc 0.9375, learning_rate 0.00134124\n","2023-06-27T18:02:16.118617: step 1670, loss 0.26878, acc 0.84375, learning_rate 0.00134039\n","2023-06-27T18:02:16.234233: step 1671, loss 0.277543, acc 0.9375, learning_rate 0.00133954\n","2023-06-27T18:02:16.348011: step 1672, loss 0.195804, acc 0.9375, learning_rate 0.00133869\n","2023-06-27T18:02:16.475090: step 1673, loss 0.251735, acc 0.9375, learning_rate 0.00133784\n","2023-06-27T18:02:16.592782: step 1674, loss 0.277014, acc 0.8125, learning_rate 0.00133699\n","2023-06-27T18:02:16.712242: step 1675, loss 0.226038, acc 0.90625, learning_rate 0.00133614\n","2023-06-27T18:02:16.829649: step 1676, loss 0.0935879, acc 0.96875, learning_rate 0.00133529\n","2023-06-27T18:02:16.940630: step 1677, loss 0.133276, acc 0.96875, learning_rate 0.00133445\n","2023-06-27T18:02:17.065956: step 1678, loss 0.428365, acc 0.84375, learning_rate 0.0013336\n","2023-06-27T18:02:17.183067: step 1679, loss 0.317743, acc 0.84375, learning_rate 0.00133275\n","2023-06-27T18:02:17.303001: step 1680, loss 0.316224, acc 0.90625, learning_rate 0.00133191\n","2023-06-27T18:02:17.435654: step 1681, loss 0.214697, acc 0.90625, learning_rate 0.00133106\n","2023-06-27T18:02:17.570358: step 1682, loss 0.246311, acc 0.96875, learning_rate 0.00133022\n","2023-06-27T18:02:17.686143: step 1683, loss 0.803799, acc 0.78125, learning_rate 0.00132938\n","2023-06-27T18:02:17.810404: step 1684, loss 0.271479, acc 0.96875, learning_rate 0.00132853\n","2023-06-27T18:02:17.928934: step 1685, loss 0.432084, acc 0.84375, learning_rate 0.00132769\n","2023-06-27T18:02:18.055011: step 1686, loss 0.230009, acc 0.9375, learning_rate 0.00132685\n","2023-06-27T18:02:18.166430: step 1687, loss 0.556318, acc 0.84375, learning_rate 0.00132601\n","2023-06-27T18:02:18.285154: step 1688, loss 0.185169, acc 0.9375, learning_rate 0.00132517\n","2023-06-27T18:02:18.398938: step 1689, loss 0.192428, acc 0.90625, learning_rate 0.00132433\n","2023-06-27T18:02:18.513787: step 1690, loss 0.421011, acc 0.78125, learning_rate 0.00132349\n","2023-06-27T18:02:18.636083: step 1691, loss 0.257881, acc 0.9375, learning_rate 0.00132265\n","2023-06-27T18:02:18.754177: step 1692, loss 0.382196, acc 0.84375, learning_rate 0.00132181\n","2023-06-27T18:02:18.871023: step 1693, loss 0.267155, acc 0.875, learning_rate 0.00132097\n","2023-06-27T18:02:18.986435: step 1694, loss 0.152465, acc 0.9375, learning_rate 0.00132014\n","2023-06-27T18:02:19.109082: step 1695, loss 0.338873, acc 0.90625, learning_rate 0.0013193\n","2023-06-27T18:02:19.219521: step 1696, loss 0.224946, acc 0.96875, learning_rate 0.00131846\n","2023-06-27T18:02:19.349261: step 1697, loss 0.355739, acc 0.84375, learning_rate 0.00131763\n","2023-06-27T18:02:19.461544: step 1698, loss 0.230645, acc 0.96875, learning_rate 0.00131679\n","2023-06-27T18:02:19.574316: step 1699, loss 0.292032, acc 0.875, learning_rate 0.00131596\n","\n","Evaluation:\n","2023-06-27T18:02:20.319744: step 1700, loss 0.567385, acc 0.798456\n","\n","Saved model checkpoint to /content/gdrive/MyDrive/lightweighted-cnn/train/runs/1687888658/checkpoints/model-1700\n","\n","2023-06-27T18:02:20.555531: step 1700, loss 0.353833, acc 0.8125, learning_rate 0.00131512\n","2023-06-27T18:02:20.673078: step 1701, loss 0.41027, acc 0.84375, learning_rate 0.00131429\n","2023-06-27T18:02:20.790291: step 1702, loss 0.136975, acc 0.9375, learning_rate 0.00131346\n","2023-06-27T18:02:20.913723: step 1703, loss 0.246815, acc 0.90625, learning_rate 0.00131263\n","2023-06-27T18:02:21.026816: step 1704, loss 0.0899811, acc 0.96875, learning_rate 0.00131179\n","2023-06-27T18:02:21.143770: step 1705, loss 0.100325, acc 0.96875, learning_rate 0.00131096\n","2023-06-27T18:02:21.266768: step 1706, loss 0.130993, acc 0.96875, learning_rate 0.00131013\n","2023-06-27T18:02:21.387104: step 1707, loss 0.241478, acc 0.90625, learning_rate 0.0013093\n","2023-06-27T18:02:21.497920: step 1708, loss 0.162874, acc 0.9375, learning_rate 0.00130847\n","2023-06-27T18:02:21.614961: step 1709, loss 0.388063, acc 0.9375, learning_rate 0.00130764\n","2023-06-27T18:02:21.727728: step 1710, loss 0.241544, acc 0.90625, learning_rate 0.00130682\n","2023-06-27T18:02:21.847505: step 1711, loss 0.230187, acc 0.84375, learning_rate 0.00130599\n","2023-06-27T18:02:21.973623: step 1712, loss 0.134011, acc 0.9375, learning_rate 0.00130516\n","2023-06-27T18:02:22.087595: step 1713, loss 0.391941, acc 0.8125, learning_rate 0.00130434\n","2023-06-27T18:02:22.241627: step 1714, loss 0.0618002, acc 1, learning_rate 0.00130351\n","2023-06-27T18:02:22.361637: step 1715, loss 0.1534, acc 0.9375, learning_rate 0.00130268\n","2023-06-27T18:02:22.481220: step 1716, loss 0.313073, acc 0.84375, learning_rate 0.00130186\n","2023-06-27T18:02:22.598781: step 1717, loss 0.140649, acc 0.96875, learning_rate 0.00130104\n","2023-06-27T18:02:22.720982: step 1718, loss 0.144942, acc 0.9375, learning_rate 0.00130021\n","2023-06-27T18:02:22.839153: step 1719, loss 0.174027, acc 0.9375, learning_rate 0.00129939\n","2023-06-27T18:02:22.948151: step 1720, loss 0.224709, acc 0.9375, learning_rate 0.00129857\n","2023-06-27T18:02:23.064592: step 1721, loss 0.441133, acc 0.84375, learning_rate 0.00129775\n","2023-06-27T18:02:23.182791: step 1722, loss 0.137955, acc 0.90625, learning_rate 0.00129692\n","2023-06-27T18:02:23.307829: step 1723, loss 0.241249, acc 0.9375, learning_rate 0.0012961\n","2023-06-27T18:02:23.429750: step 1724, loss 0.329871, acc 0.9375, learning_rate 0.00129528\n","2023-06-27T18:02:23.546395: step 1725, loss 0.168743, acc 0.9375, learning_rate 0.00129446\n","2023-06-27T18:02:23.668450: step 1726, loss 0.280877, acc 0.84375, learning_rate 0.00129364\n","2023-06-27T18:02:23.785772: step 1727, loss 0.20676, acc 0.96875, learning_rate 0.00129283\n","2023-06-27T18:02:23.903284: step 1728, loss 0.16013, acc 0.9375, learning_rate 0.00129201\n","2023-06-27T18:02:24.025593: step 1729, loss 0.172435, acc 0.90625, learning_rate 0.00129119\n","2023-06-27T18:02:24.138314: step 1730, loss 0.297617, acc 0.90625, learning_rate 0.00129037\n","2023-06-27T18:02:24.265803: step 1731, loss 0.445138, acc 0.75, learning_rate 0.00128956\n","2023-06-27T18:02:24.385620: step 1732, loss 0.181524, acc 0.90625, learning_rate 0.00128874\n","2023-06-27T18:02:24.517012: step 1733, loss 0.115777, acc 0.96875, learning_rate 0.00128793\n","2023-06-27T18:02:24.633980: step 1734, loss 0.20571, acc 0.90625, learning_rate 0.00128711\n","2023-06-27T18:02:24.750871: step 1735, loss 0.127668, acc 1, learning_rate 0.0012863\n","2023-06-27T18:02:24.902010: step 1736, loss 0.167267, acc 0.9375, learning_rate 0.00128548\n","2023-06-27T18:02:25.085744: step 1737, loss 0.251264, acc 0.9375, learning_rate 0.00128467\n","2023-06-27T18:02:25.302842: step 1738, loss 0.342414, acc 0.90625, learning_rate 0.00128386\n","2023-06-27T18:02:25.496832: step 1739, loss 0.212282, acc 0.90625, learning_rate 0.00128305\n","2023-06-27T18:02:25.693850: step 1740, loss 0.0774364, acc 0.96875, learning_rate 0.00128224\n","2023-06-27T18:02:25.896413: step 1741, loss 0.21163, acc 0.9375, learning_rate 0.00128143\n","2023-06-27T18:02:26.092743: step 1742, loss 0.256535, acc 0.90625, learning_rate 0.00128062\n","2023-06-27T18:02:26.291536: step 1743, loss 0.172363, acc 0.9375, learning_rate 0.00127981\n","2023-06-27T18:02:26.503147: step 1744, loss 0.285374, acc 0.90625, learning_rate 0.001279\n","2023-06-27T18:02:26.691451: step 1745, loss 0.101625, acc 1, learning_rate 0.00127819\n","2023-06-27T18:02:26.884756: step 1746, loss 0.185283, acc 0.9375, learning_rate 0.00127738\n","2023-06-27T18:02:27.085391: step 1747, loss 0.121315, acc 0.96875, learning_rate 0.00127657\n","2023-06-27T18:02:27.272116: step 1748, loss 0.509891, acc 0.8125, learning_rate 0.00127577\n","2023-06-27T18:02:27.474275: step 1749, loss 0.292598, acc 0.9375, learning_rate 0.00127496\n","2023-06-27T18:02:27.674528: step 1750, loss 0.102703, acc 0.96875, learning_rate 0.00127415\n","2023-06-27T18:02:27.812333: step 1751, loss 0.016363, acc 1, learning_rate 0.00127335\n","2023-06-27T18:02:28.029097: step 1752, loss 0.280441, acc 0.90625, learning_rate 0.00127254\n","2023-06-27T18:02:28.219678: step 1753, loss 0.164951, acc 0.9375, learning_rate 0.00127174\n","2023-06-27T18:02:28.433159: step 1754, loss 0.0849967, acc 0.96875, learning_rate 0.00127094\n","2023-06-27T18:02:28.631671: step 1755, loss 0.351448, acc 0.875, learning_rate 0.00127013\n","2023-06-27T18:02:28.833390: step 1756, loss 0.154044, acc 0.9375, learning_rate 0.00126933\n","2023-06-27T18:02:29.019352: step 1757, loss 0.113334, acc 0.96875, learning_rate 0.00126853\n","2023-06-27T18:02:29.209684: step 1758, loss 0.116808, acc 0.96875, learning_rate 0.00126773\n","2023-06-27T18:02:29.398749: step 1759, loss 0.115002, acc 0.96875, learning_rate 0.00126693\n","2023-06-27T18:02:29.583924: step 1760, loss 0.144773, acc 0.96875, learning_rate 0.00126613\n","2023-06-27T18:02:29.765360: step 1761, loss 0.122993, acc 0.96875, learning_rate 0.00126533\n","2023-06-27T18:02:29.954978: step 1762, loss 0.122718, acc 1, learning_rate 0.00126453\n","2023-06-27T18:02:30.172704: step 1763, loss 0.106497, acc 0.96875, learning_rate 0.00126373\n","2023-06-27T18:02:30.382546: step 1764, loss 0.214095, acc 0.9375, learning_rate 0.00126293\n","2023-06-27T18:02:30.546856: step 1765, loss 0.188206, acc 0.875, learning_rate 0.00126213\n","2023-06-27T18:02:30.738322: step 1766, loss 0.170379, acc 0.9375, learning_rate 0.00126134\n","2023-06-27T18:02:30.925732: step 1767, loss 0.0947689, acc 0.96875, learning_rate 0.00126054\n","2023-06-27T18:02:31.104956: step 1768, loss 0.114931, acc 0.96875, learning_rate 0.00125975\n","2023-06-27T18:02:31.290744: step 1769, loss 0.0660626, acc 1, learning_rate 0.00125895\n","2023-06-27T18:02:31.505002: step 1770, loss 0.0347765, acc 1, learning_rate 0.00125816\n","2023-06-27T18:02:31.691478: step 1771, loss 0.0978317, acc 1, learning_rate 0.00125736\n","2023-06-27T18:02:31.888462: step 1772, loss 0.19462, acc 0.90625, learning_rate 0.00125657\n","2023-06-27T18:02:32.063589: step 1773, loss 0.158857, acc 0.875, learning_rate 0.00125577\n","2023-06-27T18:02:32.251937: step 1774, loss 0.0795266, acc 1, learning_rate 0.00125498\n","2023-06-27T18:02:32.433582: step 1775, loss 0.0841963, acc 0.96875, learning_rate 0.00125419\n","2023-06-27T18:02:32.643115: step 1776, loss 0.151397, acc 0.9375, learning_rate 0.0012534\n","2023-06-27T18:02:32.826763: step 1777, loss 0.29685, acc 0.90625, learning_rate 0.00125261\n","2023-06-27T18:02:33.042993: step 1778, loss 0.0654671, acc 1, learning_rate 0.00125182\n","2023-06-27T18:02:33.219140: step 1779, loss 0.203412, acc 0.9375, learning_rate 0.00125103\n","2023-06-27T18:02:33.412371: step 1780, loss 0.216573, acc 0.9375, learning_rate 0.00125024\n","2023-06-27T18:02:33.606536: step 1781, loss 0.195085, acc 0.90625, learning_rate 0.00124945\n","2023-06-27T18:02:33.795050: step 1782, loss 0.115717, acc 0.96875, learning_rate 0.00124866\n","2023-06-27T18:02:33.989472: step 1783, loss 0.170826, acc 0.90625, learning_rate 0.00124787\n","2023-06-27T18:02:34.182604: step 1784, loss 0.0796855, acc 1, learning_rate 0.00124709\n","2023-06-27T18:02:34.381368: step 1785, loss 0.120948, acc 0.96875, learning_rate 0.0012463\n","2023-06-27T18:02:34.570568: step 1786, loss 0.172441, acc 0.9375, learning_rate 0.00124551\n","2023-06-27T18:02:34.766140: step 1787, loss 0.0411988, acc 1, learning_rate 0.00124473\n","2023-06-27T18:02:34.977238: step 1788, loss 0.227964, acc 0.90625, learning_rate 0.00124394\n","2023-06-27T18:02:35.177457: step 1789, loss 0.0970162, acc 1, learning_rate 0.00124316\n","2023-06-27T18:02:35.376490: step 1790, loss 0.229292, acc 0.90625, learning_rate 0.00124238\n","2023-06-27T18:02:35.513451: step 1791, loss 0.269451, acc 0.78125, learning_rate 0.00124159\n","2023-06-27T18:02:35.638142: step 1792, loss 0.175883, acc 0.90625, learning_rate 0.00124081\n","2023-06-27T18:02:35.769131: step 1793, loss 0.142441, acc 0.90625, learning_rate 0.00124003\n","2023-06-27T18:02:35.892954: step 1794, loss 0.164436, acc 0.9375, learning_rate 0.00123924\n","2023-06-27T18:02:36.004372: step 1795, loss 0.237339, acc 0.875, learning_rate 0.00123846\n","2023-06-27T18:02:36.116866: step 1796, loss 0.111221, acc 0.9375, learning_rate 0.00123768\n","2023-06-27T18:02:36.236899: step 1797, loss 0.10512, acc 0.96875, learning_rate 0.0012369\n","2023-06-27T18:02:36.354454: step 1798, loss 0.215375, acc 0.9375, learning_rate 0.00123612\n","2023-06-27T18:02:36.474705: step 1799, loss 0.157237, acc 0.9375, learning_rate 0.00123534\n","\n","Evaluation:\n","2023-06-27T18:02:37.236407: step 1800, loss 0.598213, acc 0.795669\n","\n","Saved model checkpoint to /content/gdrive/MyDrive/lightweighted-cnn/train/runs/1687888658/checkpoints/model-1800\n","\n","2023-06-27T18:02:37.490952: step 1800, loss 0.128202, acc 0.96875, learning_rate 0.00123457\n","2023-06-27T18:02:37.609304: step 1801, loss 0.332219, acc 0.8125, learning_rate 0.00123379\n","2023-06-27T18:02:37.729755: step 1802, loss 0.227059, acc 0.90625, learning_rate 0.00123301\n","2023-06-27T18:02:37.850564: step 1803, loss 0.133888, acc 1, learning_rate 0.00123223\n","2023-06-27T18:02:37.960732: step 1804, loss 0.112036, acc 0.96875, learning_rate 0.00123146\n","2023-06-27T18:02:38.073559: step 1805, loss 0.26299, acc 0.90625, learning_rate 0.00123068\n","2023-06-27T18:02:38.185370: step 1806, loss 0.105107, acc 0.96875, learning_rate 0.00122991\n","2023-06-27T18:02:38.304571: step 1807, loss 0.0551805, acc 1, learning_rate 0.00122913\n","2023-06-27T18:02:38.427665: step 1808, loss 0.0869742, acc 0.96875, learning_rate 0.00122836\n","2023-06-27T18:02:38.539150: step 1809, loss 0.197254, acc 0.96875, learning_rate 0.00122758\n","2023-06-27T18:02:38.658522: step 1810, loss 0.123416, acc 0.96875, learning_rate 0.00122681\n","2023-06-27T18:02:38.783271: step 1811, loss 0.269765, acc 0.9375, learning_rate 0.00122604\n","2023-06-27T18:02:38.908295: step 1812, loss 0.196779, acc 0.875, learning_rate 0.00122526\n","2023-06-27T18:02:39.017138: step 1813, loss 0.0644132, acc 0.96875, learning_rate 0.00122449\n","2023-06-27T18:02:39.129439: step 1814, loss 0.0752953, acc 1, learning_rate 0.00122372\n","2023-06-27T18:02:39.245194: step 1815, loss 0.142111, acc 0.96875, learning_rate 0.00122295\n","2023-06-27T18:02:39.362441: step 1816, loss 0.0676181, acc 0.96875, learning_rate 0.00122218\n","2023-06-27T18:02:39.487648: step 1817, loss 0.169857, acc 0.9375, learning_rate 0.00122141\n","2023-06-27T18:02:39.602217: step 1818, loss 0.139165, acc 0.96875, learning_rate 0.00122064\n","2023-06-27T18:02:39.720136: step 1819, loss 0.101521, acc 0.96875, learning_rate 0.00121987\n","2023-06-27T18:02:39.853809: step 1820, loss 0.167157, acc 0.96875, learning_rate 0.00121911\n","2023-06-27T18:02:39.967244: step 1821, loss 0.0493985, acc 0.96875, learning_rate 0.00121834\n","2023-06-27T18:02:40.095732: step 1822, loss 0.167406, acc 0.96875, learning_rate 0.00121757\n","2023-06-27T18:02:40.218738: step 1823, loss 0.187667, acc 0.9375, learning_rate 0.00121681\n","2023-06-27T18:02:40.335297: step 1824, loss 0.0874016, acc 0.96875, learning_rate 0.00121604\n","2023-06-27T18:02:40.455052: step 1825, loss 0.136678, acc 0.96875, learning_rate 0.00121527\n","2023-06-27T18:02:40.570484: step 1826, loss 0.159218, acc 0.9375, learning_rate 0.00121451\n","2023-06-27T18:02:40.704153: step 1827, loss 0.1084, acc 0.9375, learning_rate 0.00121375\n","2023-06-27T18:02:40.831521: step 1828, loss 0.0901587, acc 0.9375, learning_rate 0.00121298\n","2023-06-27T18:02:40.942285: step 1829, loss 0.114882, acc 0.96875, learning_rate 0.00121222\n","2023-06-27T18:02:41.059413: step 1830, loss 0.135765, acc 0.96875, learning_rate 0.00121146\n","2023-06-27T18:02:41.170661: step 1831, loss 0.0715422, acc 0.96875, learning_rate 0.00121069\n","2023-06-27T18:02:41.281886: step 1832, loss 0.138999, acc 0.96875, learning_rate 0.00120993\n","2023-06-27T18:02:41.396009: step 1833, loss 0.269763, acc 0.84375, learning_rate 0.00120917\n","2023-06-27T18:02:41.517869: step 1834, loss 0.151985, acc 0.9375, learning_rate 0.00120841\n","2023-06-27T18:02:41.631569: step 1835, loss 0.137734, acc 0.96875, learning_rate 0.00120765\n","2023-06-27T18:02:41.752030: step 1836, loss 0.126015, acc 0.96875, learning_rate 0.00120689\n","2023-06-27T18:02:41.878957: step 1837, loss 0.160252, acc 0.96875, learning_rate 0.00120613\n","2023-06-27T18:02:41.991851: step 1838, loss 0.115596, acc 0.9375, learning_rate 0.00120537\n","2023-06-27T18:02:42.111760: step 1839, loss 0.131498, acc 0.9375, learning_rate 0.00120462\n","2023-06-27T18:02:42.234936: step 1840, loss 0.165883, acc 0.90625, learning_rate 0.00120386\n","2023-06-27T18:02:42.351683: step 1841, loss 0.0709531, acc 0.96875, learning_rate 0.0012031\n","2023-06-27T18:02:42.468917: step 1842, loss 0.0929983, acc 0.9375, learning_rate 0.00120234\n","2023-06-27T18:02:42.587220: step 1843, loss 0.111297, acc 0.9375, learning_rate 0.00120159\n","2023-06-27T18:02:42.697142: step 1844, loss 0.133983, acc 0.96875, learning_rate 0.00120083\n","2023-06-27T18:02:42.827562: step 1845, loss 0.123726, acc 0.96875, learning_rate 0.00120008\n","2023-06-27T18:02:42.946371: step 1846, loss 0.159984, acc 0.9375, learning_rate 0.00119932\n","2023-06-27T18:02:43.061381: step 1847, loss 0.197457, acc 0.9375, learning_rate 0.00119857\n","2023-06-27T18:02:43.177247: step 1848, loss 0.162797, acc 0.9375, learning_rate 0.00119782\n","2023-06-27T18:02:43.289286: step 1849, loss 0.166689, acc 0.9375, learning_rate 0.00119706\n","2023-06-27T18:02:43.424116: step 1850, loss 0.118857, acc 0.96875, learning_rate 0.00119631\n","2023-06-27T18:02:43.540835: step 1851, loss 0.0923594, acc 0.9375, learning_rate 0.00119556\n","2023-06-27T18:02:43.677050: step 1852, loss 0.193082, acc 0.9375, learning_rate 0.00119481\n","2023-06-27T18:02:43.803169: step 1853, loss 0.227972, acc 0.875, learning_rate 0.00119406\n","2023-06-27T18:02:43.926908: step 1854, loss 0.140484, acc 0.96875, learning_rate 0.00119331\n","2023-06-27T18:02:44.043032: step 1855, loss 0.127951, acc 0.96875, learning_rate 0.00119256\n","2023-06-27T18:02:44.167098: step 1856, loss 0.165831, acc 0.90625, learning_rate 0.00119181\n","2023-06-27T18:02:44.282314: step 1857, loss 0.0825758, acc 0.96875, learning_rate 0.00119106\n","2023-06-27T18:02:44.406772: step 1858, loss 0.0813594, acc 0.96875, learning_rate 0.00119031\n","2023-06-27T18:02:44.519737: step 1859, loss 0.276587, acc 0.90625, learning_rate 0.00118956\n","2023-06-27T18:02:44.660969: step 1860, loss 0.118901, acc 0.9375, learning_rate 0.00118882\n","2023-06-27T18:02:44.788710: step 1861, loss 0.119384, acc 1, learning_rate 0.00118807\n","2023-06-27T18:02:44.901203: step 1862, loss 0.0426294, acc 1, learning_rate 0.00118732\n","2023-06-27T18:02:45.023474: step 1863, loss 0.129799, acc 0.9375, learning_rate 0.00118658\n","2023-06-27T18:02:45.161774: step 1864, loss 0.178396, acc 0.9375, learning_rate 0.00118583\n","2023-06-27T18:02:45.282302: step 1865, loss 0.104345, acc 0.96875, learning_rate 0.00118509\n","2023-06-27T18:02:45.399610: step 1866, loss 0.0319783, acc 1, learning_rate 0.00118435\n","2023-06-27T18:02:45.569498: step 1867, loss 0.347526, acc 0.875, learning_rate 0.0011836\n","2023-06-27T18:02:45.764535: step 1868, loss 0.208956, acc 0.90625, learning_rate 0.00118286\n","2023-06-27T18:02:45.988555: step 1869, loss 0.242289, acc 0.9375, learning_rate 0.00118212\n","2023-06-27T18:02:46.189229: step 1870, loss 0.18433, acc 0.9375, learning_rate 0.00118137\n","2023-06-27T18:02:46.390445: step 1871, loss 0.0797587, acc 0.96875, learning_rate 0.00118063\n","2023-06-27T18:02:46.574156: step 1872, loss 0.228364, acc 0.96875, learning_rate 0.00117989\n","2023-06-27T18:02:46.770680: step 1873, loss 0.151695, acc 0.9375, learning_rate 0.00117915\n","2023-06-27T18:02:46.945531: step 1874, loss 0.092589, acc 0.96875, learning_rate 0.00117841\n","2023-06-27T18:02:47.141115: step 1875, loss 0.0574895, acc 1, learning_rate 0.00117767\n","2023-06-27T18:02:47.326917: step 1876, loss 0.156795, acc 0.9375, learning_rate 0.00117693\n","2023-06-27T18:02:47.538760: step 1877, loss 0.0514094, acc 1, learning_rate 0.00117619\n","2023-06-27T18:02:47.729600: step 1878, loss 0.205155, acc 0.90625, learning_rate 0.00117546\n","2023-06-27T18:02:47.928749: step 1879, loss 0.0345596, acc 1, learning_rate 0.00117472\n","2023-06-27T18:02:48.121210: step 1880, loss 0.297241, acc 0.84375, learning_rate 0.00117398\n","2023-06-27T18:02:48.318076: step 1881, loss 0.100274, acc 0.96875, learning_rate 0.00117325\n","2023-06-27T18:02:48.534911: step 1882, loss 0.149814, acc 0.9375, learning_rate 0.00117251\n","2023-06-27T18:02:48.735839: step 1883, loss 0.213466, acc 0.9375, learning_rate 0.00117177\n","2023-06-27T18:02:48.937096: step 1884, loss 0.129166, acc 0.9375, learning_rate 0.00117104\n","2023-06-27T18:02:49.147694: step 1885, loss 0.1947, acc 0.90625, learning_rate 0.0011703\n","2023-06-27T18:02:49.337082: step 1886, loss 0.102683, acc 0.96875, learning_rate 0.00116957\n","2023-06-27T18:02:49.511666: step 1887, loss 0.117087, acc 0.96875, learning_rate 0.00116884\n","2023-06-27T18:02:49.701796: step 1888, loss 0.138029, acc 0.90625, learning_rate 0.0011681\n","2023-06-27T18:02:49.878733: step 1889, loss 0.243342, acc 0.84375, learning_rate 0.00116737\n","2023-06-27T18:02:50.059295: step 1890, loss 0.0998777, acc 0.9375, learning_rate 0.00116664\n","2023-06-27T18:02:50.268833: step 1891, loss 0.240283, acc 0.875, learning_rate 0.00116591\n","2023-06-27T18:02:50.454040: step 1892, loss 0.0729726, acc 1, learning_rate 0.00116518\n","2023-06-27T18:02:50.656390: step 1893, loss 0.0895098, acc 1, learning_rate 0.00116445\n","2023-06-27T18:02:50.856693: step 1894, loss 0.217613, acc 0.90625, learning_rate 0.00116372\n","2023-06-27T18:02:51.042781: step 1895, loss 0.123445, acc 0.96875, learning_rate 0.00116299\n","2023-06-27T18:02:51.206888: step 1896, loss 0.0405804, acc 1, learning_rate 0.00116226\n","2023-06-27T18:02:51.411876: step 1897, loss 0.128434, acc 0.96875, learning_rate 0.00116153\n","2023-06-27T18:02:51.604832: step 1898, loss 0.0429949, acc 1, learning_rate 0.0011608\n","2023-06-27T18:02:51.817094: step 1899, loss 0.20098, acc 0.90625, learning_rate 0.00116008\n","\n","Evaluation:\n","2023-06-27T18:02:53.181139: step 1900, loss 0.610179, acc 0.801244\n","\n","Saved model checkpoint to /content/gdrive/MyDrive/lightweighted-cnn/train/runs/1687888658/checkpoints/model-1900\n","\n","2023-06-27T18:02:53.471384: step 1900, loss 0.164732, acc 0.9375, learning_rate 0.00115935\n","2023-06-27T18:02:53.660146: step 1901, loss 0.0969337, acc 0.9375, learning_rate 0.00115862\n","2023-06-27T18:02:53.851321: step 1902, loss 0.0856417, acc 0.96875, learning_rate 0.0011579\n","2023-06-27T18:02:54.030762: step 1903, loss 0.226922, acc 0.9375, learning_rate 0.00115717\n","2023-06-27T18:02:54.243862: step 1904, loss 0.0569597, acc 1, learning_rate 0.00115645\n","2023-06-27T18:02:54.418429: step 1905, loss 0.0538528, acc 1, learning_rate 0.00115572\n","2023-06-27T18:02:54.608339: step 1906, loss 0.14805, acc 0.9375, learning_rate 0.001155\n","2023-06-27T18:02:54.781207: step 1907, loss 0.0329789, acc 1, learning_rate 0.00115427\n","2023-06-27T18:02:54.981530: step 1908, loss 0.286253, acc 0.84375, learning_rate 0.00115355\n","2023-06-27T18:02:55.182928: step 1909, loss 0.106104, acc 0.96875, learning_rate 0.00115283\n","2023-06-27T18:02:55.390540: step 1910, loss 0.110993, acc 0.96875, learning_rate 0.00115211\n","2023-06-27T18:02:55.580272: step 1911, loss 0.235428, acc 0.9375, learning_rate 0.00115139\n","2023-06-27T18:02:55.772453: step 1912, loss 0.0462618, acc 1, learning_rate 0.00115066\n","2023-06-27T18:02:55.965485: step 1913, loss 0.221963, acc 0.9375, learning_rate 0.00114994\n","2023-06-27T18:02:56.131711: step 1914, loss 0.0912769, acc 0.9375, learning_rate 0.00114922\n","2023-06-27T18:02:56.276811: step 1915, loss 0.154369, acc 0.90625, learning_rate 0.0011485\n","2023-06-27T18:02:56.397866: step 1916, loss 0.260731, acc 0.90625, learning_rate 0.00114779\n","2023-06-27T18:02:56.525675: step 1917, loss 0.130659, acc 0.96875, learning_rate 0.00114707\n","2023-06-27T18:02:56.640277: step 1918, loss 0.0944777, acc 0.96875, learning_rate 0.00114635\n","2023-06-27T18:02:56.759408: step 1919, loss 0.139455, acc 0.96875, learning_rate 0.00114563\n","2023-06-27T18:02:56.890300: step 1920, loss 0.145866, acc 0.90625, learning_rate 0.00114491\n","2023-06-27T18:02:57.009759: step 1921, loss 0.0716696, acc 0.96875, learning_rate 0.0011442\n","2023-06-27T18:02:57.121607: step 1922, loss 0.225657, acc 0.90625, learning_rate 0.00114348\n","2023-06-27T18:02:57.253950: step 1923, loss 0.235086, acc 0.9375, learning_rate 0.00114277\n","2023-06-27T18:02:57.371380: step 1924, loss 0.105236, acc 1, learning_rate 0.00114205\n","2023-06-27T18:02:57.493593: step 1925, loss 0.104449, acc 0.96875, learning_rate 0.00114134\n","2023-06-27T18:02:57.621592: step 1926, loss 0.107716, acc 0.96875, learning_rate 0.00114062\n","2023-06-27T18:02:57.735619: step 1927, loss 0.177419, acc 0.9375, learning_rate 0.00113991\n","2023-06-27T18:02:57.880984: step 1928, loss 0.286255, acc 0.9375, learning_rate 0.0011392\n","2023-06-27T18:02:57.993155: step 1929, loss 0.0783279, acc 1, learning_rate 0.00113848\n","2023-06-27T18:02:58.117021: step 1930, loss 0.198377, acc 0.90625, learning_rate 0.00113777\n","2023-06-27T18:02:58.244649: step 1931, loss 0.112011, acc 0.9375, learning_rate 0.00113706\n","2023-06-27T18:02:58.377247: step 1932, loss 0.0937246, acc 0.96875, learning_rate 0.00113635\n","2023-06-27T18:02:58.518879: step 1933, loss 0.0817167, acc 0.96875, learning_rate 0.00113564\n","2023-06-27T18:02:58.650215: step 1934, loss 0.0903541, acc 0.9375, learning_rate 0.00113493\n","2023-06-27T18:02:58.771706: step 1935, loss 0.141016, acc 0.9375, learning_rate 0.00113422\n","2023-06-27T18:02:58.899630: step 1936, loss 0.0924357, acc 0.96875, learning_rate 0.00113351\n","2023-06-27T18:02:59.024698: step 1937, loss 0.128131, acc 0.9375, learning_rate 0.0011328\n","2023-06-27T18:02:59.140081: step 1938, loss 0.283694, acc 0.90625, learning_rate 0.00113209\n","2023-06-27T18:02:59.264665: step 1939, loss 0.298633, acc 0.84375, learning_rate 0.00113138\n","2023-06-27T18:02:59.374508: step 1940, loss 0.135723, acc 0.96875, learning_rate 0.00113068\n","2023-06-27T18:02:59.495481: step 1941, loss 0.210425, acc 0.875, learning_rate 0.00112997\n","2023-06-27T18:02:59.618779: step 1942, loss 0.0314932, acc 1, learning_rate 0.00112926\n","2023-06-27T18:02:59.745158: step 1943, loss 0.056594, acc 0.96875, learning_rate 0.00112856\n","2023-06-27T18:02:59.878091: step 1944, loss 0.132986, acc 0.9375, learning_rate 0.00112785\n","2023-06-27T18:02:59.994643: step 1945, loss 0.198215, acc 0.96875, learning_rate 0.00112715\n","2023-06-27T18:03:00.166449: step 1946, loss 0.29946, acc 0.90625, learning_rate 0.00112644\n","2023-06-27T18:03:00.292899: step 1947, loss 0.136864, acc 0.96875, learning_rate 0.00112574\n","2023-06-27T18:03:00.409477: step 1948, loss 0.303882, acc 0.90625, learning_rate 0.00112504\n","2023-06-27T18:03:00.545709: step 1949, loss 0.104419, acc 1, learning_rate 0.00112433\n","2023-06-27T18:03:00.660428: step 1950, loss 0.197555, acc 0.9375, learning_rate 0.00112363\n","2023-06-27T18:03:00.784268: step 1951, loss 0.185211, acc 0.9375, learning_rate 0.00112293\n","2023-06-27T18:03:00.904327: step 1952, loss 0.19387, acc 0.9375, learning_rate 0.00112223\n","2023-06-27T18:03:01.020834: step 1953, loss 0.182768, acc 0.90625, learning_rate 0.00112153\n","2023-06-27T18:03:01.143469: step 1954, loss 0.236403, acc 0.90625, learning_rate 0.00112083\n","2023-06-27T18:03:01.263147: step 1955, loss 0.080696, acc 0.96875, learning_rate 0.00112013\n","2023-06-27T18:03:01.386787: step 1956, loss 0.107123, acc 0.96875, learning_rate 0.00111943\n","2023-06-27T18:03:01.514463: step 1957, loss 0.139349, acc 0.9375, learning_rate 0.00111873\n","2023-06-27T18:03:01.639212: step 1958, loss 0.177735, acc 0.90625, learning_rate 0.00111803\n","2023-06-27T18:03:01.770539: step 1959, loss 0.179249, acc 0.9375, learning_rate 0.00111733\n","2023-06-27T18:03:01.893387: step 1960, loss 0.235289, acc 0.84375, learning_rate 0.00111663\n","2023-06-27T18:03:02.016198: step 1961, loss 0.144006, acc 0.9375, learning_rate 0.00111594\n","2023-06-27T18:03:02.163095: step 1962, loss 0.0933838, acc 0.96875, learning_rate 0.00111524\n","2023-06-27T18:03:02.286700: step 1963, loss 0.195655, acc 0.90625, learning_rate 0.00111454\n","2023-06-27T18:03:02.402867: step 1964, loss 0.248302, acc 0.875, learning_rate 0.00111385\n","2023-06-27T18:03:02.535583: step 1965, loss 0.0816314, acc 0.96875, learning_rate 0.00111315\n","2023-06-27T18:03:02.646028: step 1966, loss 0.164621, acc 0.875, learning_rate 0.00111246\n","2023-06-27T18:03:02.787298: step 1967, loss 0.141967, acc 0.9375, learning_rate 0.00111176\n","2023-06-27T18:03:02.906315: step 1968, loss 0.266298, acc 0.9375, learning_rate 0.00111107\n","2023-06-27T18:03:03.026909: step 1969, loss 0.0957835, acc 1, learning_rate 0.00111038\n","2023-06-27T18:03:03.150871: step 1970, loss 0.320136, acc 0.84375, learning_rate 0.00110968\n","2023-06-27T18:03:03.267780: step 1971, loss 0.183366, acc 0.9375, learning_rate 0.00110899\n","2023-06-27T18:03:03.400549: step 1972, loss 0.108131, acc 0.96875, learning_rate 0.0011083\n","2023-06-27T18:03:03.526043: step 1973, loss 0.146318, acc 0.90625, learning_rate 0.00110761\n","2023-06-27T18:03:03.644547: step 1974, loss 0.358832, acc 0.875, learning_rate 0.00110692\n","2023-06-27T18:03:03.763031: step 1975, loss 0.0443448, acc 1, learning_rate 0.00110623\n","2023-06-27T18:03:03.892437: step 1976, loss 0.273851, acc 0.9375, learning_rate 0.00110554\n","2023-06-27T18:03:04.033024: step 1977, loss 0.143394, acc 0.96875, learning_rate 0.00110485\n","2023-06-27T18:03:04.144179: step 1978, loss 0.210436, acc 0.96875, learning_rate 0.00110416\n","2023-06-27T18:03:04.267917: step 1979, loss 0.113429, acc 0.9375, learning_rate 0.00110347\n","2023-06-27T18:03:04.397482: step 1980, loss 0.133282, acc 0.9375, learning_rate 0.00110278\n","2023-06-27T18:03:04.533174: step 1981, loss 0.115521, acc 0.9375, learning_rate 0.00110209\n","2023-06-27T18:03:04.669040: step 1982, loss 0.056305, acc 1, learning_rate 0.00110141\n","2023-06-27T18:03:04.794702: step 1983, loss 0.154922, acc 0.9375, learning_rate 0.00110072\n","2023-06-27T18:03:04.933423: step 1984, loss 0.0730185, acc 1, learning_rate 0.00110003\n","2023-06-27T18:03:05.045546: step 1985, loss 0.186644, acc 0.9375, learning_rate 0.00109935\n","2023-06-27T18:03:05.173424: step 1986, loss 0.152864, acc 0.9375, learning_rate 0.00109866\n","2023-06-27T18:03:05.297123: step 1987, loss 0.270126, acc 0.9375, learning_rate 0.00109798\n","2023-06-27T18:03:05.438874: step 1988, loss 0.128693, acc 0.96875, learning_rate 0.00109729\n","2023-06-27T18:03:05.568686: step 1989, loss 0.0243907, acc 1, learning_rate 0.00109661\n","2023-06-27T18:03:05.696901: step 1990, loss 0.146713, acc 0.9375, learning_rate 0.00109593\n","2023-06-27T18:03:05.831792: step 1991, loss 0.251872, acc 0.875, learning_rate 0.00109524\n","2023-06-27T18:03:05.953098: step 1992, loss 0.118194, acc 0.9375, learning_rate 0.00109456\n","2023-06-27T18:03:06.066620: step 1993, loss 0.176599, acc 0.9375, learning_rate 0.00109388\n","2023-06-27T18:03:06.193667: step 1994, loss 0.298191, acc 0.9375, learning_rate 0.0010932\n","2023-06-27T18:03:06.372801: step 1995, loss 0.0996023, acc 0.96875, learning_rate 0.00109252\n","2023-06-27T18:03:06.585720: step 1996, loss 0.0585519, acc 0.96875, learning_rate 0.00109184\n","2023-06-27T18:03:06.784975: step 1997, loss 0.0636402, acc 1, learning_rate 0.00109116\n","2023-06-27T18:03:06.974707: step 1998, loss 0.13205, acc 0.96875, learning_rate 0.00109048\n","2023-06-27T18:03:07.177643: step 1999, loss 0.0649226, acc 1, learning_rate 0.0010898\n","\n","Evaluation:\n","2023-06-27T18:03:08.551945: step 2000, loss 0.620475, acc 0.798027\n","\n","Saved model checkpoint to /content/gdrive/MyDrive/lightweighted-cnn/train/runs/1687888658/checkpoints/model-2000\n","\n","2023-06-27T18:03:08.909871: step 2000, loss 0.156664, acc 0.90625, learning_rate 0.00108912\n","2023-06-27T18:03:09.107978: step 2001, loss 0.0727156, acc 1, learning_rate 0.00108844\n","2023-06-27T18:03:09.317899: step 2002, loss 0.177614, acc 0.96875, learning_rate 0.00108776\n","2023-06-27T18:03:09.507169: step 2003, loss 0.0558823, acc 0.96875, learning_rate 0.00108708\n","2023-06-27T18:03:09.715458: step 2004, loss 0.115695, acc 0.96875, learning_rate 0.00108641\n","2023-06-27T18:03:09.909813: step 2005, loss 0.122221, acc 0.96875, learning_rate 0.00108573\n","2023-06-27T18:03:10.119354: step 2006, loss 0.151366, acc 0.9375, learning_rate 0.00108506\n","2023-06-27T18:03:10.318551: step 2007, loss 0.298811, acc 0.84375, learning_rate 0.00108438\n","2023-06-27T18:03:10.543125: step 2008, loss 0.145894, acc 0.90625, learning_rate 0.0010837\n","2023-06-27T18:03:10.727333: step 2009, loss 0.181548, acc 0.9375, learning_rate 0.00108303\n","2023-06-27T18:03:10.920395: step 2010, loss 0.240976, acc 0.90625, learning_rate 0.00108236\n","2023-06-27T18:03:11.115746: step 2011, loss 0.0703072, acc 0.96875, learning_rate 0.00108168\n","2023-06-27T18:03:11.300382: step 2012, loss 0.0716247, acc 0.96875, learning_rate 0.00108101\n","2023-06-27T18:03:11.479197: step 2013, loss 0.124878, acc 0.96875, learning_rate 0.00108034\n","2023-06-27T18:03:11.660427: step 2014, loss 0.124268, acc 0.9375, learning_rate 0.00107966\n","2023-06-27T18:03:11.849645: step 2015, loss 0.150322, acc 0.9375, learning_rate 0.00107899\n","2023-06-27T18:03:12.014920: step 2016, loss 0.0971159, acc 0.9375, learning_rate 0.00107832\n","2023-06-27T18:03:12.209260: step 2017, loss 0.294513, acc 0.9375, learning_rate 0.00107765\n","2023-06-27T18:03:12.401332: step 2018, loss 0.0843798, acc 0.9375, learning_rate 0.00107698\n","2023-06-27T18:03:12.595624: step 2019, loss 0.159348, acc 0.9375, learning_rate 0.00107631\n","2023-06-27T18:03:12.772555: step 2020, loss 0.231556, acc 0.90625, learning_rate 0.00107564\n","2023-06-27T18:03:12.978440: step 2021, loss 0.116062, acc 0.96875, learning_rate 0.00107497\n","2023-06-27T18:03:13.182270: step 2022, loss 0.12806, acc 0.9375, learning_rate 0.0010743\n","2023-06-27T18:03:13.385447: step 2023, loss 0.0668407, acc 0.96875, learning_rate 0.00107363\n","2023-06-27T18:03:13.562215: step 2024, loss 0.0774771, acc 1, learning_rate 0.00107297\n","2023-06-27T18:03:13.751162: step 2025, loss 0.0937723, acc 0.96875, learning_rate 0.0010723\n","2023-06-27T18:03:13.941628: step 2026, loss 0.0458569, acc 1, learning_rate 0.00107163\n","2023-06-27T18:03:14.122589: step 2027, loss 0.0664553, acc 0.96875, learning_rate 0.00107097\n","2023-06-27T18:03:14.332645: step 2028, loss 0.0728326, acc 1, learning_rate 0.0010703\n","2023-06-27T18:03:14.508456: step 2029, loss 0.141564, acc 0.96875, learning_rate 0.00106964\n","2023-06-27T18:03:14.710345: step 2030, loss 0.0472464, acc 1, learning_rate 0.00106897\n","2023-06-27T18:03:14.905194: step 2031, loss 0.169862, acc 0.90625, learning_rate 0.00106831\n","2023-06-27T18:03:15.138122: step 2032, loss 0.0801019, acc 1, learning_rate 0.00106764\n","2023-06-27T18:03:15.333404: step 2033, loss 0.0784986, acc 0.96875, learning_rate 0.00106698\n","2023-06-27T18:03:15.547580: step 2034, loss 0.0622558, acc 1, learning_rate 0.00106632\n","2023-06-27T18:03:15.754945: step 2035, loss 0.0748367, acc 0.96875, learning_rate 0.00106565\n","2023-06-27T18:03:15.956191: step 2036, loss 0.10445, acc 0.96875, learning_rate 0.00106499\n","2023-06-27T18:03:16.165607: step 2037, loss 0.1846, acc 0.96875, learning_rate 0.00106433\n","2023-06-27T18:03:16.382031: step 2038, loss 0.136082, acc 0.9375, learning_rate 0.00106367\n","2023-06-27T18:03:16.600996: step 2039, loss 0.203426, acc 0.9375, learning_rate 0.00106301\n","2023-06-27T18:03:16.783695: step 2040, loss 0.127676, acc 0.96875, learning_rate 0.00106235\n","2023-06-27T18:03:16.966849: step 2041, loss 0.0978288, acc 0.96875, learning_rate 0.00106169\n","2023-06-27T18:03:17.168361: step 2042, loss 0.274443, acc 0.90625, learning_rate 0.00106103\n","2023-06-27T18:03:17.327357: step 2043, loss 0.188482, acc 0.90625, learning_rate 0.00106037\n","2023-06-27T18:03:17.451672: step 2044, loss 0.144995, acc 0.96875, learning_rate 0.00105971\n","2023-06-27T18:03:17.568080: step 2045, loss 0.170124, acc 0.96875, learning_rate 0.00105905\n","2023-06-27T18:03:17.700777: step 2046, loss 0.130741, acc 0.90625, learning_rate 0.00105839\n","2023-06-27T18:03:17.812327: step 2047, loss 0.147864, acc 0.9375, learning_rate 0.00105774\n","2023-06-27T18:03:17.938123: step 2048, loss 0.139852, acc 0.9375, learning_rate 0.00105708\n","2023-06-27T18:03:18.067142: step 2049, loss 0.132922, acc 0.96875, learning_rate 0.00105642\n","2023-06-27T18:03:18.193500: step 2050, loss 0.0524491, acc 0.96875, learning_rate 0.00105577\n","2023-06-27T18:03:18.323816: step 2051, loss 0.0255625, acc 1, learning_rate 0.00105511\n","2023-06-27T18:03:18.439233: step 2052, loss 0.151813, acc 0.9375, learning_rate 0.00105446\n","2023-06-27T18:03:18.556972: step 2053, loss 0.133048, acc 0.96875, learning_rate 0.0010538\n","2023-06-27T18:03:18.687395: step 2054, loss 0.0975036, acc 0.96875, learning_rate 0.00105315\n","2023-06-27T18:03:18.807831: step 2055, loss 0.0635587, acc 1, learning_rate 0.0010525\n","2023-06-27T18:03:18.936596: step 2056, loss 0.130371, acc 0.96875, learning_rate 0.00105184\n","2023-06-27T18:03:19.066520: step 2057, loss 0.22131, acc 0.9375, learning_rate 0.00105119\n","2023-06-27T18:03:19.183130: step 2058, loss 0.109406, acc 0.96875, learning_rate 0.00105054\n","2023-06-27T18:03:19.301374: step 2059, loss 0.151388, acc 0.9375, learning_rate 0.00104989\n","2023-06-27T18:03:19.425117: step 2060, loss 0.227987, acc 0.90625, learning_rate 0.00104923\n","2023-06-27T18:03:19.546480: step 2061, loss 0.101039, acc 0.96875, learning_rate 0.00104858\n","2023-06-27T18:03:19.675190: step 2062, loss 0.0794454, acc 0.96875, learning_rate 0.00104793\n","2023-06-27T18:03:19.796267: step 2063, loss 0.106822, acc 0.96875, learning_rate 0.00104728\n","2023-06-27T18:03:19.924190: step 2064, loss 0.402123, acc 0.875, learning_rate 0.00104663\n","2023-06-27T18:03:20.050730: step 2065, loss 0.0851775, acc 0.96875, learning_rate 0.00104598\n","2023-06-27T18:03:20.175368: step 2066, loss 0.176639, acc 0.9375, learning_rate 0.00104534\n","2023-06-27T18:03:20.295581: step 2067, loss 0.174369, acc 0.9375, learning_rate 0.00104469\n","2023-06-27T18:03:20.409990: step 2068, loss 0.259772, acc 0.9375, learning_rate 0.00104404\n","2023-06-27T18:03:20.543707: step 2069, loss 0.0406165, acc 1, learning_rate 0.00104339\n","2023-06-27T18:03:20.667057: step 2070, loss 0.0644027, acc 1, learning_rate 0.00104275\n","2023-06-27T18:03:20.787912: step 2071, loss 0.171102, acc 0.9375, learning_rate 0.0010421\n","2023-06-27T18:03:20.915064: step 2072, loss 0.115908, acc 0.96875, learning_rate 0.00104145\n","2023-06-27T18:03:21.044625: step 2073, loss 0.39924, acc 0.875, learning_rate 0.00104081\n","2023-06-27T18:03:21.168719: step 2074, loss 0.143536, acc 0.90625, learning_rate 0.00104016\n","2023-06-27T18:03:21.281695: step 2075, loss 0.24963, acc 0.90625, learning_rate 0.00103952\n","2023-06-27T18:03:21.414078: step 2076, loss 0.259798, acc 0.90625, learning_rate 0.00103887\n","2023-06-27T18:03:21.530204: step 2077, loss 0.13157, acc 0.9375, learning_rate 0.00103823\n","2023-06-27T18:03:21.652177: step 2078, loss 0.248489, acc 0.90625, learning_rate 0.00103759\n","2023-06-27T18:03:21.777318: step 2079, loss 0.150762, acc 0.96875, learning_rate 0.00103694\n","2023-06-27T18:03:21.895141: step 2080, loss 0.0680076, acc 0.96875, learning_rate 0.0010363\n","2023-06-27T18:03:22.019157: step 2081, loss 0.329809, acc 0.78125, learning_rate 0.00103566\n","2023-06-27T18:03:22.156232: step 2082, loss 0.0559339, acc 0.96875, learning_rate 0.00103502\n","2023-06-27T18:03:22.283607: step 2083, loss 0.154234, acc 0.9375, learning_rate 0.00103438\n","2023-06-27T18:03:22.408127: step 2084, loss 0.107862, acc 0.96875, learning_rate 0.00103374\n","2023-06-27T18:03:22.527876: step 2085, loss 0.150306, acc 0.96875, learning_rate 0.00103309\n","2023-06-27T18:03:22.668947: step 2086, loss 0.169917, acc 0.9375, learning_rate 0.00103245\n","2023-06-27T18:03:22.784226: step 2087, loss 0.107859, acc 0.9375, learning_rate 0.00103182\n","2023-06-27T18:03:22.914681: step 2088, loss 0.140144, acc 1, learning_rate 0.00103118\n","2023-06-27T18:03:23.038251: step 2089, loss 0.195312, acc 0.9375, learning_rate 0.00103054\n","2023-06-27T18:03:23.175054: step 2090, loss 0.125819, acc 0.96875, learning_rate 0.0010299\n","2023-06-27T18:03:23.297370: step 2091, loss 0.324032, acc 0.9375, learning_rate 0.00102926\n","2023-06-27T18:03:23.417459: step 2092, loss 0.0915083, acc 0.96875, learning_rate 0.00102863\n","2023-06-27T18:03:23.533160: step 2093, loss 0.100367, acc 0.96875, learning_rate 0.00102799\n","2023-06-27T18:03:23.647436: step 2094, loss 0.131759, acc 0.9375, learning_rate 0.00102735\n","2023-06-27T18:03:23.782689: step 2095, loss 0.0907444, acc 1, learning_rate 0.00102672\n","2023-06-27T18:03:23.907415: step 2096, loss 0.297514, acc 0.84375, learning_rate 0.00102608\n","2023-06-27T18:03:24.018041: step 2097, loss 0.129171, acc 0.90625, learning_rate 0.00102545\n","2023-06-27T18:03:24.147244: step 2098, loss 0.158034, acc 0.90625, learning_rate 0.00102481\n","2023-06-27T18:03:24.262743: step 2099, loss 0.172293, acc 0.90625, learning_rate 0.00102418\n","\n","Evaluation:\n","2023-06-27T18:03:25.008617: step 2100, loss 0.624323, acc 0.808533\n","\n","Saved model checkpoint to /content/gdrive/MyDrive/lightweighted-cnn/train/runs/1687888658/checkpoints/model-2100\n","\n","2023-06-27T18:03:25.240880: step 2100, loss 0.18965, acc 0.875, learning_rate 0.00102354\n","2023-06-27T18:03:25.356096: step 2101, loss 0.213185, acc 0.90625, learning_rate 0.00102291\n","2023-06-27T18:03:25.469681: step 2102, loss 0.45643, acc 0.875, learning_rate 0.00102228\n","2023-06-27T18:03:25.593123: step 2103, loss 0.227761, acc 0.9375, learning_rate 0.00102164\n","2023-06-27T18:03:25.712716: step 2104, loss 0.075629, acc 0.9375, learning_rate 0.00102101\n","2023-06-27T18:03:25.825591: step 2105, loss 0.0368743, acc 1, learning_rate 0.00102038\n","2023-06-27T18:03:25.944146: step 2106, loss 0.190751, acc 0.90625, learning_rate 0.00101975\n","2023-06-27T18:03:26.055090: step 2107, loss 0.135282, acc 0.90625, learning_rate 0.00101912\n","2023-06-27T18:03:26.193176: step 2108, loss 0.118805, acc 0.9375, learning_rate 0.00101849\n","2023-06-27T18:03:26.313075: step 2109, loss 0.360088, acc 0.875, learning_rate 0.00101786\n","2023-06-27T18:03:26.447190: step 2110, loss 0.371491, acc 0.875, learning_rate 0.00101723\n","2023-06-27T18:03:26.587917: step 2111, loss 0.0938844, acc 0.9375, learning_rate 0.0010166\n","2023-06-27T18:03:26.710605: step 2112, loss 0.0478763, acc 0.96875, learning_rate 0.00101597\n","2023-06-27T18:03:26.841418: step 2113, loss 0.0752762, acc 1, learning_rate 0.00101534\n","2023-06-27T18:03:26.974139: step 2114, loss 0.431286, acc 0.875, learning_rate 0.00101472\n","2023-06-27T18:03:27.123244: step 2115, loss 0.134771, acc 0.96875, learning_rate 0.00101409\n","2023-06-27T18:03:27.256694: step 2116, loss 0.142593, acc 0.9375, learning_rate 0.00101346\n","2023-06-27T18:03:27.423899: step 2117, loss 0.193525, acc 0.90625, learning_rate 0.00101284\n","2023-06-27T18:03:27.606980: step 2118, loss 0.19413, acc 0.90625, learning_rate 0.00101221\n","2023-06-27T18:03:27.809005: step 2119, loss 0.0838859, acc 0.96875, learning_rate 0.00101158\n","2023-06-27T18:03:28.023048: step 2120, loss 0.0645591, acc 0.96875, learning_rate 0.00101096\n","2023-06-27T18:03:28.239104: step 2121, loss 0.124485, acc 0.96875, learning_rate 0.00101033\n","2023-06-27T18:03:28.463094: step 2122, loss 0.216923, acc 0.90625, learning_rate 0.00100971\n","2023-06-27T18:03:28.674966: step 2123, loss 0.122377, acc 0.96875, learning_rate 0.00100909\n","2023-06-27T18:03:28.895795: step 2124, loss 0.459489, acc 0.84375, learning_rate 0.00100846\n","2023-06-27T18:03:29.084629: step 2125, loss 0.1303, acc 0.9375, learning_rate 0.00100784\n","2023-06-27T18:03:29.307848: step 2126, loss 0.184979, acc 0.90625, learning_rate 0.00100722\n","2023-06-27T18:03:29.557210: step 2127, loss 0.0626424, acc 1, learning_rate 0.0010066\n","2023-06-27T18:03:29.792385: step 2128, loss 0.220497, acc 0.96875, learning_rate 0.00100597\n","2023-06-27T18:03:29.986424: step 2129, loss 0.144751, acc 0.96875, learning_rate 0.00100535\n","2023-06-27T18:03:30.203404: step 2130, loss 0.0334433, acc 1, learning_rate 0.00100473\n","2023-06-27T18:03:30.468282: step 2131, loss 0.115937, acc 0.9375, learning_rate 0.00100411\n","2023-06-27T18:03:30.718272: step 2132, loss 0.413772, acc 0.90625, learning_rate 0.00100349\n","2023-06-27T18:03:30.967114: step 2133, loss 0.166943, acc 0.9375, learning_rate 0.00100287\n","2023-06-27T18:03:31.225701: step 2134, loss 0.142565, acc 0.9375, learning_rate 0.00100225\n","2023-06-27T18:03:31.461893: step 2135, loss 0.114119, acc 0.96875, learning_rate 0.00100163\n","2023-06-27T18:03:31.711472: step 2136, loss 0.120804, acc 0.9375, learning_rate 0.00100102\n","2023-06-27T18:03:31.962658: step 2137, loss 0.0547384, acc 0.96875, learning_rate 0.0010004\n","2023-06-27T18:03:32.168360: step 2138, loss 0.107441, acc 0.96875, learning_rate 0.000999781\n","2023-06-27T18:03:32.443800: step 2139, loss 0.135311, acc 0.9375, learning_rate 0.000999164\n","2023-06-27T18:03:32.650277: step 2140, loss 0.220613, acc 0.90625, learning_rate 0.000998547\n","2023-06-27T18:03:32.872806: step 2141, loss 0.151774, acc 0.96875, learning_rate 0.000997931\n","2023-06-27T18:03:33.084722: step 2142, loss 0.350825, acc 0.90625, learning_rate 0.000997315\n","2023-06-27T18:03:33.286680: step 2143, loss 0.263961, acc 0.875, learning_rate 0.0009967\n","2023-06-27T18:03:33.512854: step 2144, loss 0.075783, acc 1, learning_rate 0.000996085\n","2023-06-27T18:03:33.785618: step 2145, loss 0.0487247, acc 1, learning_rate 0.00099547\n","2023-06-27T18:03:34.051801: step 2146, loss 0.0953341, acc 0.96875, learning_rate 0.000994856\n","2023-06-27T18:03:34.349835: step 2147, loss 0.18614, acc 0.9375, learning_rate 0.000994243\n","2023-06-27T18:03:34.609155: step 2148, loss 0.148445, acc 0.9375, learning_rate 0.00099363\n","2023-06-27T18:03:34.796463: step 2149, loss 0.242783, acc 0.90625, learning_rate 0.000993017\n","2023-06-27T18:03:34.988190: step 2150, loss 0.0882172, acc 0.9375, learning_rate 0.000992404\n","2023-06-27T18:03:35.210429: step 2151, loss 0.0817122, acc 0.96875, learning_rate 0.000991792\n","2023-06-27T18:03:35.462228: step 2152, loss 0.0642244, acc 0.96875, learning_rate 0.000991181\n","2023-06-27T18:03:35.700095: step 2153, loss 0.100101, acc 0.96875, learning_rate 0.00099057\n","2023-06-27T18:03:35.969649: step 2154, loss 0.0526099, acc 0.96875, learning_rate 0.000989959\n","2023-06-27T18:03:36.207496: step 2155, loss 0.21187, acc 0.9375, learning_rate 0.000989349\n","2023-06-27T18:03:36.420906: step 2156, loss 0.0665313, acc 0.96875, learning_rate 0.000988739\n","2023-06-27T18:03:36.633727: step 2157, loss 0.0954134, acc 1, learning_rate 0.00098813\n","2023-06-27T18:03:36.882487: step 2158, loss 0.0923081, acc 0.96875, learning_rate 0.000987521\n","2023-06-27T18:03:37.093930: step 2159, loss 0.0198979, acc 1, learning_rate 0.000986912\n","2023-06-27T18:03:37.300532: step 2160, loss 0.025503, acc 1, learning_rate 0.000986304\n","2023-06-27T18:03:37.488831: step 2161, loss 0.231501, acc 0.9375, learning_rate 0.000985696\n","2023-06-27T18:03:37.697291: step 2162, loss 0.11506, acc 0.9375, learning_rate 0.000985089\n","2023-06-27T18:03:37.924397: step 2163, loss 0.0539766, acc 1, learning_rate 0.000984482\n","2023-06-27T18:03:38.125961: step 2164, loss 0.165336, acc 0.90625, learning_rate 0.000983875\n","2023-06-27T18:03:38.344897: step 2165, loss 0.268756, acc 0.90625, learning_rate 0.000983269\n","2023-06-27T18:03:38.557113: step 2166, loss 0.143351, acc 0.9375, learning_rate 0.000982664\n","2023-06-27T18:03:38.766724: step 2167, loss 0.243115, acc 0.9375, learning_rate 0.000982058\n","2023-06-27T18:03:38.981885: step 2168, loss 0.0502253, acc 1, learning_rate 0.000981453\n","2023-06-27T18:03:39.178553: step 2169, loss 0.139568, acc 0.90625, learning_rate 0.000980849\n","2023-06-27T18:03:39.394662: step 2170, loss 0.174875, acc 0.96875, learning_rate 0.000980245\n","2023-06-27T18:03:39.591019: step 2171, loss 0.0879875, acc 1, learning_rate 0.000979641\n","2023-06-27T18:03:39.816248: step 2172, loss 0.281998, acc 0.96875, learning_rate 0.000979038\n","2023-06-27T18:03:40.031172: step 2173, loss 0.127117, acc 0.9375, learning_rate 0.000978435\n","2023-06-27T18:03:40.247657: step 2174, loss 0.101658, acc 0.9375, learning_rate 0.000977833\n","2023-06-27T18:03:40.486050: step 2175, loss 0.142744, acc 0.9375, learning_rate 0.000977231\n","2023-06-27T18:03:40.682139: step 2176, loss 0.0309285, acc 1, learning_rate 0.00097663\n","2023-06-27T18:03:40.908001: step 2177, loss 0.173656, acc 0.9375, learning_rate 0.000976028\n","2023-06-27T18:03:41.139365: step 2178, loss 0.266518, acc 0.875, learning_rate 0.000975428\n","2023-06-27T18:03:41.350768: step 2179, loss 0.0541922, acc 1, learning_rate 0.000974827\n","2023-06-27T18:03:41.567293: step 2180, loss 0.117149, acc 0.96875, learning_rate 0.000974227\n","2023-06-27T18:03:41.771910: step 2181, loss 0.136277, acc 0.96875, learning_rate 0.000973628\n","2023-06-27T18:03:41.976547: step 2182, loss 0.0936279, acc 0.96875, learning_rate 0.000973029\n","2023-06-27T18:03:42.178545: step 2183, loss 0.0625919, acc 0.96875, learning_rate 0.00097243\n","2023-06-27T18:03:42.381418: step 2184, loss 0.0441769, acc 1, learning_rate 0.000971832\n","2023-06-27T18:03:42.563175: step 2185, loss 0.173428, acc 0.9375, learning_rate 0.000971234\n","2023-06-27T18:03:42.775181: step 2186, loss 0.0844653, acc 0.9375, learning_rate 0.000970637\n","2023-06-27T18:03:42.981065: step 2187, loss 0.0797344, acc 0.96875, learning_rate 0.00097004\n","2023-06-27T18:03:43.204934: step 2188, loss 0.136756, acc 0.9375, learning_rate 0.000969443\n","2023-06-27T18:03:43.379717: step 2189, loss 0.306209, acc 0.875, learning_rate 0.000968847\n","2023-06-27T18:03:43.576679: step 2190, loss 0.221806, acc 0.9375, learning_rate 0.000968251\n","2023-06-27T18:03:43.771345: step 2191, loss 0.183279, acc 0.9375, learning_rate 0.000967656\n","2023-06-27T18:03:43.981227: step 2192, loss 0.334877, acc 0.875, learning_rate 0.000967061\n","2023-06-27T18:03:44.186023: step 2193, loss 0.085542, acc 0.96875, learning_rate 0.000966466\n","2023-06-27T18:03:44.355792: step 2194, loss 0.185076, acc 0.90625, learning_rate 0.000965872\n","2023-06-27T18:03:44.538064: step 2195, loss 0.0557794, acc 1, learning_rate 0.000965278\n","2023-06-27T18:03:44.736537: step 2196, loss 0.0747664, acc 1, learning_rate 0.000964685\n","2023-06-27T18:03:44.927315: step 2197, loss 0.266216, acc 0.84375, learning_rate 0.000964092\n","2023-06-27T18:03:45.125096: step 2198, loss 0.091124, acc 0.96875, learning_rate 0.0009635\n","2023-06-27T18:03:45.302449: step 2199, loss 0.100728, acc 0.96875, learning_rate 0.000962907\n","\n","Evaluation:\n","2023-06-27T18:03:46.355818: step 2200, loss 0.620094, acc 0.806175\n","\n","Saved model checkpoint to /content/gdrive/MyDrive/lightweighted-cnn/train/runs/1687888658/checkpoints/model-2200\n","\n","2023-06-27T18:03:46.570489: step 2200, loss 0.0509383, acc 1, learning_rate 0.000962316\n","2023-06-27T18:03:46.697908: step 2201, loss 0.26121, acc 0.9375, learning_rate 0.000961724\n","2023-06-27T18:03:46.812890: step 2202, loss 0.0619252, acc 1, learning_rate 0.000961133\n","2023-06-27T18:03:46.947109: step 2203, loss 0.205166, acc 0.9375, learning_rate 0.000960543\n","2023-06-27T18:03:47.065871: step 2204, loss 0.201879, acc 0.90625, learning_rate 0.000959953\n","2023-06-27T18:03:47.193226: step 2205, loss 0.140167, acc 0.9375, learning_rate 0.000959363\n","2023-06-27T18:03:47.333451: step 2206, loss 0.186263, acc 0.90625, learning_rate 0.000958774\n","2023-06-27T18:03:47.448199: step 2207, loss 0.137651, acc 0.96875, learning_rate 0.000958185\n","2023-06-27T18:03:47.577611: step 2208, loss 0.041558, acc 1, learning_rate 0.000957597\n","2023-06-27T18:03:47.717809: step 2209, loss 0.181501, acc 0.9375, learning_rate 0.000957008\n","2023-06-27T18:03:47.828952: step 2210, loss 0.0647114, acc 1, learning_rate 0.000956421\n","2023-06-27T18:03:47.956632: step 2211, loss 0.073626, acc 0.96875, learning_rate 0.000955834\n","2023-06-27T18:03:48.076541: step 2212, loss 0.107325, acc 0.96875, learning_rate 0.000955247\n","2023-06-27T18:03:48.181828: step 2213, loss 0.135288, acc 0.96875, learning_rate 0.00095466\n","2023-06-27T18:03:48.317324: step 2214, loss 0.10123, acc 0.96875, learning_rate 0.000954074\n","2023-06-27T18:03:48.440382: step 2215, loss 0.15343, acc 0.9375, learning_rate 0.000953488\n","2023-06-27T18:03:48.568662: step 2216, loss 0.101561, acc 0.96875, learning_rate 0.000952903\n","2023-06-27T18:03:48.687497: step 2217, loss 0.0988668, acc 0.96875, learning_rate 0.000952318\n","2023-06-27T18:03:48.797934: step 2218, loss 0.128741, acc 0.96875, learning_rate 0.000951734\n","2023-06-27T18:03:48.917765: step 2219, loss 0.126111, acc 0.96875, learning_rate 0.00095115\n","2023-06-27T18:03:49.031758: step 2220, loss 0.14838, acc 0.9375, learning_rate 0.000950566\n","2023-06-27T18:03:49.156135: step 2221, loss 0.138929, acc 0.9375, learning_rate 0.000949983\n","2023-06-27T18:03:49.272447: step 2222, loss 0.102261, acc 1, learning_rate 0.0009494\n","2023-06-27T18:03:49.399140: step 2223, loss 0.133936, acc 0.96875, learning_rate 0.000948818\n","2023-06-27T18:03:49.508541: step 2224, loss 0.137699, acc 0.96875, learning_rate 0.000948236\n","2023-06-27T18:03:49.627857: step 2225, loss 0.140511, acc 0.96875, learning_rate 0.000947654\n","2023-06-27T18:03:49.743206: step 2226, loss 0.0672148, acc 1, learning_rate 0.000947073\n","2023-06-27T18:03:49.869439: step 2227, loss 0.0934481, acc 1, learning_rate 0.000946492\n","2023-06-27T18:03:49.985410: step 2228, loss 0.15007, acc 0.9375, learning_rate 0.000945911\n","2023-06-27T18:03:50.097528: step 2229, loss 0.278541, acc 0.875, learning_rate 0.000945331\n","2023-06-27T18:03:50.204808: step 2230, loss 0.152794, acc 0.9375, learning_rate 0.000944752\n","2023-06-27T18:03:50.339892: step 2231, loss 0.17098, acc 0.96875, learning_rate 0.000944172\n","2023-06-27T18:03:50.458820: step 2232, loss 0.108765, acc 0.96875, learning_rate 0.000943593\n","2023-06-27T18:03:50.589537: step 2233, loss 0.290847, acc 0.875, learning_rate 0.000943015\n","2023-06-27T18:03:50.709876: step 2234, loss 0.164088, acc 0.875, learning_rate 0.000942437\n","2023-06-27T18:03:50.821138: step 2235, loss 0.0510134, acc 1, learning_rate 0.000941859\n","2023-06-27T18:03:50.939578: step 2236, loss 0.193078, acc 0.90625, learning_rate 0.000941282\n","2023-06-27T18:03:51.061304: step 2237, loss 0.103068, acc 0.9375, learning_rate 0.000940705\n","2023-06-27T18:03:51.174033: step 2238, loss 0.286893, acc 0.875, learning_rate 0.000940129\n","2023-06-27T18:03:51.297807: step 2239, loss 0.0477707, acc 1, learning_rate 0.000939553\n","2023-06-27T18:03:51.433253: step 2240, loss 0.0369836, acc 1, learning_rate 0.000938977\n","2023-06-27T18:03:51.543667: step 2241, loss 0.161973, acc 0.90625, learning_rate 0.000938402\n","2023-06-27T18:03:51.659462: step 2242, loss 0.103484, acc 0.9375, learning_rate 0.000937827\n","2023-06-27T18:03:51.792706: step 2243, loss 0.204078, acc 0.9375, learning_rate 0.000937252\n","2023-06-27T18:03:51.919721: step 2244, loss 0.302143, acc 0.84375, learning_rate 0.000936678\n","2023-06-27T18:03:52.034981: step 2245, loss 0.173476, acc 0.96875, learning_rate 0.000936104\n","2023-06-27T18:03:52.174046: step 2246, loss 0.225635, acc 0.9375, learning_rate 0.000935531\n","2023-06-27T18:03:52.303052: step 2247, loss 0.162997, acc 0.96875, learning_rate 0.000934958\n","2023-06-27T18:03:52.429630: step 2248, loss 0.160124, acc 0.90625, learning_rate 0.000934385\n","2023-06-27T18:03:52.544434: step 2249, loss 0.133085, acc 0.9375, learning_rate 0.000933813\n","2023-06-27T18:03:52.672484: step 2250, loss 0.309384, acc 0.9375, learning_rate 0.000933241\n","2023-06-27T18:03:52.794404: step 2251, loss 0.150594, acc 0.9375, learning_rate 0.00093267\n","2023-06-27T18:03:52.931300: step 2252, loss 0.16165, acc 0.96875, learning_rate 0.000932099\n","2023-06-27T18:03:53.058146: step 2253, loss 0.255647, acc 0.90625, learning_rate 0.000931529\n","2023-06-27T18:03:53.185347: step 2254, loss 0.0534033, acc 1, learning_rate 0.000930958\n","2023-06-27T18:03:53.348242: step 2255, loss 0.0427342, acc 1, learning_rate 0.000930389\n","2023-06-27T18:03:53.523419: step 2256, loss 0.258241, acc 0.84375, learning_rate 0.000929819\n","2023-06-27T18:03:53.749647: step 2257, loss 0.0952695, acc 0.96875, learning_rate 0.00092925\n","2023-06-27T18:03:53.952578: step 2258, loss 0.13323, acc 0.96875, learning_rate 0.000928681\n","2023-06-27T18:03:54.167016: step 2259, loss 0.0882915, acc 0.96875, learning_rate 0.000928113\n","2023-06-27T18:03:54.386651: step 2260, loss 0.0442755, acc 1, learning_rate 0.000927545\n","2023-06-27T18:03:54.586596: step 2261, loss 0.149673, acc 0.9375, learning_rate 0.000926978\n","2023-06-27T18:03:54.777516: step 2262, loss 0.126057, acc 0.9375, learning_rate 0.000926411\n","2023-06-27T18:03:54.982160: step 2263, loss 0.182, acc 0.9375, learning_rate 0.000925844\n","2023-06-27T18:03:55.214546: step 2264, loss 0.217516, acc 0.90625, learning_rate 0.000925278\n","2023-06-27T18:03:55.445995: step 2265, loss 0.228167, acc 0.9375, learning_rate 0.000924712\n","2023-06-27T18:03:55.641212: step 2266, loss 0.157863, acc 0.9375, learning_rate 0.000924146\n","2023-06-27T18:03:55.865107: step 2267, loss 0.197762, acc 0.9375, learning_rate 0.000923581\n","2023-06-27T18:03:56.076312: step 2268, loss 0.165222, acc 0.9375, learning_rate 0.000923016\n","2023-06-27T18:03:56.292118: step 2269, loss 0.116274, acc 0.96875, learning_rate 0.000922452\n","2023-06-27T18:03:56.487186: step 2270, loss 0.0553347, acc 0.96875, learning_rate 0.000921888\n","2023-06-27T18:03:56.697703: step 2271, loss 0.0950009, acc 0.96875, learning_rate 0.000921325\n","2023-06-27T18:03:56.916326: step 2272, loss 0.179984, acc 0.9375, learning_rate 0.000920761\n","2023-06-27T18:03:57.132613: step 2273, loss 0.135884, acc 0.9375, learning_rate 0.000920199\n","2023-06-27T18:03:57.325243: step 2274, loss 0.121958, acc 0.96875, learning_rate 0.000919636\n","2023-06-27T18:03:57.533035: step 2275, loss 0.081942, acc 0.96875, learning_rate 0.000919074\n","2023-06-27T18:03:57.721852: step 2276, loss 0.0675414, acc 1, learning_rate 0.000918512\n","2023-06-27T18:03:57.924152: step 2277, loss 0.0634659, acc 1, learning_rate 0.000917951\n","2023-06-27T18:03:58.108459: step 2278, loss 0.137856, acc 0.9375, learning_rate 0.00091739\n","2023-06-27T18:03:58.303342: step 2279, loss 0.197103, acc 0.90625, learning_rate 0.00091683\n","2023-06-27T18:03:58.517615: step 2280, loss 0.109724, acc 0.96875, learning_rate 0.00091627\n","2023-06-27T18:03:58.727486: step 2281, loss 0.136753, acc 0.96875, learning_rate 0.00091571\n","2023-06-27T18:03:58.909281: step 2282, loss 0.0692825, acc 0.96875, learning_rate 0.000915151\n","2023-06-27T18:03:59.106770: step 2283, loss 0.0212616, acc 1, learning_rate 0.000914592\n","2023-06-27T18:03:59.303391: step 2284, loss 0.122806, acc 0.96875, learning_rate 0.000914033\n","2023-06-27T18:03:59.514278: step 2285, loss 0.191335, acc 0.9375, learning_rate 0.000913475\n","2023-06-27T18:03:59.713246: step 2286, loss 0.0482443, acc 1, learning_rate 0.000912917\n","2023-06-27T18:03:59.919008: step 2287, loss 0.161013, acc 0.90625, learning_rate 0.00091236\n","2023-06-27T18:04:00.109311: step 2288, loss 0.259746, acc 0.875, learning_rate 0.000911802\n","2023-06-27T18:04:00.331492: step 2289, loss 0.142297, acc 0.96875, learning_rate 0.000911246\n","2023-06-27T18:04:00.522743: step 2290, loss 0.0842701, acc 0.96875, learning_rate 0.000910689\n","2023-06-27T18:04:00.733517: step 2291, loss 0.20495, acc 0.875, learning_rate 0.000910134\n","2023-06-27T18:04:00.928739: step 2292, loss 0.16655, acc 0.9375, learning_rate 0.000909578\n","2023-06-27T18:04:01.113647: step 2293, loss 0.118996, acc 0.9375, learning_rate 0.000909023\n","2023-06-27T18:04:01.308425: step 2294, loss 0.273541, acc 0.9375, learning_rate 0.000908468\n","2023-06-27T18:04:01.500397: step 2295, loss 0.162727, acc 0.96875, learning_rate 0.000907914\n","2023-06-27T18:04:01.698534: step 2296, loss 0.175681, acc 0.9375, learning_rate 0.00090736\n","2023-06-27T18:04:01.891227: step 2297, loss 0.111108, acc 0.96875, learning_rate 0.000906806\n","2023-06-27T18:04:02.066933: step 2298, loss 0.106534, acc 0.9375, learning_rate 0.000906253\n","2023-06-27T18:04:02.249879: step 2299, loss 0.0511743, acc 1, learning_rate 0.0009057\n","\n","Evaluation:\n","2023-06-27T18:04:03.544460: step 2300, loss 0.637678, acc 0.804888\n","\n","Saved model checkpoint to /content/gdrive/MyDrive/lightweighted-cnn/train/runs/1687888658/checkpoints/model-2300\n","\n","2023-06-27T18:04:03.895907: step 2300, loss 0.211497, acc 0.875, learning_rate 0.000905148\n","2023-06-27T18:04:04.097079: step 2301, loss 0.0981808, acc 0.96875, learning_rate 0.000904595\n","2023-06-27T18:04:04.319554: step 2302, loss 0.084078, acc 0.96875, learning_rate 0.000904044\n","2023-06-27T18:04:04.480035: step 2303, loss 0.14002, acc 0.90625, learning_rate 0.000903492\n","2023-06-27T18:04:04.607739: step 2304, loss 0.17738, acc 0.90625, learning_rate 0.000902941\n","2023-06-27T18:04:04.734065: step 2305, loss 0.128833, acc 0.9375, learning_rate 0.000902391\n","2023-06-27T18:04:04.853806: step 2306, loss 0.200997, acc 0.90625, learning_rate 0.000901841\n","2023-06-27T18:04:04.973618: step 2307, loss 0.48644, acc 0.90625, learning_rate 0.000901291\n","2023-06-27T18:04:05.101939: step 2308, loss 0.194761, acc 0.90625, learning_rate 0.000900741\n","2023-06-27T18:04:05.222645: step 2309, loss 0.0685414, acc 0.96875, learning_rate 0.000900192\n","2023-06-27T18:04:05.336763: step 2310, loss 0.0680415, acc 1, learning_rate 0.000899643\n","2023-06-27T18:04:05.462947: step 2311, loss 0.11732, acc 0.96875, learning_rate 0.000899095\n","2023-06-27T18:04:05.585501: step 2312, loss 0.0386498, acc 1, learning_rate 0.000898547\n","2023-06-27T18:04:05.710682: step 2313, loss 0.192239, acc 0.9375, learning_rate 0.000898\n","2023-06-27T18:04:05.834679: step 2314, loss 0.0676216, acc 0.96875, learning_rate 0.000897452\n","2023-06-27T18:04:05.950660: step 2315, loss 0.102468, acc 0.9375, learning_rate 0.000896906\n","2023-06-27T18:04:06.082078: step 2316, loss 0.0945379, acc 0.96875, learning_rate 0.000896359\n","2023-06-27T18:04:06.209665: step 2317, loss 0.169942, acc 0.9375, learning_rate 0.000895813\n","2023-06-27T18:04:06.351620: step 2318, loss 0.21647, acc 0.84375, learning_rate 0.000895267\n","2023-06-27T18:04:06.482349: step 2319, loss 0.149996, acc 0.96875, learning_rate 0.000894722\n","2023-06-27T18:04:06.611771: step 2320, loss 0.330042, acc 0.90625, learning_rate 0.000894177\n","2023-06-27T18:04:06.736278: step 2321, loss 0.363329, acc 0.8125, learning_rate 0.000893632\n","2023-06-27T18:04:06.856505: step 2322, loss 0.126131, acc 0.9375, learning_rate 0.000893088\n","2023-06-27T18:04:06.976101: step 2323, loss 0.209723, acc 0.875, learning_rate 0.000892544\n","2023-06-27T18:04:07.115147: step 2324, loss 0.0166329, acc 1, learning_rate 0.000892001\n","2023-06-27T18:04:07.249633: step 2325, loss 0.323516, acc 0.9375, learning_rate 0.000891458\n","2023-06-27T18:04:07.375404: step 2326, loss 0.219873, acc 0.9375, learning_rate 0.000890915\n","2023-06-27T18:04:07.484979: step 2327, loss 0.220962, acc 0.90625, learning_rate 0.000890373\n","2023-06-27T18:04:07.604338: step 2328, loss 0.0774481, acc 0.96875, learning_rate 0.000889831\n","2023-06-27T18:04:07.718648: step 2329, loss 0.0887014, acc 0.96875, learning_rate 0.000889289\n","2023-06-27T18:04:07.847189: step 2330, loss 0.184921, acc 0.9375, learning_rate 0.000888748\n","2023-06-27T18:04:07.960919: step 2331, loss 0.107476, acc 0.9375, learning_rate 0.000888207\n","2023-06-27T18:04:08.086107: step 2332, loss 0.142757, acc 0.9375, learning_rate 0.000887667\n","2023-06-27T18:04:08.214957: step 2333, loss 0.117239, acc 0.9375, learning_rate 0.000887126\n","2023-06-27T18:04:08.334847: step 2334, loss 0.0985813, acc 0.96875, learning_rate 0.000886587\n","2023-06-27T18:04:08.428090: step 2335, loss 0.0827337, acc 1, learning_rate 0.000886047\n","2023-06-27T18:04:08.567210: step 2336, loss 0.0331373, acc 1, learning_rate 0.000885508\n","2023-06-27T18:04:08.673752: step 2337, loss 0.0604381, acc 1, learning_rate 0.00088497\n","2023-06-27T18:04:08.791223: step 2338, loss 0.0509117, acc 1, learning_rate 0.000884431\n","2023-06-27T18:04:08.917999: step 2339, loss 0.0681265, acc 0.96875, learning_rate 0.000883893\n","2023-06-27T18:04:09.044060: step 2340, loss 0.0445796, acc 1, learning_rate 0.000883356\n","2023-06-27T18:04:09.171258: step 2341, loss 0.0418389, acc 1, learning_rate 0.000882819\n","2023-06-27T18:04:09.293635: step 2342, loss 0.158804, acc 0.875, learning_rate 0.000882282\n","2023-06-27T18:04:09.411853: step 2343, loss 0.138212, acc 0.9375, learning_rate 0.000881746\n","2023-06-27T18:04:09.536875: step 2344, loss 0.0543962, acc 1, learning_rate 0.000881209\n","2023-06-27T18:04:09.652869: step 2345, loss 0.0269089, acc 1, learning_rate 0.000880674\n","2023-06-27T18:04:09.763480: step 2346, loss 0.041616, acc 1, learning_rate 0.000880138\n","2023-06-27T18:04:09.874984: step 2347, loss 0.114295, acc 0.9375, learning_rate 0.000879603\n","2023-06-27T18:04:09.992683: step 2348, loss 0.0693818, acc 1, learning_rate 0.000879069\n","2023-06-27T18:04:10.150107: step 2349, loss 0.167801, acc 0.96875, learning_rate 0.000878535\n","2023-06-27T18:04:10.273256: step 2350, loss 0.0806559, acc 0.96875, learning_rate 0.000878001\n","2023-06-27T18:04:10.403319: step 2351, loss 0.039269, acc 1, learning_rate 0.000877467\n","2023-06-27T18:04:10.528957: step 2352, loss 0.11524, acc 0.96875, learning_rate 0.000876934\n","2023-06-27T18:04:10.645689: step 2353, loss 0.0648121, acc 0.96875, learning_rate 0.000876401\n","2023-06-27T18:04:10.775772: step 2354, loss 0.187122, acc 0.96875, learning_rate 0.000875869\n","2023-06-27T18:04:10.884652: step 2355, loss 0.00656659, acc 1, learning_rate 0.000875337\n","2023-06-27T18:04:11.002209: step 2356, loss 0.0895824, acc 0.96875, learning_rate 0.000874805\n","2023-06-27T18:04:11.120638: step 2357, loss 0.0428028, acc 1, learning_rate 0.000874274\n","2023-06-27T18:04:11.247807: step 2358, loss 0.190701, acc 0.9375, learning_rate 0.000873743\n","2023-06-27T18:04:11.377119: step 2359, loss 0.0397571, acc 1, learning_rate 0.000873212\n","2023-06-27T18:04:11.502390: step 2360, loss 0.183657, acc 0.875, learning_rate 0.000872682\n","2023-06-27T18:04:11.620671: step 2361, loss 0.0438957, acc 0.96875, learning_rate 0.000872152\n","2023-06-27T18:04:11.740199: step 2362, loss 0.026263, acc 1, learning_rate 0.000871623\n","2023-06-27T18:04:11.860409: step 2363, loss 0.0902407, acc 0.96875, learning_rate 0.000871094\n","2023-06-27T18:04:11.997642: step 2364, loss 0.28354, acc 0.84375, learning_rate 0.000870565\n","2023-06-27T18:04:12.112343: step 2365, loss 0.117393, acc 0.96875, learning_rate 0.000870037\n","2023-06-27T18:04:12.242687: step 2366, loss 0.0319154, acc 1, learning_rate 0.000869509\n","2023-06-27T18:04:12.367490: step 2367, loss 0.045052, acc 0.96875, learning_rate 0.000868981\n","2023-06-27T18:04:12.492720: step 2368, loss 0.053969, acc 1, learning_rate 0.000868454\n","2023-06-27T18:04:12.612284: step 2369, loss 0.0408402, acc 0.96875, learning_rate 0.000867927\n","2023-06-27T18:04:12.723527: step 2370, loss 0.0219614, acc 1, learning_rate 0.0008674\n","2023-06-27T18:04:12.846526: step 2371, loss 0.0198291, acc 1, learning_rate 0.000866874\n","2023-06-27T18:04:12.970913: step 2372, loss 0.27661, acc 0.84375, learning_rate 0.000866348\n","2023-06-27T18:04:13.090371: step 2373, loss 0.0607008, acc 0.96875, learning_rate 0.000865823\n","2023-06-27T18:04:13.216592: step 2374, loss 0.0681246, acc 0.96875, learning_rate 0.000865297\n","2023-06-27T18:04:13.332979: step 2375, loss 0.0986882, acc 0.96875, learning_rate 0.000864773\n","2023-06-27T18:04:13.460895: step 2376, loss 0.37604, acc 0.90625, learning_rate 0.000864248\n","2023-06-27T18:04:13.576225: step 2377, loss 0.111731, acc 0.9375, learning_rate 0.000863724\n","2023-06-27T18:04:13.694914: step 2378, loss 0.0685005, acc 0.96875, learning_rate 0.0008632\n","2023-06-27T18:04:13.831705: step 2379, loss 0.0369324, acc 1, learning_rate 0.000862677\n","2023-06-27T18:04:13.951564: step 2380, loss 0.0902057, acc 0.96875, learning_rate 0.000862154\n","2023-06-27T18:04:14.078218: step 2381, loss 0.0710788, acc 0.96875, learning_rate 0.000861631\n","2023-06-27T18:04:14.196844: step 2382, loss 0.2608, acc 0.90625, learning_rate 0.000861109\n","2023-06-27T18:04:14.324820: step 2383, loss 0.0304047, acc 1, learning_rate 0.000860587\n","2023-06-27T18:04:14.479996: step 2384, loss 0.0469649, acc 1, learning_rate 0.000860066\n","2023-06-27T18:04:14.678571: step 2385, loss 0.114071, acc 0.9375, learning_rate 0.000859545\n","2023-06-27T18:04:14.849640: step 2386, loss 0.0660554, acc 1, learning_rate 0.000859024\n","2023-06-27T18:04:15.043207: step 2387, loss 0.130674, acc 0.96875, learning_rate 0.000858503\n","2023-06-27T18:04:15.253852: step 2388, loss 0.0895106, acc 0.96875, learning_rate 0.000857983\n","2023-06-27T18:04:15.458683: step 2389, loss 0.14116, acc 0.9375, learning_rate 0.000857463\n","2023-06-27T18:04:15.651786: step 2390, loss 0.0431075, acc 1, learning_rate 0.000856944\n","2023-06-27T18:04:15.878015: step 2391, loss 0.08044, acc 1, learning_rate 0.000856425\n","2023-06-27T18:04:16.072142: step 2392, loss 0.0332891, acc 1, learning_rate 0.000855906\n","2023-06-27T18:04:16.284096: step 2393, loss 0.204891, acc 0.90625, learning_rate 0.000855388\n","2023-06-27T18:04:16.508536: step 2394, loss 0.10609, acc 0.9375, learning_rate 0.00085487\n","2023-06-27T18:04:16.716054: step 2395, loss 0.233458, acc 0.96875, learning_rate 0.000854352\n","2023-06-27T18:04:16.926545: step 2396, loss 0.103935, acc 0.9375, learning_rate 0.000853835\n","2023-06-27T18:04:17.130564: step 2397, loss 0.0171783, acc 1, learning_rate 0.000853318\n","2023-06-27T18:04:17.345083: step 2398, loss 0.0617084, acc 0.96875, learning_rate 0.000852801\n","2023-06-27T18:04:17.566308: step 2399, loss 0.12024, acc 0.96875, learning_rate 0.000852285\n","\n","Evaluation:\n","2023-06-27T18:04:18.899175: step 2400, loss 0.648978, acc 0.797813\n","\n","Saved model checkpoint to /content/gdrive/MyDrive/lightweighted-cnn/train/runs/1687888658/checkpoints/model-2400\n","\n","2023-06-27T18:04:19.281433: step 2400, loss 0.259558, acc 0.90625, learning_rate 0.000851769\n","2023-06-27T18:04:19.482187: step 2401, loss 0.113711, acc 0.96875, learning_rate 0.000851254\n","2023-06-27T18:04:19.672256: step 2402, loss 0.0501215, acc 0.96875, learning_rate 0.000850739\n","2023-06-27T18:04:19.855333: step 2403, loss 0.123022, acc 0.90625, learning_rate 0.000850224\n","2023-06-27T18:04:20.041948: step 2404, loss 0.0735342, acc 1, learning_rate 0.000849709\n","2023-06-27T18:04:20.255586: step 2405, loss 0.0184533, acc 1, learning_rate 0.000849195\n","2023-06-27T18:04:20.465055: step 2406, loss 0.0316086, acc 1, learning_rate 0.000848682\n","2023-06-27T18:04:20.664478: step 2407, loss 0.0103872, acc 1, learning_rate 0.000848168\n","2023-06-27T18:04:20.840501: step 2408, loss 0.0319968, acc 1, learning_rate 0.000847655\n","2023-06-27T18:04:21.014709: step 2409, loss 0.0954099, acc 0.96875, learning_rate 0.000847143\n","2023-06-27T18:04:21.186999: step 2410, loss 0.0913196, acc 1, learning_rate 0.00084663\n","2023-06-27T18:04:21.380095: step 2411, loss 0.121955, acc 0.96875, learning_rate 0.000846118\n","2023-06-27T18:04:21.591446: step 2412, loss 0.110007, acc 0.96875, learning_rate 0.000845607\n","2023-06-27T18:04:21.801337: step 2413, loss 0.143605, acc 0.9375, learning_rate 0.000845095\n","2023-06-27T18:04:22.003043: step 2414, loss 0.0697715, acc 1, learning_rate 0.000844584\n","2023-06-27T18:04:22.213253: step 2415, loss 0.055535, acc 1, learning_rate 0.000844074\n","2023-06-27T18:04:22.421012: step 2416, loss 0.10706, acc 0.9375, learning_rate 0.000843564\n","2023-06-27T18:04:22.617261: step 2417, loss 0.309527, acc 0.84375, learning_rate 0.000843054\n","2023-06-27T18:04:22.806061: step 2418, loss 0.0600495, acc 1, learning_rate 0.000842544\n","2023-06-27T18:04:22.989394: step 2419, loss 0.0539003, acc 0.96875, learning_rate 0.000842035\n","2023-06-27T18:04:23.176967: step 2420, loss 0.0424213, acc 1, learning_rate 0.000841526\n","2023-06-27T18:04:23.375792: step 2421, loss 0.0395111, acc 1, learning_rate 0.000841018\n","2023-06-27T18:04:23.565145: step 2422, loss 0.198779, acc 0.96875, learning_rate 0.00084051\n","2023-06-27T18:04:23.758572: step 2423, loss 0.135637, acc 0.96875, learning_rate 0.000840002\n","2023-06-27T18:04:23.930606: step 2424, loss 0.142717, acc 0.9375, learning_rate 0.000839494\n","2023-06-27T18:04:24.126306: step 2425, loss 0.161882, acc 0.9375, learning_rate 0.000838987\n","2023-06-27T18:04:24.342740: step 2426, loss 0.0633819, acc 0.96875, learning_rate 0.00083848\n","2023-06-27T18:04:24.546201: step 2427, loss 0.0474459, acc 1, learning_rate 0.000837974\n","2023-06-27T18:04:24.766347: step 2428, loss 0.0860462, acc 0.96875, learning_rate 0.000837468\n","2023-06-27T18:04:24.937241: step 2429, loss 0.111663, acc 0.96875, learning_rate 0.000836962\n","2023-06-27T18:04:25.137483: step 2430, loss 0.10274, acc 0.96875, learning_rate 0.000836457\n","2023-06-27T18:04:25.369594: step 2431, loss 0.0363966, acc 1, learning_rate 0.000835952\n","2023-06-27T18:04:25.526699: step 2432, loss 0.054643, acc 1, learning_rate 0.000835447\n","2023-06-27T18:04:25.640947: step 2433, loss 0.0363464, acc 1, learning_rate 0.000834943\n","2023-06-27T18:04:25.760755: step 2434, loss 0.0604241, acc 0.96875, learning_rate 0.000834439\n","2023-06-27T18:04:25.883125: step 2435, loss 0.137099, acc 0.9375, learning_rate 0.000833935\n","2023-06-27T18:04:25.998241: step 2436, loss 0.152766, acc 0.9375, learning_rate 0.000833432\n","2023-06-27T18:04:26.115660: step 2437, loss 0.0938251, acc 0.96875, learning_rate 0.000832929\n","2023-06-27T18:04:26.231101: step 2438, loss 0.0530605, acc 1, learning_rate 0.000832427\n","2023-06-27T18:04:26.354005: step 2439, loss 0.0704525, acc 0.96875, learning_rate 0.000831924\n","2023-06-27T18:04:26.475912: step 2440, loss 0.0911093, acc 0.96875, learning_rate 0.000831422\n","2023-06-27T18:04:26.597744: step 2441, loss 0.0878569, acc 0.96875, learning_rate 0.000830921\n","2023-06-27T18:04:26.710810: step 2442, loss 0.0775118, acc 1, learning_rate 0.00083042\n","2023-06-27T18:04:26.830146: step 2443, loss 0.145505, acc 0.9375, learning_rate 0.000829919\n","2023-06-27T18:04:26.936959: step 2444, loss 0.196357, acc 0.875, learning_rate 0.000829418\n","2023-06-27T18:04:27.061578: step 2445, loss 0.029195, acc 1, learning_rate 0.000828918\n","2023-06-27T18:04:27.176258: step 2446, loss 0.186804, acc 0.9375, learning_rate 0.000828418\n","2023-06-27T18:04:27.287690: step 2447, loss 0.045916, acc 0.96875, learning_rate 0.000827919\n","2023-06-27T18:04:27.417810: step 2448, loss 0.0427822, acc 1, learning_rate 0.00082742\n","2023-06-27T18:04:27.544279: step 2449, loss 0.0709358, acc 0.96875, learning_rate 0.000826921\n","2023-06-27T18:04:27.655228: step 2450, loss 0.271031, acc 0.875, learning_rate 0.000826422\n","2023-06-27T18:04:27.771764: step 2451, loss 0.0480829, acc 0.96875, learning_rate 0.000825924\n","2023-06-27T18:04:27.896562: step 2452, loss 0.129905, acc 0.9375, learning_rate 0.000825426\n","2023-06-27T18:04:28.017091: step 2453, loss 0.1528, acc 0.9375, learning_rate 0.000824929\n","2023-06-27T18:04:28.129441: step 2454, loss 0.0891846, acc 1, learning_rate 0.000824432\n","2023-06-27T18:04:28.248486: step 2455, loss 0.212598, acc 0.90625, learning_rate 0.000823935\n","2023-06-27T18:04:28.393235: step 2456, loss 0.0975993, acc 0.9375, learning_rate 0.000823439\n","2023-06-27T18:04:28.499223: step 2457, loss 0.121766, acc 0.96875, learning_rate 0.000822943\n","2023-06-27T18:04:28.628525: step 2458, loss 0.10664, acc 0.9375, learning_rate 0.000822447\n","2023-06-27T18:04:28.739191: step 2459, loss 0.0445498, acc 1, learning_rate 0.000821952\n","2023-06-27T18:04:28.875848: step 2460, loss 0.103281, acc 0.9375, learning_rate 0.000821456\n","2023-06-27T18:04:29.016025: step 2461, loss 0.0961694, acc 0.96875, learning_rate 0.000820962\n","2023-06-27T18:04:29.138581: step 2462, loss 0.103669, acc 0.96875, learning_rate 0.000820467\n","2023-06-27T18:04:29.268289: step 2463, loss 0.0647753, acc 0.96875, learning_rate 0.000819973\n","2023-06-27T18:04:29.395942: step 2464, loss 0.225709, acc 0.9375, learning_rate 0.00081948\n","2023-06-27T18:04:29.507368: step 2465, loss 0.0786128, acc 1, learning_rate 0.000818986\n","2023-06-27T18:04:29.627838: step 2466, loss 0.0888141, acc 0.9375, learning_rate 0.000818493\n","2023-06-27T18:04:29.754852: step 2467, loss 0.0738304, acc 0.96875, learning_rate 0.000818001\n","2023-06-27T18:04:29.873692: step 2468, loss 0.233367, acc 0.90625, learning_rate 0.000817508\n","2023-06-27T18:04:29.985171: step 2469, loss 0.106316, acc 0.9375, learning_rate 0.000817016\n","2023-06-27T18:04:30.100408: step 2470, loss 0.0130074, acc 1, learning_rate 0.000816524\n","2023-06-27T18:04:30.225542: step 2471, loss 0.0943873, acc 0.96875, learning_rate 0.000816033\n","2023-06-27T18:04:30.348021: step 2472, loss 0.0541643, acc 0.96875, learning_rate 0.000815542\n","2023-06-27T18:04:30.462026: step 2473, loss 0.0532358, acc 0.96875, learning_rate 0.000815051\n","2023-06-27T18:04:30.570599: step 2474, loss 0.188589, acc 0.90625, learning_rate 0.000814561\n","2023-06-27T18:04:30.700693: step 2475, loss 0.111862, acc 0.96875, learning_rate 0.000814071\n","2023-06-27T18:04:30.811346: step 2476, loss 0.219596, acc 0.90625, learning_rate 0.000813582\n","2023-06-27T18:04:30.952152: step 2477, loss 0.199681, acc 0.9375, learning_rate 0.000813092\n","2023-06-27T18:04:31.066984: step 2478, loss 0.18608, acc 0.96875, learning_rate 0.000812603\n","2023-06-27T18:04:31.194124: step 2479, loss 0.0621572, acc 1, learning_rate 0.000812115\n","2023-06-27T18:04:31.316058: step 2480, loss 0.0503846, acc 1, learning_rate 0.000811626\n","2023-06-27T18:04:31.425435: step 2481, loss 0.0581624, acc 1, learning_rate 0.000811138\n","2023-06-27T18:04:31.541832: step 2482, loss 0.0565525, acc 0.96875, learning_rate 0.000810651\n","2023-06-27T18:04:31.681319: step 2483, loss 0.0674275, acc 1, learning_rate 0.000810163\n","2023-06-27T18:04:31.802653: step 2484, loss 0.0640622, acc 0.96875, learning_rate 0.000809676\n","2023-06-27T18:04:31.929851: step 2485, loss 0.0866268, acc 0.96875, learning_rate 0.00080919\n","2023-06-27T18:04:32.059211: step 2486, loss 0.221744, acc 0.90625, learning_rate 0.000808703\n","2023-06-27T18:04:32.182343: step 2487, loss 0.0274174, acc 1, learning_rate 0.000808217\n","2023-06-27T18:04:32.304099: step 2488, loss 0.0206926, acc 1, learning_rate 0.000807732\n","2023-06-27T18:04:32.415798: step 2489, loss 0.308325, acc 0.875, learning_rate 0.000807246\n","2023-06-27T18:04:32.527261: step 2490, loss 0.139928, acc 0.96875, learning_rate 0.000806761\n","2023-06-27T18:04:32.649623: step 2491, loss 0.0520434, acc 1, learning_rate 0.000806277\n","2023-06-27T18:04:32.762155: step 2492, loss 0.25874, acc 0.90625, learning_rate 0.000805793\n","2023-06-27T18:04:32.874408: step 2493, loss 0.03516, acc 0.96875, learning_rate 0.000805309\n","2023-06-27T18:04:33.022170: step 2494, loss 0.151054, acc 0.9375, learning_rate 0.000804825\n","2023-06-27T18:04:33.147775: step 2495, loss 0.121803, acc 0.9375, learning_rate 0.000804342\n","2023-06-27T18:04:33.265616: step 2496, loss 0.198222, acc 0.875, learning_rate 0.000803859\n","2023-06-27T18:04:33.380698: step 2497, loss 0.209837, acc 0.9375, learning_rate 0.000803376\n","2023-06-27T18:04:33.502763: step 2498, loss 0.0703593, acc 0.96875, learning_rate 0.000802894\n","2023-06-27T18:04:33.619074: step 2499, loss 0.0478975, acc 1, learning_rate 0.000802412\n","\n","Evaluation:\n","2023-06-27T18:04:34.380082: step 2500, loss 0.657632, acc 0.802959\n","\n","Saved model checkpoint to /content/gdrive/MyDrive/lightweighted-cnn/train/runs/1687888658/checkpoints/model-2500\n","\n","2023-06-27T18:04:34.594327: step 2500, loss 0.0771506, acc 0.96875, learning_rate 0.00080193\n","2023-06-27T18:04:34.728519: step 2501, loss 0.0159092, acc 1, learning_rate 0.000801449\n","2023-06-27T18:04:34.844737: step 2502, loss 0.143471, acc 0.90625, learning_rate 0.000800968\n","2023-06-27T18:04:34.964889: step 2503, loss 0.134402, acc 0.90625, learning_rate 0.000800487\n","2023-06-27T18:04:35.099894: step 2504, loss 0.104824, acc 0.96875, learning_rate 0.000800007\n","2023-06-27T18:04:35.214786: step 2505, loss 0.122739, acc 0.9375, learning_rate 0.000799527\n","2023-06-27T18:04:35.341240: step 2506, loss 0.162008, acc 0.9375, learning_rate 0.000799047\n","2023-06-27T18:04:35.465214: step 2507, loss 0.0931773, acc 1, learning_rate 0.000798568\n","2023-06-27T18:04:35.650399: step 2508, loss 0.045891, acc 1, learning_rate 0.000798089\n","2023-06-27T18:04:35.862409: step 2509, loss 0.065485, acc 1, learning_rate 0.00079761\n","2023-06-27T18:04:36.087438: step 2510, loss 0.140642, acc 0.9375, learning_rate 0.000797132\n","2023-06-27T18:04:36.312569: step 2511, loss 0.0704437, acc 0.96875, learning_rate 0.000796653\n","2023-06-27T18:04:36.527968: step 2512, loss 0.158282, acc 0.90625, learning_rate 0.000796176\n","2023-06-27T18:04:36.743601: step 2513, loss 0.138753, acc 0.9375, learning_rate 0.000795698\n","2023-06-27T18:04:36.966441: step 2514, loss 0.061514, acc 0.96875, learning_rate 0.000795221\n","2023-06-27T18:04:37.186659: step 2515, loss 0.0746694, acc 0.96875, learning_rate 0.000794745\n","2023-06-27T18:04:37.389693: step 2516, loss 0.0370133, acc 1, learning_rate 0.000794268\n","2023-06-27T18:04:37.588820: step 2517, loss 0.113208, acc 0.96875, learning_rate 0.000793792\n","2023-06-27T18:04:37.799130: step 2518, loss 0.109475, acc 0.9375, learning_rate 0.000793316\n","2023-06-27T18:04:38.008864: step 2519, loss 0.0821685, acc 0.9375, learning_rate 0.000792841\n","2023-06-27T18:04:38.202282: step 2520, loss 0.192608, acc 0.90625, learning_rate 0.000792366\n","2023-06-27T18:04:38.409690: step 2521, loss 0.0893147, acc 0.9375, learning_rate 0.000791891\n","2023-06-27T18:04:38.600327: step 2522, loss 0.310668, acc 0.9375, learning_rate 0.000791417\n","2023-06-27T18:04:38.803530: step 2523, loss 0.139513, acc 0.9375, learning_rate 0.000790942\n","2023-06-27T18:04:38.995924: step 2524, loss 0.13562, acc 1, learning_rate 0.000790469\n","2023-06-27T18:04:39.197941: step 2525, loss 0.0881115, acc 0.96875, learning_rate 0.000789995\n","2023-06-27T18:04:39.379590: step 2526, loss 0.143953, acc 0.9375, learning_rate 0.000789522\n","2023-06-27T18:04:39.580948: step 2527, loss 0.0824603, acc 0.9375, learning_rate 0.000789049\n","2023-06-27T18:04:39.765064: step 2528, loss 0.063913, acc 1, learning_rate 0.000788577\n","2023-06-27T18:04:39.950342: step 2529, loss 0.182204, acc 0.96875, learning_rate 0.000788105\n","2023-06-27T18:04:40.197689: step 2530, loss 0.0805051, acc 0.96875, learning_rate 0.000787633\n","2023-06-27T18:04:40.420757: step 2531, loss 0.084414, acc 1, learning_rate 0.000787161\n","2023-06-27T18:04:40.594941: step 2532, loss 0.202649, acc 0.9375, learning_rate 0.00078669\n","2023-06-27T18:04:40.774636: step 2533, loss 0.103614, acc 1, learning_rate 0.000786219\n","2023-06-27T18:04:40.964022: step 2534, loss 0.196777, acc 0.9375, learning_rate 0.000785749\n","2023-06-27T18:04:41.164616: step 2535, loss 0.107629, acc 0.96875, learning_rate 0.000785278\n","2023-06-27T18:04:41.343256: step 2536, loss 0.202956, acc 0.90625, learning_rate 0.000784808\n","2023-06-27T18:04:41.524037: step 2537, loss 0.0495503, acc 1, learning_rate 0.000784339\n","2023-06-27T18:04:41.704628: step 2538, loss 0.0842927, acc 0.96875, learning_rate 0.00078387\n","2023-06-27T18:04:41.909792: step 2539, loss 0.137995, acc 0.96875, learning_rate 0.000783401\n","2023-06-27T18:04:42.099199: step 2540, loss 0.097494, acc 0.96875, learning_rate 0.000782932\n","2023-06-27T18:04:42.273033: step 2541, loss 0.0897107, acc 0.9375, learning_rate 0.000782464\n","2023-06-27T18:04:42.480839: step 2542, loss 0.0634692, acc 1, learning_rate 0.000781996\n","2023-06-27T18:04:42.676459: step 2543, loss 0.0712403, acc 0.96875, learning_rate 0.000781528\n","2023-06-27T18:04:42.859139: step 2544, loss 0.0256728, acc 1, learning_rate 0.000781061\n","2023-06-27T18:04:43.050371: step 2545, loss 0.106174, acc 0.9375, learning_rate 0.000780594\n","2023-06-27T18:04:43.246763: step 2546, loss 0.141942, acc 0.9375, learning_rate 0.000780127\n","2023-06-27T18:04:43.450287: step 2547, loss 0.0786537, acc 0.96875, learning_rate 0.000779661\n","2023-06-27T18:04:43.633363: step 2548, loss 0.0676567, acc 0.96875, learning_rate 0.000779195\n","2023-06-27T18:04:43.818051: step 2549, loss 0.0655565, acc 1, learning_rate 0.000778729\n","2023-06-27T18:04:43.991184: step 2550, loss 0.142326, acc 0.96875, learning_rate 0.000778263\n","2023-06-27T18:04:44.166169: step 2551, loss 0.172446, acc 0.96875, learning_rate 0.000777798\n","2023-06-27T18:04:44.355549: step 2552, loss 0.0973739, acc 0.9375, learning_rate 0.000777334\n","2023-06-27T18:04:44.574879: step 2553, loss 0.13674, acc 0.9375, learning_rate 0.000776869\n","2023-06-27T18:04:44.773657: step 2554, loss 0.0234513, acc 1, learning_rate 0.000776405\n","2023-06-27T18:04:44.966734: step 2555, loss 0.0452246, acc 1, learning_rate 0.000775941\n","2023-06-27T18:04:45.149738: step 2556, loss 0.361842, acc 0.75, learning_rate 0.000775478\n","2023-06-27T18:04:45.354942: step 2557, loss 0.138239, acc 0.96875, learning_rate 0.000775014\n","2023-06-27T18:04:45.559707: step 2558, loss 0.0724552, acc 0.96875, learning_rate 0.000774551\n","2023-06-27T18:04:45.753827: step 2559, loss 0.162391, acc 0.90625, learning_rate 0.000774089\n","2023-06-27T18:04:45.939682: step 2560, loss 0.0793294, acc 1, learning_rate 0.000773627\n","2023-06-27T18:04:46.123351: step 2561, loss 0.0642598, acc 0.96875, learning_rate 0.000773165\n","2023-06-27T18:04:46.238918: step 2562, loss 0.00909437, acc 1, learning_rate 0.000772703\n","2023-06-27T18:04:46.376464: step 2563, loss 0.119958, acc 0.96875, learning_rate 0.000772242\n","2023-06-27T18:04:46.500885: step 2564, loss 0.123736, acc 0.9375, learning_rate 0.000771781\n","2023-06-27T18:04:46.622810: step 2565, loss 0.0435887, acc 1, learning_rate 0.00077132\n","2023-06-27T18:04:46.744288: step 2566, loss 0.0787631, acc 1, learning_rate 0.00077086\n","2023-06-27T18:04:46.859398: step 2567, loss 0.0278544, acc 1, learning_rate 0.0007704\n","2023-06-27T18:04:46.984962: step 2568, loss 0.0365126, acc 1, learning_rate 0.00076994\n","2023-06-27T18:04:47.102252: step 2569, loss 0.0600065, acc 0.96875, learning_rate 0.000769481\n","2023-06-27T18:04:47.220940: step 2570, loss 0.0448789, acc 1, learning_rate 0.000769022\n","2023-06-27T18:04:47.331200: step 2571, loss 0.0381633, acc 1, learning_rate 0.000768563\n","2023-06-27T18:04:47.442061: step 2572, loss 0.161243, acc 0.90625, learning_rate 0.000768104\n","2023-06-27T18:04:47.577613: step 2573, loss 0.0931667, acc 0.9375, learning_rate 0.000767646\n","2023-06-27T18:04:47.690846: step 2574, loss 0.113307, acc 0.96875, learning_rate 0.000767189\n","2023-06-27T18:04:47.798178: step 2575, loss 0.0879321, acc 0.96875, learning_rate 0.000766731\n","2023-06-27T18:04:47.926969: step 2576, loss 0.0325962, acc 1, learning_rate 0.000766274\n","2023-06-27T18:04:48.061288: step 2577, loss 0.0320967, acc 1, learning_rate 0.000765817\n","2023-06-27T18:04:48.176220: step 2578, loss 0.0511377, acc 0.96875, learning_rate 0.00076536\n","2023-06-27T18:04:48.309660: step 2579, loss 0.20865, acc 0.875, learning_rate 0.000764904\n","2023-06-27T18:04:48.433346: step 2580, loss 0.0704531, acc 0.96875, learning_rate 0.000764448\n","2023-06-27T18:04:48.562482: step 2581, loss 0.0345241, acc 1, learning_rate 0.000763993\n","2023-06-27T18:04:48.673494: step 2582, loss 0.0945079, acc 0.96875, learning_rate 0.000763537\n","2023-06-27T18:04:48.790536: step 2583, loss 0.10018, acc 0.9375, learning_rate 0.000763082\n","2023-06-27T18:04:48.906877: step 2584, loss 0.050744, acc 1, learning_rate 0.000762628\n","2023-06-27T18:04:49.020313: step 2585, loss 0.0914453, acc 0.9375, learning_rate 0.000762173\n","2023-06-27T18:04:49.135698: step 2586, loss 0.21169, acc 0.90625, learning_rate 0.000761719\n","2023-06-27T18:04:49.247854: step 2587, loss 0.0820263, acc 0.96875, learning_rate 0.000761265\n","2023-06-27T18:04:49.390341: step 2588, loss 0.0942041, acc 0.96875, learning_rate 0.000760812\n","2023-06-27T18:04:49.507418: step 2589, loss 0.123794, acc 0.9375, learning_rate 0.000760359\n","2023-06-27T18:04:49.626123: step 2590, loss 0.200758, acc 0.9375, learning_rate 0.000759906\n","2023-06-27T18:04:49.742737: step 2591, loss 0.0689883, acc 0.96875, learning_rate 0.000759453\n","2023-06-27T18:04:49.868870: step 2592, loss 0.0871904, acc 0.9375, learning_rate 0.000759001\n","2023-06-27T18:04:49.986216: step 2593, loss 0.0763999, acc 0.96875, learning_rate 0.000758549\n","2023-06-27T18:04:50.106643: step 2594, loss 0.0362188, acc 1, learning_rate 0.000758098\n","2023-06-27T18:04:50.234734: step 2595, loss 0.0165978, acc 1, learning_rate 0.000757646\n","2023-06-27T18:04:50.360632: step 2596, loss 0.0775258, acc 1, learning_rate 0.000757196\n","2023-06-27T18:04:50.481753: step 2597, loss 0.0555313, acc 1, learning_rate 0.000756745\n","2023-06-27T18:04:50.609442: step 2598, loss 0.0805733, acc 0.96875, learning_rate 0.000756295\n","2023-06-27T18:04:50.724540: step 2599, loss 0.0956354, acc 0.9375, learning_rate 0.000755844\n","\n","Evaluation:\n","2023-06-27T18:04:51.445979: step 2600, loss 0.665303, acc 0.805103\n","\n","Saved model checkpoint to /content/gdrive/MyDrive/lightweighted-cnn/train/runs/1687888658/checkpoints/model-2600\n","\n","2023-06-27T18:04:51.673108: step 2600, loss 0.0375705, acc 1, learning_rate 0.000755395\n","2023-06-27T18:04:51.798787: step 2601, loss 0.0935561, acc 0.9375, learning_rate 0.000754945\n","2023-06-27T18:04:51.925551: step 2602, loss 0.0482717, acc 1, learning_rate 0.000754496\n","2023-06-27T18:04:52.045389: step 2603, loss 0.232232, acc 0.875, learning_rate 0.000754047\n","2023-06-27T18:04:52.170260: step 2604, loss 0.126278, acc 0.9375, learning_rate 0.000753599\n","2023-06-27T18:04:52.308002: step 2605, loss 0.0869806, acc 0.96875, learning_rate 0.000753151\n","2023-06-27T18:04:52.422769: step 2606, loss 0.144113, acc 0.90625, learning_rate 0.000752703\n","2023-06-27T18:04:52.530128: step 2607, loss 0.0879447, acc 0.96875, learning_rate 0.000752255\n","2023-06-27T18:04:52.657785: step 2608, loss 0.0504814, acc 1, learning_rate 0.000751808\n","2023-06-27T18:04:52.774345: step 2609, loss 0.189868, acc 0.9375, learning_rate 0.000751361\n","2023-06-27T18:04:52.887485: step 2610, loss 0.136734, acc 0.9375, learning_rate 0.000750914\n","2023-06-27T18:04:53.019114: step 2611, loss 0.0323112, acc 0.96875, learning_rate 0.000750468\n","2023-06-27T18:04:53.135285: step 2612, loss 0.0184667, acc 1, learning_rate 0.000750022\n","2023-06-27T18:04:53.246294: step 2613, loss 0.113485, acc 0.9375, learning_rate 0.000749576\n","2023-06-27T18:04:53.372176: step 2614, loss 0.212801, acc 0.90625, learning_rate 0.000749131\n","2023-06-27T18:04:53.494350: step 2615, loss 0.0902909, acc 0.96875, learning_rate 0.000748686\n","2023-06-27T18:04:53.608305: step 2616, loss 0.144711, acc 0.90625, learning_rate 0.000748241\n","2023-06-27T18:04:53.736605: step 2617, loss 0.12213, acc 0.96875, learning_rate 0.000747796\n","2023-06-27T18:04:53.854370: step 2618, loss 0.101506, acc 0.9375, learning_rate 0.000747352\n","2023-06-27T18:04:53.977446: step 2619, loss 0.0634704, acc 0.96875, learning_rate 0.000746908\n","2023-06-27T18:04:54.086154: step 2620, loss 0.075178, acc 0.96875, learning_rate 0.000746465\n","2023-06-27T18:04:54.207706: step 2621, loss 0.120476, acc 0.96875, learning_rate 0.000746021\n","2023-06-27T18:04:54.324572: step 2622, loss 0.18083, acc 0.96875, learning_rate 0.000745578\n","2023-06-27T18:04:54.442819: step 2623, loss 0.0198644, acc 1, learning_rate 0.000745136\n","2023-06-27T18:04:54.585287: step 2624, loss 0.0846352, acc 0.96875, learning_rate 0.000744693\n","2023-06-27T18:04:54.707722: step 2625, loss 0.251847, acc 0.9375, learning_rate 0.000744251\n","2023-06-27T18:04:54.839178: step 2626, loss 0.0289882, acc 1, learning_rate 0.000743809\n","2023-06-27T18:04:54.957618: step 2627, loss 0.134485, acc 0.96875, learning_rate 0.000743368\n","2023-06-27T18:04:55.077483: step 2628, loss 0.160694, acc 0.9375, learning_rate 0.000742927\n","2023-06-27T18:04:55.198961: step 2629, loss 0.108781, acc 0.96875, learning_rate 0.000742486\n","2023-06-27T18:04:55.319631: step 2630, loss 0.0220709, acc 1, learning_rate 0.000742045\n","2023-06-27T18:04:55.443718: step 2631, loss 0.0315708, acc 1, learning_rate 0.000741605\n","2023-06-27T18:04:55.566894: step 2632, loss 0.0841041, acc 0.96875, learning_rate 0.000741165\n","2023-06-27T18:04:55.695843: step 2633, loss 0.0678688, acc 0.96875, learning_rate 0.000740725\n","2023-06-27T18:04:55.822735: step 2634, loss 0.0938752, acc 0.96875, learning_rate 0.000740286\n","2023-06-27T18:04:55.936686: step 2635, loss 0.192654, acc 0.9375, learning_rate 0.000739847\n","2023-06-27T18:04:56.060047: step 2636, loss 0.0144891, acc 1, learning_rate 0.000739408\n","2023-06-27T18:04:56.228046: step 2637, loss 0.169998, acc 0.9375, learning_rate 0.00073897\n","2023-06-27T18:04:56.414101: step 2638, loss 0.0350319, acc 1, learning_rate 0.000738532\n","2023-06-27T18:04:56.595176: step 2639, loss 0.137754, acc 0.96875, learning_rate 0.000738094\n","2023-06-27T18:04:56.776539: step 2640, loss 0.105804, acc 0.96875, learning_rate 0.000737656\n","2023-06-27T18:04:56.979786: step 2641, loss 0.255939, acc 0.90625, learning_rate 0.000737219\n","2023-06-27T18:04:57.184270: step 2642, loss 0.23608, acc 0.90625, learning_rate 0.000736782\n","2023-06-27T18:04:57.392922: step 2643, loss 0.120733, acc 1, learning_rate 0.000736345\n","2023-06-27T18:04:57.601810: step 2644, loss 0.201745, acc 0.96875, learning_rate 0.000735909\n","2023-06-27T18:04:57.794029: step 2645, loss 0.0634123, acc 0.96875, learning_rate 0.000735473\n","2023-06-27T18:04:57.989451: step 2646, loss 0.14338, acc 0.90625, learning_rate 0.000735037\n","2023-06-27T18:04:58.209246: step 2647, loss 0.0850944, acc 0.96875, learning_rate 0.000734602\n","2023-06-27T18:04:58.427544: step 2648, loss 0.195891, acc 0.9375, learning_rate 0.000734167\n","2023-06-27T18:04:58.655929: step 2649, loss 0.189936, acc 0.9375, learning_rate 0.000733732\n","2023-06-27T18:04:58.860688: step 2650, loss 0.0438628, acc 1, learning_rate 0.000733297\n","2023-06-27T18:04:59.062102: step 2651, loss 0.0556606, acc 0.96875, learning_rate 0.000732863\n","2023-06-27T18:04:59.276898: step 2652, loss 0.105637, acc 0.96875, learning_rate 0.000732429\n","2023-06-27T18:04:59.446454: step 2653, loss 0.164228, acc 0.96875, learning_rate 0.000731995\n","2023-06-27T18:04:59.666404: step 2654, loss 0.0816716, acc 0.96875, learning_rate 0.000731562\n","2023-06-27T18:04:59.868277: step 2655, loss 0.102951, acc 0.96875, learning_rate 0.000731129\n","2023-06-27T18:05:00.062626: step 2656, loss 0.158182, acc 0.875, learning_rate 0.000730696\n","2023-06-27T18:05:00.297269: step 2657, loss 0.0819083, acc 0.96875, learning_rate 0.000730264\n","2023-06-27T18:05:00.494818: step 2658, loss 0.143397, acc 0.9375, learning_rate 0.000729831\n","2023-06-27T18:05:00.680286: step 2659, loss 0.107873, acc 0.96875, learning_rate 0.000729399\n","2023-06-27T18:05:00.868373: step 2660, loss 0.0680333, acc 0.96875, learning_rate 0.000728968\n","2023-06-27T18:05:01.036967: step 2661, loss 0.0595721, acc 0.96875, learning_rate 0.000728537\n","2023-06-27T18:05:01.226684: step 2662, loss 0.0483556, acc 0.96875, learning_rate 0.000728106\n","2023-06-27T18:05:01.415274: step 2663, loss 0.168493, acc 0.96875, learning_rate 0.000727675\n","2023-06-27T18:05:01.603728: step 2664, loss 0.31561, acc 0.90625, learning_rate 0.000727244\n","2023-06-27T18:05:01.812082: step 2665, loss 0.102436, acc 0.96875, learning_rate 0.000726814\n","2023-06-27T18:05:02.002228: step 2666, loss 0.101738, acc 0.9375, learning_rate 0.000726385\n","2023-06-27T18:05:02.194579: step 2667, loss 0.0518261, acc 1, learning_rate 0.000725955\n","2023-06-27T18:05:02.381115: step 2668, loss 0.100007, acc 0.96875, learning_rate 0.000725526\n","2023-06-27T18:05:02.582103: step 2669, loss 0.114164, acc 0.96875, learning_rate 0.000725097\n","2023-06-27T18:05:02.766187: step 2670, loss 0.120317, acc 0.9375, learning_rate 0.000724668\n","2023-06-27T18:05:02.968635: step 2671, loss 0.0893525, acc 0.96875, learning_rate 0.00072424\n","2023-06-27T18:05:03.137956: step 2672, loss 0.0484135, acc 0.96875, learning_rate 0.000723812\n","2023-06-27T18:05:03.332491: step 2673, loss 0.12414, acc 0.9375, learning_rate 0.000723384\n","2023-06-27T18:05:03.535024: step 2674, loss 0.0651946, acc 0.96875, learning_rate 0.000722957\n","2023-06-27T18:05:03.714915: step 2675, loss 0.129502, acc 0.9375, learning_rate 0.000722529\n","2023-06-27T18:05:03.897802: step 2676, loss 0.116393, acc 0.9375, learning_rate 0.000722102\n","2023-06-27T18:05:04.098490: step 2677, loss 0.0908306, acc 1, learning_rate 0.000721676\n","2023-06-27T18:05:04.272290: step 2678, loss 0.0169222, acc 1, learning_rate 0.00072125\n","2023-06-27T18:05:04.475190: step 2679, loss 0.166507, acc 0.96875, learning_rate 0.000720824\n","2023-06-27T18:05:04.683861: step 2680, loss 0.0774893, acc 0.96875, learning_rate 0.000720398\n","2023-06-27T18:05:04.880711: step 2681, loss 0.147893, acc 0.9375, learning_rate 0.000719972\n","2023-06-27T18:05:05.064419: step 2682, loss 0.0371111, acc 0.96875, learning_rate 0.000719547\n","2023-06-27T18:05:05.263386: step 2683, loss 0.0770657, acc 1, learning_rate 0.000719122\n","2023-06-27T18:05:05.456614: step 2684, loss 0.0676925, acc 0.96875, learning_rate 0.000718698\n","2023-06-27T18:05:05.652667: step 2685, loss 0.133811, acc 0.90625, learning_rate 0.000718274\n","2023-06-27T18:05:05.835652: step 2686, loss 0.133982, acc 0.9375, learning_rate 0.00071785\n","2023-06-27T18:05:06.029379: step 2687, loss 0.152488, acc 0.9375, learning_rate 0.000717426\n","2023-06-27T18:05:06.219297: step 2688, loss 0.037876, acc 1, learning_rate 0.000717003\n","2023-06-27T18:05:06.392018: step 2689, loss 0.0287687, acc 1, learning_rate 0.00071658\n","2023-06-27T18:05:06.583114: step 2690, loss 0.0343413, acc 1, learning_rate 0.000716157\n","2023-06-27T18:05:06.773576: step 2691, loss 0.0840559, acc 0.96875, learning_rate 0.000715734\n","2023-06-27T18:05:06.945306: step 2692, loss 0.131248, acc 0.9375, learning_rate 0.000715312\n","2023-06-27T18:05:07.083385: step 2693, loss 0.0764662, acc 0.96875, learning_rate 0.00071489\n","2023-06-27T18:05:07.213627: step 2694, loss 0.11296, acc 0.96875, learning_rate 0.000714468\n","2023-06-27T18:05:07.339677: step 2695, loss 0.310935, acc 0.84375, learning_rate 0.000714047\n","2023-06-27T18:05:07.457974: step 2696, loss 0.173942, acc 0.875, learning_rate 0.000713626\n","2023-06-27T18:05:07.583657: step 2697, loss 0.0771083, acc 0.96875, learning_rate 0.000713205\n","2023-06-27T18:05:07.698672: step 2698, loss 0.154068, acc 0.96875, learning_rate 0.000712785\n","2023-06-27T18:05:07.813816: step 2699, loss 0.122658, acc 0.9375, learning_rate 0.000712365\n","\n","Evaluation:\n","2023-06-27T18:05:08.560869: step 2700, loss 0.679227, acc 0.797384\n","\n","Saved model checkpoint to /content/gdrive/MyDrive/lightweighted-cnn/train/runs/1687888658/checkpoints/model-2700\n","\n","2023-06-27T18:05:08.774846: step 2700, loss 0.242862, acc 0.90625, learning_rate 0.000711945\n","2023-06-27T18:05:08.891717: step 2701, loss 0.0366482, acc 1, learning_rate 0.000711525\n","2023-06-27T18:05:09.007372: step 2702, loss 0.185601, acc 0.9375, learning_rate 0.000711106\n","2023-06-27T18:05:09.131355: step 2703, loss 0.155949, acc 0.9375, learning_rate 0.000710687\n","2023-06-27T18:05:09.255973: step 2704, loss 0.0790011, acc 0.96875, learning_rate 0.000710268\n","2023-06-27T18:05:09.371965: step 2705, loss 0.0758637, acc 0.9375, learning_rate 0.000709849\n","2023-06-27T18:05:09.495547: step 2706, loss 0.225526, acc 0.90625, learning_rate 0.000709431\n","2023-06-27T18:05:09.610148: step 2707, loss 0.0937692, acc 0.96875, learning_rate 0.000709013\n","2023-06-27T18:05:09.734082: step 2708, loss 0.120667, acc 0.96875, learning_rate 0.000708596\n","2023-06-27T18:05:09.850614: step 2709, loss 0.111987, acc 0.9375, learning_rate 0.000708178\n","2023-06-27T18:05:09.974299: step 2710, loss 0.0278665, acc 1, learning_rate 0.000707761\n","2023-06-27T18:05:10.130343: step 2711, loss 0.0699346, acc 1, learning_rate 0.000707345\n","2023-06-27T18:05:10.247911: step 2712, loss 0.0950651, acc 0.9375, learning_rate 0.000706928\n","2023-06-27T18:05:10.370234: step 2713, loss 0.140302, acc 0.9375, learning_rate 0.000706512\n","2023-06-27T18:05:10.488482: step 2714, loss 0.035209, acc 1, learning_rate 0.000706096\n","2023-06-27T18:05:10.597746: step 2715, loss 0.0970502, acc 0.96875, learning_rate 0.00070568\n","2023-06-27T18:05:10.721592: step 2716, loss 0.0721708, acc 0.96875, learning_rate 0.000705265\n","2023-06-27T18:05:10.835878: step 2717, loss 0.0842158, acc 0.96875, learning_rate 0.00070485\n","2023-06-27T18:05:10.960669: step 2718, loss 0.272002, acc 0.8125, learning_rate 0.000704435\n","2023-06-27T18:05:11.070491: step 2719, loss 0.114588, acc 0.96875, learning_rate 0.000704021\n","2023-06-27T18:05:11.189675: step 2720, loss 0.142332, acc 0.90625, learning_rate 0.000703607\n","2023-06-27T18:05:11.302644: step 2721, loss 0.143668, acc 0.9375, learning_rate 0.000703193\n","2023-06-27T18:05:11.424763: step 2722, loss 0.0540842, acc 0.96875, learning_rate 0.000702779\n","2023-06-27T18:05:11.549569: step 2723, loss 0.0767389, acc 0.96875, learning_rate 0.000702366\n","2023-06-27T18:05:11.665123: step 2724, loss 0.0793547, acc 0.96875, learning_rate 0.000701953\n","2023-06-27T18:05:11.783301: step 2725, loss 0.24371, acc 0.90625, learning_rate 0.00070154\n","2023-06-27T18:05:11.902084: step 2726, loss 0.132985, acc 0.9375, learning_rate 0.000701127\n","2023-06-27T18:05:12.018468: step 2727, loss 0.0957571, acc 0.9375, learning_rate 0.000700715\n","2023-06-27T18:05:12.150323: step 2728, loss 0.0672373, acc 1, learning_rate 0.000700303\n","2023-06-27T18:05:12.279853: step 2729, loss 0.0708985, acc 0.96875, learning_rate 0.000699892\n","2023-06-27T18:05:12.400374: step 2730, loss 0.0460609, acc 1, learning_rate 0.00069948\n","2023-06-27T18:05:12.514559: step 2731, loss 0.0433146, acc 1, learning_rate 0.000699069\n","2023-06-27T18:05:12.637363: step 2732, loss 0.337891, acc 0.90625, learning_rate 0.000698658\n","2023-06-27T18:05:12.749886: step 2733, loss 0.0630655, acc 1, learning_rate 0.000698248\n","2023-06-27T18:05:12.867768: step 2734, loss 0.270836, acc 0.875, learning_rate 0.000697838\n","2023-06-27T18:05:12.983876: step 2735, loss 0.0268724, acc 1, learning_rate 0.000697428\n","2023-06-27T18:05:13.101012: step 2736, loss 0.0841135, acc 0.96875, learning_rate 0.000697018\n","2023-06-27T18:05:13.234546: step 2737, loss 0.168463, acc 0.9375, learning_rate 0.000696609\n","2023-06-27T18:05:13.365255: step 2738, loss 0.115237, acc 0.96875, learning_rate 0.0006962\n","2023-06-27T18:05:13.494251: step 2739, loss 0.159722, acc 0.90625, learning_rate 0.000695791\n","2023-06-27T18:05:13.610011: step 2740, loss 0.107218, acc 0.96875, learning_rate 0.000695382\n","2023-06-27T18:05:13.730497: step 2741, loss 0.10514, acc 1, learning_rate 0.000694974\n","2023-06-27T18:05:13.853169: step 2742, loss 0.45817, acc 0.875, learning_rate 0.000694566\n","2023-06-27T18:05:13.974105: step 2743, loss 0.180991, acc 0.9375, learning_rate 0.000694158\n","2023-06-27T18:05:14.096192: step 2744, loss 0.103554, acc 0.9375, learning_rate 0.000693751\n","2023-06-27T18:05:14.214874: step 2745, loss 0.186929, acc 0.9375, learning_rate 0.000693344\n","2023-06-27T18:05:14.338739: step 2746, loss 0.191601, acc 0.9375, learning_rate 0.000692937\n","2023-06-27T18:05:14.461367: step 2747, loss 0.0501972, acc 1, learning_rate 0.00069253\n","2023-06-27T18:05:14.584325: step 2748, loss 0.0862388, acc 0.9375, learning_rate 0.000692124\n","2023-06-27T18:05:14.706992: step 2749, loss 0.0939698, acc 0.96875, learning_rate 0.000691718\n","2023-06-27T18:05:14.816811: step 2750, loss 0.0486719, acc 1, learning_rate 0.000691312\n","2023-06-27T18:05:14.926428: step 2751, loss 0.159929, acc 0.96875, learning_rate 0.000690907\n","2023-06-27T18:05:15.046138: step 2752, loss 0.0833223, acc 1, learning_rate 0.000690501\n","2023-06-27T18:05:15.171040: step 2753, loss 0.128253, acc 0.9375, learning_rate 0.000690096\n","2023-06-27T18:05:15.327056: step 2754, loss 0.0681947, acc 0.96875, learning_rate 0.000689692\n","2023-06-27T18:05:15.456525: step 2755, loss 0.123347, acc 0.9375, learning_rate 0.000689287\n","2023-06-27T18:05:15.582452: step 2756, loss 0.0626798, acc 1, learning_rate 0.000688883\n","2023-06-27T18:05:15.720407: step 2757, loss 0.353796, acc 0.875, learning_rate 0.00068848\n","2023-06-27T18:05:15.837371: step 2758, loss 0.0786351, acc 0.96875, learning_rate 0.000688076\n","2023-06-27T18:05:15.968362: step 2759, loss 0.173474, acc 0.9375, learning_rate 0.000687673\n","2023-06-27T18:05:16.093950: step 2760, loss 0.114623, acc 0.9375, learning_rate 0.00068727\n","2023-06-27T18:05:16.210333: step 2761, loss 0.0750315, acc 0.96875, learning_rate 0.000686867\n","2023-06-27T18:05:16.346468: step 2762, loss 0.134227, acc 0.9375, learning_rate 0.000686465\n","2023-06-27T18:05:16.467058: step 2763, loss 0.0693451, acc 1, learning_rate 0.000686062\n","2023-06-27T18:05:16.595031: step 2764, loss 0.0280206, acc 1, learning_rate 0.000685661\n","2023-06-27T18:05:16.731905: step 2765, loss 0.351099, acc 0.96875, learning_rate 0.000685259\n","2023-06-27T18:05:16.854265: step 2766, loss 0.0890519, acc 1, learning_rate 0.000684858\n","2023-06-27T18:05:17.010472: step 2767, loss 0.106615, acc 0.96875, learning_rate 0.000684457\n","2023-06-27T18:05:17.206750: step 2768, loss 0.131506, acc 0.9375, learning_rate 0.000684056\n","2023-06-27T18:05:17.418455: step 2769, loss 0.11501, acc 0.9375, learning_rate 0.000683655\n","2023-06-27T18:05:17.616524: step 2770, loss 0.076675, acc 0.96875, learning_rate 0.000683255\n","2023-06-27T18:05:17.822561: step 2771, loss 0.0699946, acc 0.96875, learning_rate 0.000682855\n","2023-06-27T18:05:18.029638: step 2772, loss 0.104752, acc 0.9375, learning_rate 0.000682455\n","2023-06-27T18:05:18.237745: step 2773, loss 0.220939, acc 0.96875, learning_rate 0.000682056\n","2023-06-27T18:05:18.469159: step 2774, loss 0.124369, acc 0.9375, learning_rate 0.000681657\n","2023-06-27T18:05:18.687300: step 2775, loss 0.0643395, acc 0.96875, learning_rate 0.000681258\n","2023-06-27T18:05:18.895578: step 2776, loss 0.0482876, acc 0.96875, learning_rate 0.000680859\n","2023-06-27T18:05:19.097660: step 2777, loss 0.0283021, acc 1, learning_rate 0.000680461\n","2023-06-27T18:05:19.315616: step 2778, loss 0.174888, acc 0.9375, learning_rate 0.000680063\n","2023-06-27T18:05:19.531501: step 2779, loss 0.0633306, acc 0.96875, learning_rate 0.000679665\n","2023-06-27T18:05:19.759123: step 2780, loss 0.190197, acc 0.9375, learning_rate 0.000679268\n","2023-06-27T18:05:19.966617: step 2781, loss 0.29766, acc 0.90625, learning_rate 0.000678871\n","2023-06-27T18:05:20.188209: step 2782, loss 0.0492043, acc 0.96875, learning_rate 0.000678474\n","2023-06-27T18:05:20.414534: step 2783, loss 0.210557, acc 0.90625, learning_rate 0.000678077\n","2023-06-27T18:05:20.615397: step 2784, loss 0.0877826, acc 0.96875, learning_rate 0.000677681\n","2023-06-27T18:05:20.821699: step 2785, loss 0.10061, acc 0.96875, learning_rate 0.000677285\n","2023-06-27T18:05:21.017432: step 2786, loss 0.0858029, acc 0.9375, learning_rate 0.000676889\n","2023-06-27T18:05:21.193692: step 2787, loss 0.0737306, acc 0.96875, learning_rate 0.000676493\n","2023-06-27T18:05:21.395855: step 2788, loss 0.0486741, acc 1, learning_rate 0.000676098\n","2023-06-27T18:05:21.608641: step 2789, loss 0.0470003, acc 0.96875, learning_rate 0.000675703\n","2023-06-27T18:05:21.807995: step 2790, loss 0.0200333, acc 1, learning_rate 0.000675308\n","2023-06-27T18:05:22.013584: step 2791, loss 0.106035, acc 0.9375, learning_rate 0.000674913\n","2023-06-27T18:05:22.205140: step 2792, loss 0.0552538, acc 0.96875, learning_rate 0.000674519\n","2023-06-27T18:05:22.409091: step 2793, loss 0.149022, acc 0.96875, learning_rate 0.000674125\n","2023-06-27T18:05:22.617050: step 2794, loss 0.0867927, acc 0.96875, learning_rate 0.000673732\n","2023-06-27T18:05:22.836754: step 2795, loss 0.201031, acc 0.875, learning_rate 0.000673338\n","2023-06-27T18:05:23.043472: step 2796, loss 0.0317954, acc 1, learning_rate 0.000672945\n","2023-06-27T18:05:23.246495: step 2797, loss 0.0949041, acc 0.9375, learning_rate 0.000672552\n","2023-06-27T18:05:23.457206: step 2798, loss 0.0396804, acc 1, learning_rate 0.000672159\n","2023-06-27T18:05:23.682711: step 2799, loss 0.0443921, acc 0.96875, learning_rate 0.000671767\n","\n","Evaluation:\n","2023-06-27T18:05:25.119497: step 2800, loss 0.679568, acc 0.801887\n","\n","Saved model checkpoint to /content/gdrive/MyDrive/lightweighted-cnn/train/runs/1687888658/checkpoints/model-2800\n","\n","2023-06-27T18:05:25.457566: step 2800, loss 0.270742, acc 0.90625, learning_rate 0.000671375\n","2023-06-27T18:05:25.648925: step 2801, loss 0.109065, acc 1, learning_rate 0.000670983\n","2023-06-27T18:05:25.843632: step 2802, loss 0.0944557, acc 0.96875, learning_rate 0.000670592\n","2023-06-27T18:05:26.023401: step 2803, loss 0.0813034, acc 0.96875, learning_rate 0.0006702\n","2023-06-27T18:05:26.214357: step 2804, loss 0.0756283, acc 1, learning_rate 0.000669809\n","2023-06-27T18:05:26.406834: step 2805, loss 0.0573013, acc 1, learning_rate 0.000669419\n","2023-06-27T18:05:26.585960: step 2806, loss 0.08748, acc 0.96875, learning_rate 0.000669028\n","2023-06-27T18:05:26.777251: step 2807, loss 0.0786722, acc 0.96875, learning_rate 0.000668638\n","2023-06-27T18:05:26.969983: step 2808, loss 0.154397, acc 0.9375, learning_rate 0.000668248\n","2023-06-27T18:05:27.144089: step 2809, loss 0.0958922, acc 0.96875, learning_rate 0.000667858\n","2023-06-27T18:05:27.346131: step 2810, loss 0.138282, acc 0.9375, learning_rate 0.000667469\n","2023-06-27T18:05:27.529177: step 2811, loss 0.0514408, acc 1, learning_rate 0.00066708\n","2023-06-27T18:05:27.733613: step 2812, loss 0.107588, acc 0.9375, learning_rate 0.000666691\n","2023-06-27T18:05:27.850672: step 2813, loss 0.192374, acc 0.90625, learning_rate 0.000666303\n","2023-06-27T18:05:27.981364: step 2814, loss 0.109512, acc 0.96875, learning_rate 0.000665914\n","2023-06-27T18:05:28.102942: step 2815, loss 0.180783, acc 0.9375, learning_rate 0.000665526\n","2023-06-27T18:05:28.237321: step 2816, loss 0.0777832, acc 0.9375, learning_rate 0.000665138\n","2023-06-27T18:05:28.361895: step 2817, loss 0.114325, acc 0.9375, learning_rate 0.000664751\n","2023-06-27T18:05:28.483911: step 2818, loss 0.213301, acc 0.875, learning_rate 0.000664364\n","2023-06-27T18:05:28.611519: step 2819, loss 0.0841926, acc 0.96875, learning_rate 0.000663977\n","2023-06-27T18:05:28.732449: step 2820, loss 0.0576624, acc 0.96875, learning_rate 0.00066359\n","2023-06-27T18:05:28.882126: step 2821, loss 0.0455631, acc 1, learning_rate 0.000663203\n","2023-06-27T18:05:29.030636: step 2822, loss 0.0853069, acc 0.96875, learning_rate 0.000662817\n","2023-06-27T18:05:29.160730: step 2823, loss 0.0838024, acc 0.96875, learning_rate 0.000662431\n","2023-06-27T18:05:29.290430: step 2824, loss 0.193847, acc 0.875, learning_rate 0.000662046\n","2023-06-27T18:05:29.409099: step 2825, loss 0.0445086, acc 0.96875, learning_rate 0.00066166\n","2023-06-27T18:05:29.546703: step 2826, loss 0.0460344, acc 1, learning_rate 0.000661275\n","2023-06-27T18:05:29.658628: step 2827, loss 0.0859625, acc 0.96875, learning_rate 0.00066089\n","2023-06-27T18:05:29.778634: step 2828, loss 0.10014, acc 1, learning_rate 0.000660505\n","2023-06-27T18:05:29.906788: step 2829, loss 0.0211684, acc 1, learning_rate 0.000660121\n","2023-06-27T18:05:30.020820: step 2830, loss 0.0534627, acc 1, learning_rate 0.000659737\n","2023-06-27T18:05:30.131425: step 2831, loss 0.0481258, acc 0.96875, learning_rate 0.000659353\n","2023-06-27T18:05:30.296240: step 2832, loss 0.0766991, acc 0.96875, learning_rate 0.00065897\n","2023-06-27T18:05:30.417296: step 2833, loss 0.0384125, acc 1, learning_rate 0.000658586\n","2023-06-27T18:05:30.529423: step 2834, loss 0.0356936, acc 1, learning_rate 0.000658203\n","2023-06-27T18:05:30.651026: step 2835, loss 0.153405, acc 0.9375, learning_rate 0.000657821\n","2023-06-27T18:05:30.769520: step 2836, loss 0.0155474, acc 1, learning_rate 0.000657438\n","2023-06-27T18:05:30.897045: step 2837, loss 0.0297467, acc 1, learning_rate 0.000657056\n","2023-06-27T18:05:31.014624: step 2838, loss 0.0460773, acc 0.96875, learning_rate 0.000656674\n","2023-06-27T18:05:31.124923: step 2839, loss 0.142786, acc 0.96875, learning_rate 0.000656292\n","2023-06-27T18:05:31.242710: step 2840, loss 0.134039, acc 0.96875, learning_rate 0.000655911\n","2023-06-27T18:05:31.357471: step 2841, loss 0.100907, acc 0.96875, learning_rate 0.000655529\n","2023-06-27T18:05:31.479404: step 2842, loss 0.185504, acc 0.96875, learning_rate 0.000655148\n","2023-06-27T18:05:31.613389: step 2843, loss 0.0649193, acc 1, learning_rate 0.000654768\n","2023-06-27T18:05:31.726927: step 2844, loss 0.171695, acc 0.90625, learning_rate 0.000654387\n","2023-06-27T18:05:31.853127: step 2845, loss 0.019604, acc 1, learning_rate 0.000654007\n","2023-06-27T18:05:31.978130: step 2846, loss 0.0444767, acc 1, learning_rate 0.000653627\n","2023-06-27T18:05:32.094335: step 2847, loss 0.0481737, acc 1, learning_rate 0.000653248\n","2023-06-27T18:05:32.219008: step 2848, loss 0.0440061, acc 1, learning_rate 0.000652868\n","2023-06-27T18:05:32.343870: step 2849, loss 0.136321, acc 0.96875, learning_rate 0.000652489\n","2023-06-27T18:05:32.463731: step 2850, loss 0.0645652, acc 0.9375, learning_rate 0.00065211\n","2023-06-27T18:05:32.587109: step 2851, loss 0.127465, acc 0.9375, learning_rate 0.000651732\n","2023-06-27T18:05:32.709987: step 2852, loss 0.0806447, acc 1, learning_rate 0.000651353\n","2023-06-27T18:05:32.825693: step 2853, loss 0.138863, acc 0.90625, learning_rate 0.000650975\n","2023-06-27T18:05:32.954339: step 2854, loss 0.186435, acc 0.9375, learning_rate 0.000650598\n","2023-06-27T18:05:33.090225: step 2855, loss 0.111155, acc 1, learning_rate 0.00065022\n","2023-06-27T18:05:33.214540: step 2856, loss 0.102555, acc 0.96875, learning_rate 0.000649843\n","2023-06-27T18:05:33.320717: step 2857, loss 0.377999, acc 0.84375, learning_rate 0.000649466\n","2023-06-27T18:05:33.447381: step 2858, loss 0.108083, acc 0.96875, learning_rate 0.000649089\n","2023-06-27T18:05:33.567850: step 2859, loss 0.0804708, acc 0.9375, learning_rate 0.000648712\n","2023-06-27T18:05:33.695538: step 2860, loss 0.149435, acc 0.96875, learning_rate 0.000648336\n","2023-06-27T18:05:33.819421: step 2861, loss 0.158649, acc 0.96875, learning_rate 0.00064796\n","2023-06-27T18:05:33.944744: step 2862, loss 0.0663135, acc 1, learning_rate 0.000647584\n","2023-06-27T18:05:34.071284: step 2863, loss 0.073956, acc 0.96875, learning_rate 0.000647209\n","2023-06-27T18:05:34.200304: step 2864, loss 0.00902296, acc 1, learning_rate 0.000646834\n","2023-06-27T18:05:34.325772: step 2865, loss 0.0270265, acc 1, learning_rate 0.000646459\n","2023-06-27T18:05:34.459137: step 2866, loss 0.0449318, acc 1, learning_rate 0.000646084\n","2023-06-27T18:05:34.588878: step 2867, loss 0.0414946, acc 0.96875, learning_rate 0.000645709\n","2023-06-27T18:05:34.718035: step 2868, loss 0.0438833, acc 1, learning_rate 0.000645335\n","2023-06-27T18:05:34.844194: step 2869, loss 0.0584331, acc 1, learning_rate 0.000644961\n","2023-06-27T18:05:34.966202: step 2870, loss 0.0248343, acc 1, learning_rate 0.000644588\n","2023-06-27T18:05:35.095552: step 2871, loss 0.0582654, acc 1, learning_rate 0.000644214\n","2023-06-27T18:05:35.217367: step 2872, loss 0.160064, acc 0.875, learning_rate 0.000643841\n","2023-06-27T18:05:35.335969: step 2873, loss 0.147619, acc 0.9375, learning_rate 0.000643468\n","2023-06-27T18:05:35.456530: step 2874, loss 0.100749, acc 1, learning_rate 0.000643095\n","2023-06-27T18:05:35.590690: step 2875, loss 0.0389622, acc 0.96875, learning_rate 0.000642723\n","2023-06-27T18:05:35.710724: step 2876, loss 0.0734635, acc 0.96875, learning_rate 0.000642351\n","2023-06-27T18:05:35.827779: step 2877, loss 0.0998666, acc 0.96875, learning_rate 0.000641979\n","2023-06-27T18:05:35.935924: step 2878, loss 0.0815389, acc 0.96875, learning_rate 0.000641607\n","2023-06-27T18:05:36.064060: step 2879, loss 0.139111, acc 0.90625, learning_rate 0.000641236\n","2023-06-27T18:05:36.191808: step 2880, loss 0.0371245, acc 0.96875, learning_rate 0.000640865\n","2023-06-27T18:05:36.303733: step 2881, loss 0.255799, acc 0.90625, learning_rate 0.000640494\n","2023-06-27T18:05:36.426842: step 2882, loss 0.0246736, acc 1, learning_rate 0.000640123\n","2023-06-27T18:05:36.545491: step 2883, loss 0.222167, acc 0.9375, learning_rate 0.000639753\n","2023-06-27T18:05:36.666235: step 2884, loss 0.0646806, acc 0.96875, learning_rate 0.000639383\n","2023-06-27T18:05:36.785490: step 2885, loss 0.0483404, acc 1, learning_rate 0.000639013\n","2023-06-27T18:05:36.905621: step 2886, loss 0.34668, acc 0.90625, learning_rate 0.000638643\n","2023-06-27T18:05:37.047924: step 2887, loss 0.0783248, acc 0.96875, learning_rate 0.000638274\n","2023-06-27T18:05:37.159653: step 2888, loss 0.171517, acc 0.90625, learning_rate 0.000637905\n","2023-06-27T18:05:37.283681: step 2889, loss 0.0483726, acc 0.96875, learning_rate 0.000637536\n","2023-06-27T18:05:37.413738: step 2890, loss 0.118674, acc 0.9375, learning_rate 0.000637167\n","2023-06-27T18:05:37.539225: step 2891, loss 0.0981568, acc 0.96875, learning_rate 0.000636799\n","2023-06-27T18:05:37.669268: step 2892, loss 0.0928906, acc 0.96875, learning_rate 0.000636431\n","2023-06-27T18:05:37.852958: step 2893, loss 0.196353, acc 0.90625, learning_rate 0.000636063\n","2023-06-27T18:05:38.066597: step 2894, loss 0.0245935, acc 1, learning_rate 0.000635695\n","2023-06-27T18:05:38.259623: step 2895, loss 0.173054, acc 0.96875, learning_rate 0.000635328\n","2023-06-27T18:05:38.464192: step 2896, loss 0.150974, acc 0.9375, learning_rate 0.000634961\n","2023-06-27T18:05:38.667906: step 2897, loss 0.0677692, acc 1, learning_rate 0.000634594\n","2023-06-27T18:05:38.876572: step 2898, loss 0.0593633, acc 1, learning_rate 0.000634228\n","2023-06-27T18:05:39.060012: step 2899, loss 0.0847062, acc 0.96875, learning_rate 0.000633861\n","\n","Evaluation:\n","2023-06-27T18:05:40.337740: step 2900, loss 0.694365, acc 0.798027\n","\n","Saved model checkpoint to /content/gdrive/MyDrive/lightweighted-cnn/train/runs/1687888658/checkpoints/model-2900\n","\n","2023-06-27T18:05:40.686329: step 2900, loss 0.127572, acc 0.96875, learning_rate 0.000633495\n","2023-06-27T18:05:40.893801: step 2901, loss 0.17616, acc 0.96875, learning_rate 0.000633129\n","2023-06-27T18:05:41.094859: step 2902, loss 0.0205074, acc 1, learning_rate 0.000632764\n","2023-06-27T18:05:41.298440: step 2903, loss 0.0678888, acc 1, learning_rate 0.000632398\n","2023-06-27T18:05:41.508351: step 2904, loss 0.0506694, acc 0.96875, learning_rate 0.000632033\n","2023-06-27T18:05:41.711124: step 2905, loss 0.114291, acc 0.9375, learning_rate 0.000631668\n","2023-06-27T18:05:41.908896: step 2906, loss 0.13123, acc 0.9375, learning_rate 0.000631304\n","2023-06-27T18:05:42.144207: step 2907, loss 0.114266, acc 0.96875, learning_rate 0.00063094\n","2023-06-27T18:05:42.325730: step 2908, loss 0.0576168, acc 0.96875, learning_rate 0.000630576\n","2023-06-27T18:05:42.509150: step 2909, loss 0.0901499, acc 0.9375, learning_rate 0.000630212\n","2023-06-27T18:05:42.715230: step 2910, loss 0.061568, acc 1, learning_rate 0.000629848\n","2023-06-27T18:05:42.902874: step 2911, loss 0.299117, acc 0.90625, learning_rate 0.000629485\n","2023-06-27T18:05:43.100540: step 2912, loss 0.0337115, acc 1, learning_rate 0.000629122\n","2023-06-27T18:05:43.287236: step 2913, loss 0.106439, acc 0.96875, learning_rate 0.000628759\n","2023-06-27T18:05:43.485495: step 2914, loss 0.220324, acc 0.90625, learning_rate 0.000628396\n","2023-06-27T18:05:43.685754: step 2915, loss 0.0811005, acc 0.96875, learning_rate 0.000628034\n","2023-06-27T18:05:43.890412: step 2916, loss 0.00330079, acc 1, learning_rate 0.000627672\n","2023-06-27T18:05:44.088825: step 2917, loss 0.0572536, acc 1, learning_rate 0.00062731\n","2023-06-27T18:05:44.280002: step 2918, loss 0.138087, acc 0.9375, learning_rate 0.000626948\n","2023-06-27T18:05:44.442790: step 2919, loss 0.103544, acc 1, learning_rate 0.000626587\n","2023-06-27T18:05:44.671422: step 2920, loss 0.0352988, acc 1, learning_rate 0.000626226\n","2023-06-27T18:05:44.863196: step 2921, loss 0.124785, acc 0.9375, learning_rate 0.000625865\n","2023-06-27T18:05:45.087474: step 2922, loss 0.0995601, acc 1, learning_rate 0.000625505\n","2023-06-27T18:05:45.285273: step 2923, loss 0.0896763, acc 0.96875, learning_rate 0.000625144\n","2023-06-27T18:05:45.507937: step 2924, loss 0.0631307, acc 0.96875, learning_rate 0.000624784\n","2023-06-27T18:05:45.696389: step 2925, loss 0.0262025, acc 1, learning_rate 0.000624424\n","2023-06-27T18:05:45.892069: step 2926, loss 0.0583116, acc 0.96875, learning_rate 0.000624065\n","2023-06-27T18:05:46.075204: step 2927, loss 0.0731949, acc 0.96875, learning_rate 0.000623705\n","2023-06-27T18:05:46.277403: step 2928, loss 0.193004, acc 0.9375, learning_rate 0.000623346\n","2023-06-27T18:05:46.488439: step 2929, loss 0.167172, acc 0.9375, learning_rate 0.000622987\n","2023-06-27T18:05:46.668453: step 2930, loss 0.00865278, acc 1, learning_rate 0.000622629\n","2023-06-27T18:05:46.835103: step 2931, loss 0.0424066, acc 1, learning_rate 0.00062227\n","2023-06-27T18:05:47.021938: step 2932, loss 0.0833855, acc 0.96875, learning_rate 0.000621912\n","2023-06-27T18:05:47.201426: step 2933, loss 0.0789754, acc 0.9375, learning_rate 0.000621554\n","2023-06-27T18:05:47.395669: step 2934, loss 0.0293169, acc 1, learning_rate 0.000621197\n","2023-06-27T18:05:47.621311: step 2935, loss 0.106558, acc 0.9375, learning_rate 0.000620839\n","2023-06-27T18:05:47.802379: step 2936, loss 0.0562952, acc 1, learning_rate 0.000620482\n","2023-06-27T18:05:48.002727: step 2937, loss 0.0840541, acc 0.96875, learning_rate 0.000620125\n","2023-06-27T18:05:48.201854: step 2938, loss 0.0103369, acc 1, learning_rate 0.000619768\n","2023-06-27T18:05:48.398396: step 2939, loss 0.217246, acc 0.9375, learning_rate 0.000619412\n","2023-06-27T18:05:48.582109: step 2940, loss 0.0293092, acc 1, learning_rate 0.000619056\n","2023-06-27T18:05:48.737612: step 2941, loss 0.235387, acc 0.9375, learning_rate 0.0006187\n","2023-06-27T18:05:48.852765: step 2942, loss 0.175386, acc 0.9375, learning_rate 0.000618344\n","2023-06-27T18:05:48.973340: step 2943, loss 0.043893, acc 0.96875, learning_rate 0.000617989\n","2023-06-27T18:05:49.108841: step 2944, loss 0.032622, acc 1, learning_rate 0.000617634\n","2023-06-27T18:05:49.226503: step 2945, loss 0.0928907, acc 0.96875, learning_rate 0.000617279\n","2023-06-27T18:05:49.343933: step 2946, loss 0.0264536, acc 1, learning_rate 0.000616924\n","2023-06-27T18:05:49.457879: step 2947, loss 0.0656058, acc 0.96875, learning_rate 0.00061657\n","2023-06-27T18:05:49.606386: step 2948, loss 0.0480947, acc 1, learning_rate 0.000616215\n","2023-06-27T18:05:49.742172: step 2949, loss 0.174585, acc 0.96875, learning_rate 0.000615861\n","2023-06-27T18:05:49.858253: step 2950, loss 0.0263709, acc 1, learning_rate 0.000615508\n","2023-06-27T18:05:49.974290: step 2951, loss 0.10273, acc 0.96875, learning_rate 0.000615154\n","2023-06-27T18:05:50.095812: step 2952, loss 0.194316, acc 0.90625, learning_rate 0.000614801\n","2023-06-27T18:05:50.210948: step 2953, loss 0.0689886, acc 1, learning_rate 0.000614448\n","2023-06-27T18:05:50.333932: step 2954, loss 0.020911, acc 1, learning_rate 0.000614095\n","2023-06-27T18:05:50.460117: step 2955, loss 0.0393572, acc 1, learning_rate 0.000613743\n","2023-06-27T18:05:50.596997: step 2956, loss 0.103576, acc 0.9375, learning_rate 0.00061339\n","2023-06-27T18:05:50.723117: step 2957, loss 0.149388, acc 0.90625, learning_rate 0.000613038\n","2023-06-27T18:05:50.860774: step 2958, loss 0.0352676, acc 1, learning_rate 0.000612686\n","2023-06-27T18:05:50.991829: step 2959, loss 0.0729958, acc 1, learning_rate 0.000612335\n","2023-06-27T18:05:51.109740: step 2960, loss 0.0339391, acc 0.96875, learning_rate 0.000611983\n","2023-06-27T18:05:51.220366: step 2961, loss 0.114488, acc 0.9375, learning_rate 0.000611632\n","2023-06-27T18:05:51.344705: step 2962, loss 0.100639, acc 0.96875, learning_rate 0.000611282\n","2023-06-27T18:05:51.461878: step 2963, loss 0.0943944, acc 0.96875, learning_rate 0.000610931\n","2023-06-27T18:05:51.593453: step 2964, loss 0.0534797, acc 0.96875, learning_rate 0.000610581\n","2023-06-27T18:05:51.719469: step 2965, loss 0.0483673, acc 1, learning_rate 0.000610231\n","2023-06-27T18:05:51.838727: step 2966, loss 0.0454849, acc 0.96875, learning_rate 0.000609881\n","2023-06-27T18:05:51.960827: step 2967, loss 0.232769, acc 0.90625, learning_rate 0.000609531\n","2023-06-27T18:05:52.073986: step 2968, loss 0.16125, acc 0.90625, learning_rate 0.000609182\n","2023-06-27T18:05:52.187128: step 2969, loss 0.0934562, acc 0.96875, learning_rate 0.000608832\n","2023-06-27T18:05:52.313198: step 2970, loss 0.172047, acc 0.875, learning_rate 0.000608484\n","2023-06-27T18:05:52.431002: step 2971, loss 0.0572765, acc 1, learning_rate 0.000608135\n","2023-06-27T18:05:52.547369: step 2972, loss 0.0656364, acc 1, learning_rate 0.000607786\n","2023-06-27T18:05:52.685938: step 2973, loss 0.061495, acc 1, learning_rate 0.000607438\n","2023-06-27T18:05:52.796773: step 2974, loss 0.041275, acc 0.96875, learning_rate 0.00060709\n","2023-06-27T18:05:52.936167: step 2975, loss 0.0510006, acc 0.96875, learning_rate 0.000606743\n","2023-06-27T18:05:53.067366: step 2976, loss 0.0884871, acc 0.9375, learning_rate 0.000606395\n","2023-06-27T18:05:53.192366: step 2977, loss 0.0978533, acc 0.96875, learning_rate 0.000606048\n","2023-06-27T18:05:53.308000: step 2978, loss 0.261139, acc 0.875, learning_rate 0.000605701\n","2023-06-27T18:05:53.429174: step 2979, loss 0.0638917, acc 1, learning_rate 0.000605354\n","2023-06-27T18:05:53.554473: step 2980, loss 0.00764245, acc 1, learning_rate 0.000605007\n","2023-06-27T18:05:53.680520: step 2981, loss 0.0682779, acc 1, learning_rate 0.000604661\n","2023-06-27T18:05:53.805464: step 2982, loss 0.0561993, acc 0.96875, learning_rate 0.000604315\n","2023-06-27T18:05:53.933132: step 2983, loss 0.0594092, acc 0.96875, learning_rate 0.000603969\n","2023-06-27T18:05:54.040043: step 2984, loss 0.0441259, acc 0.96875, learning_rate 0.000603624\n","2023-06-27T18:05:54.149077: step 2985, loss 0.148454, acc 0.9375, learning_rate 0.000603278\n","2023-06-27T18:05:54.275012: step 2986, loss 0.0440944, acc 1, learning_rate 0.000602933\n","2023-06-27T18:05:54.394092: step 2987, loss 0.0225008, acc 1, learning_rate 0.000602588\n","2023-06-27T18:05:54.515336: step 2988, loss 0.131341, acc 0.96875, learning_rate 0.000602244\n","2023-06-27T18:05:54.653125: step 2989, loss 0.115809, acc 0.9375, learning_rate 0.000601899\n","2023-06-27T18:05:54.777721: step 2990, loss 0.447824, acc 0.875, learning_rate 0.000601555\n","2023-06-27T18:05:54.892551: step 2991, loss 0.0397095, acc 1, learning_rate 0.000601211\n","2023-06-27T18:05:55.011431: step 2992, loss 0.173285, acc 0.90625, learning_rate 0.000600868\n","2023-06-27T18:05:55.144725: step 2993, loss 0.0818451, acc 0.96875, learning_rate 0.000600524\n","2023-06-27T18:05:55.267369: step 2994, loss 0.0445881, acc 1, learning_rate 0.000600181\n","2023-06-27T18:05:55.395190: step 2995, loss 0.060386, acc 0.96875, learning_rate 0.000599838\n","2023-06-27T18:05:55.508072: step 2996, loss 0.0811652, acc 0.96875, learning_rate 0.000599495\n","2023-06-27T18:05:55.618603: step 2997, loss 0.0551422, acc 1, learning_rate 0.000599153\n","2023-06-27T18:05:55.757708: step 2998, loss 0.350816, acc 0.9375, learning_rate 0.00059881\n","2023-06-27T18:05:55.879146: step 2999, loss 0.0400015, acc 1, learning_rate 0.000598468\n","\n","Evaluation:\n","2023-06-27T18:05:56.607544: step 3000, loss 0.695904, acc 0.8006\n","\n","Saved model checkpoint to /content/gdrive/MyDrive/lightweighted-cnn/train/runs/1687888658/checkpoints/model-3000\n","\n","2023-06-27T18:05:56.862706: step 3000, loss 0.0985087, acc 0.90625, learning_rate 0.000598126\n","2023-06-27T18:05:56.992216: step 3001, loss 0.0563311, acc 1, learning_rate 0.000597785\n","2023-06-27T18:05:57.104085: step 3002, loss 0.095234, acc 0.96875, learning_rate 0.000597444\n","2023-06-27T18:05:57.232023: step 3003, loss 0.174962, acc 0.90625, learning_rate 0.000597102\n","2023-06-27T18:05:57.341689: step 3004, loss 0.0439231, acc 0.96875, learning_rate 0.000596762\n","2023-06-27T18:05:57.472650: step 3005, loss 0.0506779, acc 1, learning_rate 0.000596421\n","2023-06-27T18:05:57.594002: step 3006, loss 0.0997244, acc 0.96875, learning_rate 0.000596081\n","2023-06-27T18:05:57.730269: step 3007, loss 0.159082, acc 0.90625, learning_rate 0.00059574\n","2023-06-27T18:05:57.860760: step 3008, loss 0.0395844, acc 1, learning_rate 0.0005954\n","2023-06-27T18:05:57.978584: step 3009, loss 0.0569556, acc 0.96875, learning_rate 0.000595061\n","2023-06-27T18:05:58.096444: step 3010, loss 0.100678, acc 0.96875, learning_rate 0.000594721\n","2023-06-27T18:05:58.226021: step 3011, loss 0.107622, acc 1, learning_rate 0.000594382\n","2023-06-27T18:05:58.359856: step 3012, loss 0.0489195, acc 0.96875, learning_rate 0.000594043\n","2023-06-27T18:05:58.478092: step 3013, loss 0.0443531, acc 1, learning_rate 0.000593704\n","2023-06-27T18:05:58.590626: step 3014, loss 0.0830256, acc 0.96875, learning_rate 0.000593366\n","2023-06-27T18:05:58.729637: step 3015, loss 0.0425861, acc 1, learning_rate 0.000593027\n","2023-06-27T18:05:58.917838: step 3016, loss 0.101527, acc 0.9375, learning_rate 0.000592689\n","2023-06-27T18:05:59.125908: step 3017, loss 0.0991182, acc 0.96875, learning_rate 0.000592351\n","2023-06-27T18:05:59.333015: step 3018, loss 0.13477, acc 0.9375, learning_rate 0.000592014\n","2023-06-27T18:05:59.546866: step 3019, loss 0.102917, acc 0.9375, learning_rate 0.000591676\n","2023-06-27T18:05:59.757502: step 3020, loss 0.10027, acc 1, learning_rate 0.000591339\n","2023-06-27T18:06:00.001434: step 3021, loss 0.0267583, acc 1, learning_rate 0.000591002\n","2023-06-27T18:06:00.213541: step 3022, loss 0.0714853, acc 0.96875, learning_rate 0.000590666\n","2023-06-27T18:06:00.399567: step 3023, loss 0.0130856, acc 1, learning_rate 0.000590329\n","2023-06-27T18:06:00.609363: step 3024, loss 0.0495725, acc 1, learning_rate 0.000589993\n","2023-06-27T18:06:00.807646: step 3025, loss 0.107749, acc 0.96875, learning_rate 0.000589657\n","2023-06-27T18:06:01.002152: step 3026, loss 0.0609852, acc 0.96875, learning_rate 0.000589321\n","2023-06-27T18:06:01.203121: step 3027, loss 0.105399, acc 0.9375, learning_rate 0.000588986\n","2023-06-27T18:06:01.412851: step 3028, loss 0.0552636, acc 0.96875, learning_rate 0.00058865\n","2023-06-27T18:06:01.620909: step 3029, loss 0.00908647, acc 1, learning_rate 0.000588315\n","2023-06-27T18:06:01.825884: step 3030, loss 0.342655, acc 0.9375, learning_rate 0.00058798\n","2023-06-27T18:06:02.028029: step 3031, loss 0.0412041, acc 1, learning_rate 0.000587646\n","2023-06-27T18:06:02.236143: step 3032, loss 0.12203, acc 0.9375, learning_rate 0.000587311\n","2023-06-27T18:06:02.455009: step 3033, loss 0.180991, acc 0.90625, learning_rate 0.000586977\n","2023-06-27T18:06:02.651514: step 3034, loss 0.0956472, acc 0.96875, learning_rate 0.000586643\n","2023-06-27T18:06:02.853315: step 3035, loss 0.00853813, acc 1, learning_rate 0.00058631\n","2023-06-27T18:06:03.034492: step 3036, loss 0.0457443, acc 0.96875, learning_rate 0.000585976\n","2023-06-27T18:06:03.216505: step 3037, loss 0.113953, acc 0.9375, learning_rate 0.000585643\n","2023-06-27T18:06:03.405184: step 3038, loss 0.0764897, acc 0.96875, learning_rate 0.00058531\n","2023-06-27T18:06:03.606847: step 3039, loss 0.0241388, acc 1, learning_rate 0.000584977\n","2023-06-27T18:06:03.796303: step 3040, loss 0.0406653, acc 1, learning_rate 0.000584645\n","2023-06-27T18:06:03.991351: step 3041, loss 0.0449615, acc 1, learning_rate 0.000584312\n","2023-06-27T18:06:04.201843: step 3042, loss 0.0671085, acc 0.96875, learning_rate 0.00058398\n","2023-06-27T18:06:04.397641: step 3043, loss 0.0951946, acc 0.96875, learning_rate 0.000583648\n","2023-06-27T18:06:04.592963: step 3044, loss 0.13212, acc 0.96875, learning_rate 0.000583317\n","2023-06-27T18:06:04.802610: step 3045, loss 0.0143029, acc 1, learning_rate 0.000582985\n","2023-06-27T18:06:05.003062: step 3046, loss 0.0753059, acc 0.9375, learning_rate 0.000582654\n","2023-06-27T18:06:05.196794: step 3047, loss 0.117789, acc 0.9375, learning_rate 0.000582323\n","2023-06-27T18:06:05.416483: step 3048, loss 0.0793297, acc 0.96875, learning_rate 0.000581992\n","2023-06-27T18:06:05.601587: step 3049, loss 0.0504109, acc 1, learning_rate 0.000581662\n","2023-06-27T18:06:05.815549: step 3050, loss 0.0206788, acc 1, learning_rate 0.000581331\n","2023-06-27T18:06:06.001368: step 3051, loss 0.291934, acc 0.9375, learning_rate 0.000581001\n","2023-06-27T18:06:06.206498: step 3052, loss 0.0513344, acc 0.96875, learning_rate 0.000580672\n","2023-06-27T18:06:06.379805: step 3053, loss 0.0327934, acc 1, learning_rate 0.000580342\n","2023-06-27T18:06:06.566721: step 3054, loss 0.140117, acc 0.96875, learning_rate 0.000580013\n","2023-06-27T18:06:06.756656: step 3055, loss 0.0571818, acc 0.96875, learning_rate 0.000579683\n","2023-06-27T18:06:06.964706: step 3056, loss 0.108434, acc 0.96875, learning_rate 0.000579354\n","2023-06-27T18:06:07.188208: step 3057, loss 0.043333, acc 1, learning_rate 0.000579026\n","2023-06-27T18:06:07.358092: step 3058, loss 0.0279433, acc 1, learning_rate 0.000578697\n","2023-06-27T18:06:07.543927: step 3059, loss 0.0455211, acc 1, learning_rate 0.000578369\n","2023-06-27T18:06:07.753352: step 3060, loss 0.162447, acc 0.9375, learning_rate 0.000578041\n","2023-06-27T18:06:07.955203: step 3061, loss 0.00942259, acc 1, learning_rate 0.000577713\n","2023-06-27T18:06:08.152314: step 3062, loss 0.0806536, acc 0.96875, learning_rate 0.000577386\n","2023-06-27T18:06:08.346265: step 3063, loss 0.0215441, acc 1, learning_rate 0.000577058\n","2023-06-27T18:06:08.564574: step 3064, loss 0.153241, acc 0.90625, learning_rate 0.000576731\n","2023-06-27T18:06:08.767025: step 3065, loss 0.117352, acc 0.9375, learning_rate 0.000576404\n","2023-06-27T18:06:08.968273: step 3066, loss 0.0250346, acc 1, learning_rate 0.000576078\n","2023-06-27T18:06:09.164507: step 3067, loss 0.117816, acc 0.9375, learning_rate 0.000575751\n","2023-06-27T18:06:09.351294: step 3068, loss 0.022716, acc 1, learning_rate 0.000575425\n","2023-06-27T18:06:09.557629: step 3069, loss 0.0383289, acc 1, learning_rate 0.000575099\n","2023-06-27T18:06:09.737648: step 3070, loss 0.0343494, acc 1, learning_rate 0.000574773\n","2023-06-27T18:06:09.862258: step 3071, loss 0.0188023, acc 1, learning_rate 0.000574447\n","2023-06-27T18:06:09.980796: step 3072, loss 0.101394, acc 0.96875, learning_rate 0.000574122\n","2023-06-27T18:06:10.109950: step 3073, loss 0.058718, acc 0.96875, learning_rate 0.000573797\n","2023-06-27T18:06:10.237624: step 3074, loss 0.0399088, acc 1, learning_rate 0.000573472\n","2023-06-27T18:06:10.373271: step 3075, loss 0.0624129, acc 0.96875, learning_rate 0.000573147\n","2023-06-27T18:06:10.517463: step 3076, loss 0.144024, acc 0.90625, learning_rate 0.000572823\n","2023-06-27T18:06:10.633395: step 3077, loss 0.0219708, acc 1, learning_rate 0.000572499\n","2023-06-27T18:06:10.770801: step 3078, loss 0.0152867, acc 1, learning_rate 0.000572175\n","2023-06-27T18:06:10.888374: step 3079, loss 0.0214893, acc 1, learning_rate 0.000571851\n","2023-06-27T18:06:11.023904: step 3080, loss 0.0397486, acc 1, learning_rate 0.000571527\n","2023-06-27T18:06:11.138645: step 3081, loss 0.0061319, acc 1, learning_rate 0.000571204\n","2023-06-27T18:06:11.248017: step 3082, loss 0.0502739, acc 1, learning_rate 0.000570881\n","2023-06-27T18:06:11.377746: step 3083, loss 0.410247, acc 0.90625, learning_rate 0.000570558\n","2023-06-27T18:06:11.486745: step 3084, loss 0.22543, acc 0.90625, learning_rate 0.000570235\n","2023-06-27T18:06:11.604208: step 3085, loss 0.0581934, acc 0.96875, learning_rate 0.000569913\n","2023-06-27T18:06:11.735279: step 3086, loss 0.061461, acc 0.96875, learning_rate 0.000569591\n","2023-06-27T18:06:11.846430: step 3087, loss 0.158851, acc 0.9375, learning_rate 0.000569269\n","2023-06-27T18:06:11.963913: step 3088, loss 0.052256, acc 0.96875, learning_rate 0.000568947\n","2023-06-27T18:06:12.096206: step 3089, loss 0.036487, acc 1, learning_rate 0.000568625\n","2023-06-27T18:06:12.216687: step 3090, loss 0.15028, acc 0.96875, learning_rate 0.000568304\n","2023-06-27T18:06:12.355944: step 3091, loss 0.0103666, acc 1, learning_rate 0.000567983\n","2023-06-27T18:06:12.479545: step 3092, loss 0.0774261, acc 1, learning_rate 0.000567662\n","2023-06-27T18:06:12.627392: step 3093, loss 0.111552, acc 0.9375, learning_rate 0.000567341\n","2023-06-27T18:06:12.752032: step 3094, loss 0.0390522, acc 1, learning_rate 0.000567021\n","2023-06-27T18:06:12.883064: step 3095, loss 0.207339, acc 0.9375, learning_rate 0.000566701\n","2023-06-27T18:06:13.016156: step 3096, loss 0.162791, acc 0.90625, learning_rate 0.000566381\n","2023-06-27T18:06:13.124032: step 3097, loss 0.0386908, acc 1, learning_rate 0.000566061\n","2023-06-27T18:06:13.244324: step 3098, loss 0.205041, acc 0.9375, learning_rate 0.000565741\n","2023-06-27T18:06:13.375672: step 3099, loss 0.0250468, acc 1, learning_rate 0.000565422\n","\n","Evaluation:\n","2023-06-27T18:06:14.107643: step 3100, loss 0.699091, acc 0.801887\n","\n","Saved model checkpoint to /content/gdrive/MyDrive/lightweighted-cnn/train/runs/1687888658/checkpoints/model-3100\n","\n","2023-06-27T18:06:14.344946: step 3100, loss 0.0273935, acc 1, learning_rate 0.000565103\n","2023-06-27T18:06:14.491013: step 3101, loss 0.109267, acc 0.9375, learning_rate 0.000564784\n","2023-06-27T18:06:14.616287: step 3102, loss 0.115586, acc 0.9375, learning_rate 0.000564465\n","2023-06-27T18:06:14.744194: step 3103, loss 0.188302, acc 0.9375, learning_rate 0.000564146\n","2023-06-27T18:06:14.857659: step 3104, loss 0.0346322, acc 1, learning_rate 0.000563828\n","2023-06-27T18:06:14.973928: step 3105, loss 0.0140579, acc 1, learning_rate 0.00056351\n","2023-06-27T18:06:15.102207: step 3106, loss 0.0309315, acc 1, learning_rate 0.000563192\n","2023-06-27T18:06:15.238909: step 3107, loss 0.176029, acc 0.9375, learning_rate 0.000562875\n","2023-06-27T18:06:15.358712: step 3108, loss 0.0624315, acc 0.96875, learning_rate 0.000562557\n","2023-06-27T18:06:15.494577: step 3109, loss 0.0924711, acc 0.96875, learning_rate 0.00056224\n","2023-06-27T18:06:15.611078: step 3110, loss 0.078508, acc 0.96875, learning_rate 0.000561923\n","2023-06-27T18:06:15.743303: step 3111, loss 0.0236489, acc 1, learning_rate 0.000561606\n","2023-06-27T18:06:15.867561: step 3112, loss 0.202655, acc 0.90625, learning_rate 0.00056129\n","2023-06-27T18:06:15.988458: step 3113, loss 0.0984585, acc 0.96875, learning_rate 0.000560974\n","2023-06-27T18:06:16.107906: step 3114, loss 0.123632, acc 0.96875, learning_rate 0.000560657\n","2023-06-27T18:06:16.230263: step 3115, loss 0.13365, acc 0.96875, learning_rate 0.000560342\n","2023-06-27T18:06:16.374475: step 3116, loss 0.0557666, acc 0.96875, learning_rate 0.000560026\n","2023-06-27T18:06:16.519435: step 3117, loss 0.115018, acc 0.9375, learning_rate 0.00055971\n","2023-06-27T18:06:16.638438: step 3118, loss 0.0611686, acc 0.96875, learning_rate 0.000559395\n","2023-06-27T18:06:16.760200: step 3119, loss 0.0349161, acc 1, learning_rate 0.00055908\n","2023-06-27T18:06:16.878079: step 3120, loss 0.158006, acc 0.9375, learning_rate 0.000558765\n","2023-06-27T18:06:16.995581: step 3121, loss 0.134137, acc 0.9375, learning_rate 0.000558451\n","2023-06-27T18:06:17.115369: step 3122, loss 0.0328578, acc 1, learning_rate 0.000558136\n","2023-06-27T18:06:17.236376: step 3123, loss 0.0656595, acc 1, learning_rate 0.000557822\n","2023-06-27T18:06:17.365205: step 3124, loss 0.0370569, acc 1, learning_rate 0.000557508\n","2023-06-27T18:06:17.491820: step 3125, loss 0.0378036, acc 1, learning_rate 0.000557195\n","2023-06-27T18:06:17.611857: step 3126, loss 0.0250161, acc 1, learning_rate 0.000556881\n","2023-06-27T18:06:17.729241: step 3127, loss 0.0740977, acc 0.96875, learning_rate 0.000556568\n","2023-06-27T18:06:17.856808: step 3128, loss 0.0281972, acc 1, learning_rate 0.000556255\n","2023-06-27T18:06:17.983097: step 3129, loss 0.0900472, acc 0.96875, learning_rate 0.000555942\n","2023-06-27T18:06:18.098341: step 3130, loss 0.0119212, acc 1, learning_rate 0.000555629\n","2023-06-27T18:06:18.220359: step 3131, loss 0.030133, acc 1, learning_rate 0.000555317\n","2023-06-27T18:06:18.336287: step 3132, loss 0.0980469, acc 0.96875, learning_rate 0.000555005\n","2023-06-27T18:06:18.479236: step 3133, loss 0.107137, acc 0.96875, learning_rate 0.000554693\n","2023-06-27T18:06:18.602690: step 3134, loss 0.0354995, acc 1, learning_rate 0.000554381\n","2023-06-27T18:06:18.723251: step 3135, loss 0.14118, acc 0.9375, learning_rate 0.000554069\n","2023-06-27T18:06:18.849999: step 3136, loss 0.0693138, acc 1, learning_rate 0.000553758\n","2023-06-27T18:06:18.975965: step 3137, loss 0.220285, acc 0.90625, learning_rate 0.000553447\n","2023-06-27T18:06:19.096531: step 3138, loss 0.0279251, acc 1, learning_rate 0.000553136\n","2023-06-27T18:06:19.220719: step 3139, loss 0.0798813, acc 0.9375, learning_rate 0.000552825\n","2023-06-27T18:06:19.349966: step 3140, loss 0.159783, acc 0.90625, learning_rate 0.000552514\n","2023-06-27T18:06:19.470843: step 3141, loss 0.0612314, acc 0.96875, learning_rate 0.000552204\n","2023-06-27T18:06:19.602550: step 3142, loss 0.0563835, acc 0.96875, learning_rate 0.000551894\n","2023-06-27T18:06:19.720305: step 3143, loss 0.123022, acc 0.9375, learning_rate 0.000551584\n","2023-06-27T18:06:19.919182: step 3144, loss 0.118971, acc 0.96875, learning_rate 0.000551275\n","2023-06-27T18:06:20.119134: step 3145, loss 0.112651, acc 0.96875, learning_rate 0.000550965\n","2023-06-27T18:06:20.384215: step 3146, loss 0.0577809, acc 0.96875, learning_rate 0.000550656\n","2023-06-27T18:06:20.605291: step 3147, loss 0.0821844, acc 1, learning_rate 0.000550347\n","2023-06-27T18:06:20.814387: step 3148, loss 0.0398695, acc 1, learning_rate 0.000550038\n","2023-06-27T18:06:21.019343: step 3149, loss 0.101388, acc 0.96875, learning_rate 0.000549729\n","2023-06-27T18:06:21.228811: step 3150, loss 0.208183, acc 0.90625, learning_rate 0.000549421\n","2023-06-27T18:06:21.420753: step 3151, loss 0.191634, acc 0.90625, learning_rate 0.000549113\n","2023-06-27T18:06:21.628349: step 3152, loss 0.0124194, acc 1, learning_rate 0.000548805\n","2023-06-27T18:06:21.845040: step 3153, loss 0.0700442, acc 1, learning_rate 0.000548497\n","2023-06-27T18:06:22.067938: step 3154, loss 0.0342605, acc 1, learning_rate 0.00054819\n","2023-06-27T18:06:22.283042: step 3155, loss 0.0667515, acc 0.96875, learning_rate 0.000547882\n","2023-06-27T18:06:22.486176: step 3156, loss 0.199821, acc 0.875, learning_rate 0.000547575\n","2023-06-27T18:06:22.709643: step 3157, loss 0.0551216, acc 1, learning_rate 0.000547268\n","2023-06-27T18:06:22.899819: step 3158, loss 0.158078, acc 0.9375, learning_rate 0.000546961\n","2023-06-27T18:06:23.103249: step 3159, loss 0.0147084, acc 1, learning_rate 0.000546655\n","2023-06-27T18:06:23.273822: step 3160, loss 0.0279483, acc 1, learning_rate 0.000546349\n","2023-06-27T18:06:23.460972: step 3161, loss 0.136819, acc 0.96875, learning_rate 0.000546043\n","2023-06-27T18:06:23.651262: step 3162, loss 0.254844, acc 0.9375, learning_rate 0.000545737\n","2023-06-27T18:06:23.850558: step 3163, loss 0.211092, acc 0.90625, learning_rate 0.000545431\n","2023-06-27T18:06:24.055103: step 3164, loss 0.242128, acc 0.875, learning_rate 0.000545126\n","2023-06-27T18:06:24.224465: step 3165, loss 0.00706269, acc 1, learning_rate 0.00054482\n","2023-06-27T18:06:24.426655: step 3166, loss 0.032941, acc 1, learning_rate 0.000544515\n","2023-06-27T18:06:24.624960: step 3167, loss 0.0886399, acc 0.96875, learning_rate 0.000544211\n","2023-06-27T18:06:24.840589: step 3168, loss 0.151817, acc 0.96875, learning_rate 0.000543906\n","2023-06-27T18:06:25.001996: step 3169, loss 0.116099, acc 0.9375, learning_rate 0.000543602\n","2023-06-27T18:06:25.185754: step 3170, loss 0.0703735, acc 0.96875, learning_rate 0.000543297\n","2023-06-27T18:06:25.379990: step 3171, loss 0.0852514, acc 0.96875, learning_rate 0.000542993\n","2023-06-27T18:06:25.568683: step 3172, loss 0.0690969, acc 1, learning_rate 0.00054269\n","2023-06-27T18:06:25.742254: step 3173, loss 0.0313167, acc 1, learning_rate 0.000542386\n","2023-06-27T18:06:25.933119: step 3174, loss 0.0366719, acc 1, learning_rate 0.000542083\n","2023-06-27T18:06:26.103908: step 3175, loss 0.0235986, acc 1, learning_rate 0.00054178\n","2023-06-27T18:06:26.299943: step 3176, loss 0.0383648, acc 1, learning_rate 0.000541477\n","2023-06-27T18:06:26.487290: step 3177, loss 0.021225, acc 1, learning_rate 0.000541174\n","2023-06-27T18:06:26.697033: step 3178, loss 0.0709114, acc 0.96875, learning_rate 0.000540871\n","2023-06-27T18:06:26.882989: step 3179, loss 0.0532547, acc 1, learning_rate 0.000540569\n","2023-06-27T18:06:27.065115: step 3180, loss 0.0490686, acc 0.96875, learning_rate 0.000540267\n","2023-06-27T18:06:27.271128: step 3181, loss 0.0796692, acc 0.96875, learning_rate 0.000539965\n","2023-06-27T18:06:27.489191: step 3182, loss 0.0515248, acc 1, learning_rate 0.000539663\n","2023-06-27T18:06:27.682865: step 3183, loss 0.0412223, acc 1, learning_rate 0.000539362\n","2023-06-27T18:06:27.888793: step 3184, loss 0.237049, acc 0.9375, learning_rate 0.000539061\n","2023-06-27T18:06:28.092681: step 3185, loss 0.11314, acc 0.9375, learning_rate 0.00053876\n","2023-06-27T18:06:28.286442: step 3186, loss 0.029933, acc 1, learning_rate 0.000538459\n","2023-06-27T18:06:28.483076: step 3187, loss 0.0446278, acc 1, learning_rate 0.000538158\n","2023-06-27T18:06:28.680335: step 3188, loss 0.0293604, acc 1, learning_rate 0.000537858\n","2023-06-27T18:06:28.902295: step 3189, loss 0.0344902, acc 0.96875, learning_rate 0.000537557\n","2023-06-27T18:06:29.087896: step 3190, loss 0.153565, acc 0.9375, learning_rate 0.000537257\n","2023-06-27T18:06:29.267172: step 3191, loss 0.0411023, acc 1, learning_rate 0.000536957\n","2023-06-27T18:06:29.467881: step 3192, loss 0.121265, acc 0.9375, learning_rate 0.000536658\n","2023-06-27T18:06:29.654986: step 3193, loss 0.0462112, acc 1, learning_rate 0.000536358\n","2023-06-27T18:06:29.842000: step 3194, loss 0.130849, acc 0.96875, learning_rate 0.000536059\n","2023-06-27T18:06:30.022152: step 3195, loss 0.0302773, acc 1, learning_rate 0.00053576\n","2023-06-27T18:06:30.203762: step 3196, loss 0.159077, acc 0.9375, learning_rate 0.000535461\n","2023-06-27T18:06:30.382686: step 3197, loss 0.0913957, acc 0.96875, learning_rate 0.000535163\n","2023-06-27T18:06:30.562371: step 3198, loss 0.0170505, acc 1, learning_rate 0.000534864\n","2023-06-27T18:06:30.689505: step 3199, loss 0.0519752, acc 1, learning_rate 0.000534566\n","\n","Evaluation:\n","2023-06-27T18:06:31.463206: step 3200, loss 0.71273, acc 0.801244\n","\n","Saved model checkpoint to /content/gdrive/MyDrive/lightweighted-cnn/train/runs/1687888658/checkpoints/model-3200\n","\n","2023-06-27T18:06:31.689577: step 3200, loss 0.135347, acc 0.9375, learning_rate 0.000534268\n","2023-06-27T18:06:31.825350: step 3201, loss 0.133541, acc 0.96875, learning_rate 0.00053397\n","2023-06-27T18:06:31.957901: step 3202, loss 0.0872513, acc 0.96875, learning_rate 0.000533673\n","2023-06-27T18:06:32.110241: step 3203, loss 0.00788796, acc 1, learning_rate 0.000533375\n","2023-06-27T18:06:32.240324: step 3204, loss 0.0634259, acc 0.96875, learning_rate 0.000533078\n","2023-06-27T18:06:32.358900: step 3205, loss 0.0365187, acc 1, learning_rate 0.000532781\n","2023-06-27T18:06:32.485021: step 3206, loss 0.0951402, acc 0.96875, learning_rate 0.000532484\n","2023-06-27T18:06:32.614762: step 3207, loss 0.168268, acc 0.9375, learning_rate 0.000532188\n","2023-06-27T18:06:32.735587: step 3208, loss 0.2147, acc 0.9375, learning_rate 0.000531892\n","2023-06-27T18:06:32.858858: step 3209, loss 0.131007, acc 0.9375, learning_rate 0.000531595\n","2023-06-27T18:06:32.986858: step 3210, loss 0.137172, acc 0.9375, learning_rate 0.000531299\n","2023-06-27T18:06:33.129726: step 3211, loss 0.10177, acc 0.9375, learning_rate 0.000531004\n","2023-06-27T18:06:33.251859: step 3212, loss 0.0528089, acc 0.96875, learning_rate 0.000530708\n","2023-06-27T18:06:33.369442: step 3213, loss 0.0363129, acc 1, learning_rate 0.000530413\n","2023-06-27T18:06:33.492681: step 3214, loss 0.00959928, acc 1, learning_rate 0.000530118\n","2023-06-27T18:06:33.624629: step 3215, loss 0.0130744, acc 1, learning_rate 0.000529823\n","2023-06-27T18:06:33.742151: step 3216, loss 0.0861948, acc 0.96875, learning_rate 0.000529528\n","2023-06-27T18:06:33.867159: step 3217, loss 0.152761, acc 0.96875, learning_rate 0.000529233\n","2023-06-27T18:06:34.018901: step 3218, loss 0.152726, acc 0.9375, learning_rate 0.000528939\n","2023-06-27T18:06:34.149474: step 3219, loss 0.0271738, acc 1, learning_rate 0.000528645\n","2023-06-27T18:06:34.270979: step 3220, loss 0.0610095, acc 0.96875, learning_rate 0.000528351\n","2023-06-27T18:06:34.415563: step 3221, loss 0.0644745, acc 0.96875, learning_rate 0.000528057\n","2023-06-27T18:06:34.540815: step 3222, loss 0.0234563, acc 1, learning_rate 0.000527764\n","2023-06-27T18:06:34.662082: step 3223, loss 0.176152, acc 0.9375, learning_rate 0.00052747\n","2023-06-27T18:06:34.785681: step 3224, loss 0.238773, acc 0.875, learning_rate 0.000527177\n","2023-06-27T18:06:34.910473: step 3225, loss 0.0686447, acc 0.96875, learning_rate 0.000526884\n","2023-06-27T18:06:35.032733: step 3226, loss 0.083131, acc 0.96875, learning_rate 0.000526592\n","2023-06-27T18:06:35.146127: step 3227, loss 0.205072, acc 0.96875, learning_rate 0.000526299\n","2023-06-27T18:06:35.284025: step 3228, loss 0.223506, acc 0.90625, learning_rate 0.000526007\n","2023-06-27T18:06:35.408957: step 3229, loss 0.026978, acc 1, learning_rate 0.000525715\n","2023-06-27T18:06:35.526687: step 3230, loss 0.0183293, acc 1, learning_rate 0.000525423\n","2023-06-27T18:06:35.658317: step 3231, loss 0.269029, acc 0.90625, learning_rate 0.000525131\n","2023-06-27T18:06:35.774912: step 3232, loss 0.129547, acc 0.9375, learning_rate 0.00052484\n","2023-06-27T18:06:35.884645: step 3233, loss 0.0810431, acc 0.96875, learning_rate 0.000524548\n","2023-06-27T18:06:36.004424: step 3234, loss 0.114099, acc 0.9375, learning_rate 0.000524257\n","2023-06-27T18:06:36.121217: step 3235, loss 0.150985, acc 0.96875, learning_rate 0.000523966\n","2023-06-27T18:06:36.256794: step 3236, loss 0.0352954, acc 1, learning_rate 0.000523675\n","2023-06-27T18:06:36.374138: step 3237, loss 0.176156, acc 0.96875, learning_rate 0.000523385\n","2023-06-27T18:06:36.490559: step 3238, loss 0.160735, acc 0.875, learning_rate 0.000523095\n","2023-06-27T18:06:36.629796: step 3239, loss 0.0468088, acc 1, learning_rate 0.000522804\n","2023-06-27T18:06:36.751541: step 3240, loss 0.181103, acc 0.9375, learning_rate 0.000522515\n","2023-06-27T18:06:36.862738: step 3241, loss 0.0181805, acc 1, learning_rate 0.000522225\n","2023-06-27T18:06:36.991491: step 3242, loss 0.112827, acc 0.96875, learning_rate 0.000521935\n","2023-06-27T18:06:37.114627: step 3243, loss 0.208051, acc 0.9375, learning_rate 0.000521646\n","2023-06-27T18:06:37.248315: step 3244, loss 0.0371077, acc 0.96875, learning_rate 0.000521357\n","2023-06-27T18:06:37.367727: step 3245, loss 0.0951418, acc 0.96875, learning_rate 0.000521068\n","2023-06-27T18:06:37.480560: step 3246, loss 0.0510758, acc 1, learning_rate 0.000520779\n","2023-06-27T18:06:37.608324: step 3247, loss 0.0389517, acc 1, learning_rate 0.000520491\n","2023-06-27T18:06:37.730261: step 3248, loss 0.00997461, acc 1, learning_rate 0.000520202\n","2023-06-27T18:06:37.853702: step 3249, loss 0.137597, acc 0.9375, learning_rate 0.000519914\n","2023-06-27T18:06:37.970709: step 3250, loss 0.0776931, acc 0.96875, learning_rate 0.000519626\n","2023-06-27T18:06:38.078989: step 3251, loss 0.242984, acc 0.9375, learning_rate 0.000519338\n","2023-06-27T18:06:38.216281: step 3252, loss 0.194706, acc 0.9375, learning_rate 0.000519051\n","2023-06-27T18:06:38.341638: step 3253, loss 0.0332565, acc 1, learning_rate 0.000518764\n","2023-06-27T18:06:38.481990: step 3254, loss 0.0434861, acc 1, learning_rate 0.000518476\n","2023-06-27T18:06:38.609320: step 3255, loss 0.105962, acc 0.96875, learning_rate 0.000518189\n","2023-06-27T18:06:38.733263: step 3256, loss 0.0241055, acc 1, learning_rate 0.000517903\n","2023-06-27T18:06:38.851425: step 3257, loss 0.0816234, acc 0.96875, learning_rate 0.000517616\n","2023-06-27T18:06:38.966990: step 3258, loss 0.0951225, acc 0.96875, learning_rate 0.00051733\n","2023-06-27T18:06:39.083815: step 3259, loss 0.15027, acc 0.9375, learning_rate 0.000517044\n","2023-06-27T18:06:39.205722: step 3260, loss 0.0651104, acc 1, learning_rate 0.000516758\n","2023-06-27T18:06:39.332316: step 3261, loss 0.108132, acc 0.9375, learning_rate 0.000516472\n","2023-06-27T18:06:39.443694: step 3262, loss 0.0256601, acc 1, learning_rate 0.000516186\n","2023-06-27T18:06:39.558713: step 3263, loss 0.160656, acc 0.9375, learning_rate 0.000515901\n","2023-06-27T18:06:39.682114: step 3264, loss 0.00480274, acc 1, learning_rate 0.000515616\n","2023-06-27T18:06:39.802820: step 3265, loss 0.0157027, acc 1, learning_rate 0.000515331\n","2023-06-27T18:06:39.929424: step 3266, loss 0.0779321, acc 1, learning_rate 0.000515046\n","2023-06-27T18:06:40.046650: step 3267, loss 0.179649, acc 0.90625, learning_rate 0.000514761\n","2023-06-27T18:06:40.158458: step 3268, loss 0.180047, acc 0.90625, learning_rate 0.000514477\n","2023-06-27T18:06:40.316452: step 3269, loss 0.127549, acc 0.96875, learning_rate 0.000514193\n","2023-06-27T18:06:40.445670: step 3270, loss 0.0479012, acc 0.96875, learning_rate 0.000513909\n","2023-06-27T18:06:40.586539: step 3271, loss 0.0876109, acc 0.96875, learning_rate 0.000513625\n","2023-06-27T18:06:40.783933: step 3272, loss 0.0597397, acc 0.96875, learning_rate 0.000513341\n","2023-06-27T18:06:40.995481: step 3273, loss 0.0198971, acc 1, learning_rate 0.000513058\n","2023-06-27T18:06:41.179460: step 3274, loss 0.20167, acc 0.9375, learning_rate 0.000512774\n","2023-06-27T18:06:41.397022: step 3275, loss 0.0610863, acc 1, learning_rate 0.000512491\n","2023-06-27T18:06:41.609321: step 3276, loss 0.137503, acc 0.9375, learning_rate 0.000512208\n","2023-06-27T18:06:41.811523: step 3277, loss 0.080806, acc 0.96875, learning_rate 0.000511926\n","2023-06-27T18:06:42.027005: step 3278, loss 0.0966288, acc 0.9375, learning_rate 0.000511643\n","2023-06-27T18:06:42.245454: step 3279, loss 0.0157189, acc 1, learning_rate 0.000511361\n","2023-06-27T18:06:42.421665: step 3280, loss 0.0246875, acc 1, learning_rate 0.000511079\n","2023-06-27T18:06:42.621708: step 3281, loss 0.0142267, acc 1, learning_rate 0.000510797\n","2023-06-27T18:06:42.817745: step 3282, loss 0.0168084, acc 1, learning_rate 0.000510515\n","2023-06-27T18:06:43.031177: step 3283, loss 0.125856, acc 0.9375, learning_rate 0.000510234\n","2023-06-27T18:06:43.240511: step 3284, loss 0.143739, acc 0.9375, learning_rate 0.000509953\n","2023-06-27T18:06:43.439536: step 3285, loss 0.0459165, acc 0.96875, learning_rate 0.000509672\n","2023-06-27T18:06:43.627941: step 3286, loss 0.0845715, acc 0.96875, learning_rate 0.000509391\n","2023-06-27T18:06:43.842937: step 3287, loss 0.0757786, acc 0.96875, learning_rate 0.00050911\n","2023-06-27T18:06:44.054995: step 3288, loss 0.010149, acc 1, learning_rate 0.000508829\n","2023-06-27T18:06:44.265952: step 3289, loss 0.0297289, acc 1, learning_rate 0.000508549\n","2023-06-27T18:06:44.487997: step 3290, loss 0.111166, acc 0.96875, learning_rate 0.000508269\n","2023-06-27T18:06:44.679174: step 3291, loss 0.285032, acc 0.875, learning_rate 0.000507989\n","2023-06-27T18:06:44.872552: step 3292, loss 0.178544, acc 0.96875, learning_rate 0.000507709\n","2023-06-27T18:06:45.081110: step 3293, loss 0.0625116, acc 0.96875, learning_rate 0.00050743\n","2023-06-27T18:06:45.265162: step 3294, loss 0.0468586, acc 0.96875, learning_rate 0.00050715\n","2023-06-27T18:06:45.469092: step 3295, loss 0.00726839, acc 1, learning_rate 0.000506871\n","2023-06-27T18:06:45.653059: step 3296, loss 0.234276, acc 0.90625, learning_rate 0.000506592\n","2023-06-27T18:06:45.834021: step 3297, loss 0.0202261, acc 1, learning_rate 0.000506313\n","2023-06-27T18:06:46.044535: step 3298, loss 0.0228735, acc 1, learning_rate 0.000506035\n","2023-06-27T18:06:46.247447: step 3299, loss 0.121901, acc 0.96875, learning_rate 0.000505756\n","\n","Evaluation:\n","2023-06-27T18:06:47.578929: step 3300, loss 0.713455, acc 0.802959\n","\n","Saved model checkpoint to /content/gdrive/MyDrive/lightweighted-cnn/train/runs/1687888658/checkpoints/model-3300\n","\n","2023-06-27T18:06:47.913740: step 3300, loss 0.146275, acc 0.90625, learning_rate 0.000505478\n","2023-06-27T18:06:48.106351: step 3301, loss 0.0761762, acc 0.96875, learning_rate 0.0005052\n","2023-06-27T18:06:48.313857: step 3302, loss 0.11853, acc 0.96875, learning_rate 0.000504922\n","2023-06-27T18:06:48.527402: step 3303, loss 0.091904, acc 0.96875, learning_rate 0.000504644\n","2023-06-27T18:06:48.722249: step 3304, loss 0.0629305, acc 0.96875, learning_rate 0.000504367\n","2023-06-27T18:06:48.919018: step 3305, loss 0.0147944, acc 1, learning_rate 0.00050409\n","2023-06-27T18:06:49.097452: step 3306, loss 0.0248352, acc 1, learning_rate 0.000503812\n","2023-06-27T18:06:49.265308: step 3307, loss 0.101398, acc 0.96875, learning_rate 0.000503536\n","2023-06-27T18:06:49.448401: step 3308, loss 0.0925166, acc 0.96875, learning_rate 0.000503259\n","2023-06-27T18:06:49.642607: step 3309, loss 0.0562004, acc 1, learning_rate 0.000502982\n","2023-06-27T18:06:49.802619: step 3310, loss 0.0267954, acc 1, learning_rate 0.000502706\n","2023-06-27T18:06:49.992907: step 3311, loss 0.243696, acc 0.84375, learning_rate 0.00050243\n","2023-06-27T18:06:50.184758: step 3312, loss 0.0788829, acc 0.96875, learning_rate 0.000502154\n","2023-06-27T18:06:50.373372: step 3313, loss 0.0259064, acc 1, learning_rate 0.000501878\n","2023-06-27T18:06:50.555083: step 3314, loss 0.112868, acc 0.9375, learning_rate 0.000501603\n","2023-06-27T18:06:50.743756: step 3315, loss 0.0510193, acc 1, learning_rate 0.000501327\n","2023-06-27T18:06:50.924302: step 3316, loss 0.113074, acc 0.9375, learning_rate 0.000501052\n","2023-06-27T18:06:51.108120: step 3317, loss 0.0108037, acc 1, learning_rate 0.000500777\n","2023-06-27T18:06:51.299109: step 3318, loss 0.0324852, acc 1, learning_rate 0.000500502\n","2023-06-27T18:06:51.474040: step 3319, loss 0.0438863, acc 0.96875, learning_rate 0.000500227\n","2023-06-27T18:06:51.659236: step 3320, loss 0.0583402, acc 0.96875, learning_rate 0.000499953\n","2023-06-27T18:06:51.826714: step 3321, loss 0.125623, acc 0.9375, learning_rate 0.000499679\n","2023-06-27T18:06:51.957031: step 3322, loss 0.0712113, acc 0.96875, learning_rate 0.000499405\n","2023-06-27T18:06:52.085811: step 3323, loss 0.076819, acc 0.96875, learning_rate 0.000499131\n","2023-06-27T18:06:52.205276: step 3324, loss 0.103851, acc 0.96875, learning_rate 0.000498857\n","2023-06-27T18:06:52.347020: step 3325, loss 0.0833292, acc 0.96875, learning_rate 0.000498584\n","2023-06-27T18:06:52.469775: step 3326, loss 0.0258161, acc 1, learning_rate 0.00049831\n","2023-06-27T18:06:52.587576: step 3327, loss 0.163171, acc 0.90625, learning_rate 0.000498037\n","2023-06-27T18:06:52.696533: step 3328, loss 0.128674, acc 0.9375, learning_rate 0.000497764\n","2023-06-27T18:06:52.823407: step 3329, loss 0.0792892, acc 0.9375, learning_rate 0.000497491\n","2023-06-27T18:06:52.949890: step 3330, loss 0.0213402, acc 1, learning_rate 0.000497219\n","2023-06-27T18:06:53.062349: step 3331, loss 0.140799, acc 0.9375, learning_rate 0.000496946\n","2023-06-27T18:06:53.187640: step 3332, loss 0.0558127, acc 1, learning_rate 0.000496674\n","2023-06-27T18:06:53.320500: step 3333, loss 0.0937075, acc 0.9375, learning_rate 0.000496402\n","2023-06-27T18:06:53.441982: step 3334, loss 0.0640738, acc 1, learning_rate 0.00049613\n","2023-06-27T18:06:53.553521: step 3335, loss 0.0367139, acc 1, learning_rate 0.000495859\n","2023-06-27T18:06:53.668182: step 3336, loss 0.24247, acc 0.90625, learning_rate 0.000495587\n","2023-06-27T18:06:53.798927: step 3337, loss 0.142851, acc 0.96875, learning_rate 0.000495316\n","2023-06-27T18:06:53.925722: step 3338, loss 0.116762, acc 0.96875, learning_rate 0.000495045\n","2023-06-27T18:06:54.042753: step 3339, loss 0.0459795, acc 1, learning_rate 0.000494774\n","2023-06-27T18:06:54.151170: step 3340, loss 0.159761, acc 0.9375, learning_rate 0.000494503\n","2023-06-27T18:06:54.273680: step 3341, loss 0.153463, acc 0.90625, learning_rate 0.000494233\n","2023-06-27T18:06:54.405295: step 3342, loss 0.0615374, acc 1, learning_rate 0.000493963\n","2023-06-27T18:06:54.560398: step 3343, loss 0.0477255, acc 1, learning_rate 0.000493692\n","2023-06-27T18:06:54.671648: step 3344, loss 0.0575182, acc 0.96875, learning_rate 0.000493422\n","2023-06-27T18:06:54.787859: step 3345, loss 0.0558407, acc 1, learning_rate 0.000493153\n","2023-06-27T18:06:54.916642: step 3346, loss 0.10528, acc 0.9375, learning_rate 0.000492883\n","2023-06-27T18:06:55.035910: step 3347, loss 0.0277835, acc 1, learning_rate 0.000492614\n","2023-06-27T18:06:55.150146: step 3348, loss 0.0369339, acc 1, learning_rate 0.000492344\n","2023-06-27T18:06:55.313787: step 3349, loss 0.0998496, acc 0.96875, learning_rate 0.000492075\n","2023-06-27T18:06:55.470344: step 3350, loss 0.0971792, acc 0.9375, learning_rate 0.000491807\n","2023-06-27T18:06:55.590426: step 3351, loss 0.0357623, acc 1, learning_rate 0.000491538\n","2023-06-27T18:06:55.720706: step 3352, loss 0.103526, acc 0.9375, learning_rate 0.000491269\n","2023-06-27T18:06:55.851031: step 3353, loss 0.227667, acc 0.90625, learning_rate 0.000491001\n","2023-06-27T18:06:55.968353: step 3354, loss 0.0317094, acc 1, learning_rate 0.000490733\n","2023-06-27T18:06:56.088950: step 3355, loss 0.0613466, acc 0.96875, learning_rate 0.000490465\n","2023-06-27T18:06:56.214788: step 3356, loss 0.192146, acc 0.875, learning_rate 0.000490197\n","2023-06-27T18:06:56.345361: step 3357, loss 0.0266051, acc 1, learning_rate 0.00048993\n","2023-06-27T18:06:56.467789: step 3358, loss 0.21403, acc 0.90625, learning_rate 0.000489662\n","2023-06-27T18:06:56.590911: step 3359, loss 0.124826, acc 0.9375, learning_rate 0.000489395\n","2023-06-27T18:06:56.697630: step 3360, loss 0.0833171, acc 0.9375, learning_rate 0.000489128\n","2023-06-27T18:06:56.825680: step 3361, loss 0.0335047, acc 0.96875, learning_rate 0.000488861\n","2023-06-27T18:06:56.944133: step 3362, loss 0.0484838, acc 1, learning_rate 0.000488595\n","2023-06-27T18:06:57.056967: step 3363, loss 0.114855, acc 0.9375, learning_rate 0.000488328\n","2023-06-27T18:06:57.194131: step 3364, loss 0.19317, acc 0.96875, learning_rate 0.000488062\n","2023-06-27T18:06:57.314004: step 3365, loss 0.0449483, acc 1, learning_rate 0.000487796\n","2023-06-27T18:06:57.451651: step 3366, loss 0.0260823, acc 1, learning_rate 0.00048753\n","2023-06-27T18:06:57.573045: step 3367, loss 0.0468237, acc 0.96875, learning_rate 0.000487264\n","2023-06-27T18:06:57.698772: step 3368, loss 0.0355761, acc 1, learning_rate 0.000486999\n","2023-06-27T18:06:57.813288: step 3369, loss 0.0538155, acc 0.96875, learning_rate 0.000486733\n","2023-06-27T18:06:57.944339: step 3370, loss 0.0386153, acc 1, learning_rate 0.000486468\n","2023-06-27T18:06:58.067771: step 3371, loss 0.142648, acc 0.9375, learning_rate 0.000486203\n","2023-06-27T18:06:58.177367: step 3372, loss 0.156993, acc 0.9375, learning_rate 0.000485938\n","2023-06-27T18:06:58.297807: step 3373, loss 0.0299254, acc 1, learning_rate 0.000485674\n","2023-06-27T18:06:58.425327: step 3374, loss 0.0390135, acc 1, learning_rate 0.000485409\n","2023-06-27T18:06:58.552506: step 3375, loss 0.0124668, acc 1, learning_rate 0.000485145\n","2023-06-27T18:06:58.672476: step 3376, loss 0.037111, acc 1, learning_rate 0.000484881\n","2023-06-27T18:06:58.793562: step 3377, loss 0.11025, acc 0.9375, learning_rate 0.000484617\n","2023-06-27T18:06:58.930664: step 3378, loss 0.140807, acc 0.90625, learning_rate 0.000484353\n","2023-06-27T18:06:59.057530: step 3379, loss 0.076729, acc 0.96875, learning_rate 0.000484089\n","2023-06-27T18:06:59.186632: step 3380, loss 0.0301513, acc 1, learning_rate 0.000483826\n","2023-06-27T18:06:59.309398: step 3381, loss 0.115148, acc 0.9375, learning_rate 0.000483563\n","2023-06-27T18:06:59.424053: step 3382, loss 0.0147226, acc 1, learning_rate 0.0004833\n","2023-06-27T18:06:59.550216: step 3383, loss 0.0464288, acc 1, learning_rate 0.000483037\n","2023-06-27T18:06:59.662326: step 3384, loss 0.242939, acc 0.90625, learning_rate 0.000482774\n","2023-06-27T18:06:59.786427: step 3385, loss 0.0181817, acc 1, learning_rate 0.000482512\n","2023-06-27T18:06:59.914606: step 3386, loss 0.158162, acc 0.9375, learning_rate 0.00048225\n","2023-06-27T18:07:00.033269: step 3387, loss 0.0703594, acc 0.96875, learning_rate 0.000481987\n","2023-06-27T18:07:00.153495: step 3388, loss 0.106294, acc 0.96875, learning_rate 0.000481726\n","2023-06-27T18:07:00.288703: step 3389, loss 0.0210695, acc 1, learning_rate 0.000481464\n","2023-06-27T18:07:00.441539: step 3390, loss 0.0732169, acc 0.96875, learning_rate 0.000481202\n","2023-06-27T18:07:00.549819: step 3391, loss 0.132294, acc 0.90625, learning_rate 0.000480941\n","2023-06-27T18:07:00.664776: step 3392, loss 0.305166, acc 0.90625, learning_rate 0.00048068\n","2023-06-27T18:07:00.786461: step 3393, loss 0.116611, acc 0.90625, learning_rate 0.000480419\n","2023-06-27T18:07:00.924815: step 3394, loss 0.0509787, acc 0.96875, learning_rate 0.000480158\n","2023-06-27T18:07:01.054899: step 3395, loss 0.046689, acc 0.96875, learning_rate 0.000479897\n","2023-06-27T18:07:01.172333: step 3396, loss 0.0942864, acc 0.96875, learning_rate 0.000479636\n","2023-06-27T18:07:01.300172: step 3397, loss 0.0944998, acc 0.96875, learning_rate 0.000479376\n","2023-06-27T18:07:01.426652: step 3398, loss 0.0986836, acc 0.96875, learning_rate 0.000479116\n","2023-06-27T18:07:01.550385: step 3399, loss 0.11161, acc 0.96875, learning_rate 0.000478856\n","\n","Evaluation:\n","2023-06-27T18:07:02.596363: step 3400, loss 0.742664, acc 0.796312\n","\n","Saved model checkpoint to /content/gdrive/MyDrive/lightweighted-cnn/train/runs/1687888658/checkpoints/model-3400\n","\n","2023-06-27T18:07:02.986409: step 3400, loss 0.148446, acc 0.90625, learning_rate 0.000478596\n","2023-06-27T18:07:03.195283: step 3401, loss 0.0779143, acc 0.96875, learning_rate 0.000478337\n","2023-06-27T18:07:03.401555: step 3402, loss 0.0622778, acc 0.96875, learning_rate 0.000478077\n","2023-06-27T18:07:03.591405: step 3403, loss 0.141519, acc 0.9375, learning_rate 0.000477818\n","2023-06-27T18:07:03.774835: step 3404, loss 0.14345, acc 0.9375, learning_rate 0.000477559\n","2023-06-27T18:07:03.972282: step 3405, loss 0.0262537, acc 1, learning_rate 0.0004773\n","2023-06-27T18:07:04.161234: step 3406, loss 0.0241352, acc 1, learning_rate 0.000477041\n","2023-06-27T18:07:04.383649: step 3407, loss 0.102323, acc 1, learning_rate 0.000476783\n","2023-06-27T18:07:04.625570: step 3408, loss 0.0217847, acc 1, learning_rate 0.000476524\n","2023-06-27T18:07:04.830868: step 3409, loss 0.0212852, acc 1, learning_rate 0.000476266\n","2023-06-27T18:07:05.045463: step 3410, loss 0.0795753, acc 0.9375, learning_rate 0.000476008\n","2023-06-27T18:07:05.243597: step 3411, loss 0.0651539, acc 0.96875, learning_rate 0.00047575\n","2023-06-27T18:07:05.463237: step 3412, loss 0.119058, acc 0.9375, learning_rate 0.000475493\n","2023-06-27T18:07:05.699863: step 3413, loss 0.0982338, acc 0.96875, learning_rate 0.000475235\n","2023-06-27T18:07:05.920763: step 3414, loss 0.0209589, acc 1, learning_rate 0.000474978\n","2023-06-27T18:07:06.103349: step 3415, loss 0.0890706, acc 1, learning_rate 0.000474721\n","2023-06-27T18:07:06.297049: step 3416, loss 0.0824313, acc 0.96875, learning_rate 0.000474464\n","2023-06-27T18:07:06.484992: step 3417, loss 0.110898, acc 0.96875, learning_rate 0.000474207\n","2023-06-27T18:07:06.690184: step 3418, loss 0.0473008, acc 1, learning_rate 0.00047395\n","2023-06-27T18:07:06.874924: step 3419, loss 0.0554824, acc 1, learning_rate 0.000473694\n","2023-06-27T18:07:07.075355: step 3420, loss 0.113216, acc 0.9375, learning_rate 0.000473438\n","2023-06-27T18:07:07.303106: step 3421, loss 0.128705, acc 0.96875, learning_rate 0.000473182\n","2023-06-27T18:07:07.520921: step 3422, loss 0.052751, acc 1, learning_rate 0.000472926\n","2023-06-27T18:07:07.724044: step 3423, loss 0.0470195, acc 0.96875, learning_rate 0.00047267\n","2023-06-27T18:07:07.917858: step 3424, loss 0.132631, acc 0.9375, learning_rate 0.000472414\n","2023-06-27T18:07:08.123498: step 3425, loss 0.130951, acc 0.96875, learning_rate 0.000472159\n","2023-06-27T18:07:08.343935: step 3426, loss 0.248931, acc 0.875, learning_rate 0.000471904\n","2023-06-27T18:07:08.562196: step 3427, loss 0.107561, acc 0.96875, learning_rate 0.000471649\n","2023-06-27T18:07:08.764234: step 3428, loss 0.0249739, acc 1, learning_rate 0.000471394\n","2023-06-27T18:07:08.975757: step 3429, loss 0.0392199, acc 0.96875, learning_rate 0.000471139\n","2023-06-27T18:07:09.166122: step 3430, loss 0.0302676, acc 1, learning_rate 0.000470885\n","2023-06-27T18:07:09.361173: step 3431, loss 0.026171, acc 1, learning_rate 0.00047063\n","2023-06-27T18:07:09.565063: step 3432, loss 0.0722996, acc 0.96875, learning_rate 0.000470376\n","2023-06-27T18:07:09.766725: step 3433, loss 0.0641636, acc 0.96875, learning_rate 0.000470122\n","2023-06-27T18:07:09.942298: step 3434, loss 0.0725985, acc 0.96875, learning_rate 0.000469869\n","2023-06-27T18:07:10.141623: step 3435, loss 0.134953, acc 0.9375, learning_rate 0.000469615\n","2023-06-27T18:07:10.377641: step 3436, loss 0.0245977, acc 1, learning_rate 0.000469361\n","2023-06-27T18:07:10.586832: step 3437, loss 0.107923, acc 0.96875, learning_rate 0.000469108\n","2023-06-27T18:07:10.785336: step 3438, loss 0.0986388, acc 0.96875, learning_rate 0.000468855\n","2023-06-27T18:07:10.970470: step 3439, loss 0.0490245, acc 1, learning_rate 0.000468602\n","2023-06-27T18:07:11.157641: step 3440, loss 0.0882903, acc 0.9375, learning_rate 0.000468349\n","2023-06-27T18:07:11.362462: step 3441, loss 0.0232759, acc 1, learning_rate 0.000468097\n","2023-06-27T18:07:11.535759: step 3442, loss 0.0757884, acc 0.96875, learning_rate 0.000467844\n","2023-06-27T18:07:11.731347: step 3443, loss 0.0381573, acc 0.96875, learning_rate 0.000467592\n","2023-06-27T18:07:11.921924: step 3444, loss 0.024826, acc 1, learning_rate 0.00046734\n","2023-06-27T18:07:12.101196: step 3445, loss 0.0217893, acc 1, learning_rate 0.000467088\n","2023-06-27T18:07:12.284144: step 3446, loss 0.0257806, acc 1, learning_rate 0.000466836\n","2023-06-27T18:07:12.460105: step 3447, loss 0.0649316, acc 0.96875, learning_rate 0.000466585\n","2023-06-27T18:07:12.638015: step 3448, loss 0.0925971, acc 0.9375, learning_rate 0.000466334\n","2023-06-27T18:07:12.842053: step 3449, loss 0.0766432, acc 0.96875, learning_rate 0.000466082\n","2023-06-27T18:07:12.967633: step 3450, loss 0.0808015, acc 0.9375, learning_rate 0.000465831\n","2023-06-27T18:07:13.082299: step 3451, loss 0.063472, acc 1, learning_rate 0.00046558\n","2023-06-27T18:07:13.210876: step 3452, loss 0.0498095, acc 1, learning_rate 0.00046533\n","2023-06-27T18:07:13.331406: step 3453, loss 0.156681, acc 0.9375, learning_rate 0.000465079\n","2023-06-27T18:07:13.470294: step 3454, loss 0.0552133, acc 0.96875, learning_rate 0.000464829\n","2023-06-27T18:07:13.594482: step 3455, loss 0.0780882, acc 0.96875, learning_rate 0.000464579\n","2023-06-27T18:07:13.717503: step 3456, loss 0.0667178, acc 1, learning_rate 0.000464329\n","2023-06-27T18:07:13.838837: step 3457, loss 0.0686237, acc 0.96875, learning_rate 0.000464079\n","2023-06-27T18:07:13.955755: step 3458, loss 0.0826557, acc 1, learning_rate 0.000463829\n","2023-06-27T18:07:14.092331: step 3459, loss 0.0593315, acc 0.96875, learning_rate 0.00046358\n","2023-06-27T18:07:14.200652: step 3460, loss 0.0704767, acc 1, learning_rate 0.00046333\n","2023-06-27T18:07:14.326235: step 3461, loss 0.0286693, acc 1, learning_rate 0.000463081\n","2023-06-27T18:07:14.465956: step 3462, loss 0.13755, acc 0.96875, learning_rate 0.000462832\n","2023-06-27T18:07:14.587895: step 3463, loss 0.0598576, acc 0.96875, learning_rate 0.000462584\n","2023-06-27T18:07:14.707373: step 3464, loss 0.238753, acc 0.875, learning_rate 0.000462335\n","2023-06-27T18:07:14.829378: step 3465, loss 0.0552475, acc 0.96875, learning_rate 0.000462086\n","2023-06-27T18:07:14.941691: step 3466, loss 0.104126, acc 0.96875, learning_rate 0.000461838\n","2023-06-27T18:07:15.048095: step 3467, loss 0.104085, acc 1, learning_rate 0.00046159\n","2023-06-27T18:07:15.172331: step 3468, loss 0.100532, acc 0.96875, learning_rate 0.000461342\n","2023-06-27T18:07:15.306836: step 3469, loss 0.0240911, acc 1, learning_rate 0.000461094\n","2023-06-27T18:07:15.433739: step 3470, loss 0.0242887, acc 1, learning_rate 0.000460847\n","2023-06-27T18:07:15.563705: step 3471, loss 0.131508, acc 0.9375, learning_rate 0.000460599\n","2023-06-27T18:07:15.678517: step 3472, loss 0.093285, acc 0.96875, learning_rate 0.000460352\n","2023-06-27T18:07:15.799978: step 3473, loss 0.052303, acc 1, learning_rate 0.000460105\n","2023-06-27T18:07:15.930215: step 3474, loss 0.0328732, acc 1, learning_rate 0.000459858\n","2023-06-27T18:07:16.047475: step 3475, loss 0.0447263, acc 1, learning_rate 0.000459611\n","2023-06-27T18:07:16.180089: step 3476, loss 0.145756, acc 0.96875, learning_rate 0.000459365\n","2023-06-27T18:07:16.313162: step 3477, loss 0.0329053, acc 1, learning_rate 0.000459118\n","2023-06-27T18:07:16.430309: step 3478, loss 0.186678, acc 0.96875, learning_rate 0.000458872\n","2023-06-27T18:07:16.592247: step 3479, loss 0.108724, acc 0.96875, learning_rate 0.000458626\n","2023-06-27T18:07:16.704606: step 3480, loss 0.217595, acc 0.9375, learning_rate 0.00045838\n","2023-06-27T18:07:16.821762: step 3481, loss 0.0540916, acc 0.96875, learning_rate 0.000458134\n","2023-06-27T18:07:16.948336: step 3482, loss 0.14353, acc 0.9375, learning_rate 0.000457889\n","2023-06-27T18:07:17.066921: step 3483, loss 0.0577419, acc 0.96875, learning_rate 0.000457643\n","2023-06-27T18:07:17.190148: step 3484, loss 0.0222062, acc 1, learning_rate 0.000457398\n","2023-06-27T18:07:17.313490: step 3485, loss 0.052332, acc 1, learning_rate 0.000457153\n","2023-06-27T18:07:17.451476: step 3486, loss 0.0485035, acc 0.96875, learning_rate 0.000456908\n","2023-06-27T18:07:17.575328: step 3487, loss 0.0485555, acc 0.96875, learning_rate 0.000456663\n","2023-06-27T18:07:17.687750: step 3488, loss 0.130437, acc 0.90625, learning_rate 0.000456419\n","2023-06-27T18:07:17.817362: step 3489, loss 0.145453, acc 0.90625, learning_rate 0.000456174\n","2023-06-27T18:07:17.944967: step 3490, loss 0.0283724, acc 1, learning_rate 0.00045593\n","2023-06-27T18:07:18.066767: step 3491, loss 0.0180164, acc 1, learning_rate 0.000455686\n","2023-06-27T18:07:18.194146: step 3492, loss 0.175235, acc 0.9375, learning_rate 0.000455442\n","2023-06-27T18:07:18.342446: step 3493, loss 0.108493, acc 0.9375, learning_rate 0.000455198\n","2023-06-27T18:07:18.492759: step 3494, loss 0.00878702, acc 1, learning_rate 0.000454955\n","2023-06-27T18:07:18.625648: step 3495, loss 0.0615956, acc 0.96875, learning_rate 0.000454711\n","2023-06-27T18:07:18.761836: step 3496, loss 0.103004, acc 0.96875, learning_rate 0.000454468\n","2023-06-27T18:07:18.891150: step 3497, loss 0.075197, acc 0.96875, learning_rate 0.000454225\n","2023-06-27T18:07:19.011088: step 3498, loss 0.180464, acc 0.90625, learning_rate 0.000453982\n","2023-06-27T18:07:19.137132: step 3499, loss 0.0352225, acc 1, learning_rate 0.000453739\n","\n","Evaluation:\n","2023-06-27T18:07:19.888130: step 3500, loss 0.732517, acc 0.801244\n","\n","Saved model checkpoint to /content/gdrive/MyDrive/lightweighted-cnn/train/runs/1687888658/checkpoints/model-3500\n","\n","2023-06-27T18:07:20.090293: step 3500, loss 0.0799579, acc 0.96875, learning_rate 0.000453497\n","2023-06-27T18:07:20.212718: step 3501, loss 0.0928742, acc 0.96875, learning_rate 0.000453254\n","2023-06-27T18:07:20.336706: step 3502, loss 0.0159014, acc 1, learning_rate 0.000453012\n","2023-06-27T18:07:20.450204: step 3503, loss 0.00026299, acc 1, learning_rate 0.00045277\n","2023-06-27T18:07:20.575438: step 3504, loss 0.139148, acc 0.96875, learning_rate 0.000452528\n","2023-06-27T18:07:20.750084: step 3505, loss 0.0121683, acc 1, learning_rate 0.000452286\n","2023-06-27T18:07:20.890967: step 3506, loss 0.0263988, acc 1, learning_rate 0.000452045\n","2023-06-27T18:07:21.016696: step 3507, loss 0.0779695, acc 0.96875, learning_rate 0.000451803\n","2023-06-27T18:07:21.144628: step 3508, loss 0.0957315, acc 0.96875, learning_rate 0.000451562\n","2023-06-27T18:07:21.284227: step 3509, loss 0.0335544, acc 1, learning_rate 0.000451321\n","2023-06-27T18:07:21.410955: step 3510, loss 0.0495774, acc 0.96875, learning_rate 0.00045108\n","2023-06-27T18:07:21.540233: step 3511, loss 0.109656, acc 0.96875, learning_rate 0.000450839\n","2023-06-27T18:07:21.690480: step 3512, loss 0.35163, acc 0.90625, learning_rate 0.000450599\n","2023-06-27T18:07:21.807542: step 3513, loss 0.0590303, acc 0.96875, learning_rate 0.000450358\n","2023-06-27T18:07:21.934665: step 3514, loss 0.017939, acc 1, learning_rate 0.000450118\n","2023-06-27T18:07:22.065226: step 3515, loss 0.0274835, acc 1, learning_rate 0.000449878\n","2023-06-27T18:07:22.179415: step 3516, loss 0.0650491, acc 1, learning_rate 0.000449638\n","2023-06-27T18:07:22.299068: step 3517, loss 0.119514, acc 0.9375, learning_rate 0.000449398\n","2023-06-27T18:07:22.451387: step 3518, loss 0.0219683, acc 1, learning_rate 0.000449159\n","2023-06-27T18:07:22.575264: step 3519, loss 0.0409127, acc 1, learning_rate 0.000448919\n","2023-06-27T18:07:22.697572: step 3520, loss 0.0195263, acc 1, learning_rate 0.00044868\n","2023-06-27T18:07:22.827043: step 3521, loss 0.0436011, acc 1, learning_rate 0.000448441\n","2023-06-27T18:07:23.013449: step 3522, loss 0.188282, acc 0.9375, learning_rate 0.000448202\n","2023-06-27T18:07:23.243479: step 3523, loss 0.0318299, acc 1, learning_rate 0.000447963\n","2023-06-27T18:07:23.438536: step 3524, loss 0.0481374, acc 1, learning_rate 0.000447725\n","2023-06-27T18:07:23.656625: step 3525, loss 0.0408665, acc 1, learning_rate 0.000447486\n","2023-06-27T18:07:23.866156: step 3526, loss 0.0509169, acc 0.96875, learning_rate 0.000447248\n","2023-06-27T18:07:24.086076: step 3527, loss 0.0766796, acc 0.96875, learning_rate 0.00044701\n","2023-06-27T18:07:24.299985: step 3528, loss 0.0423049, acc 1, learning_rate 0.000446772\n","2023-06-27T18:07:24.526557: step 3529, loss 0.156852, acc 0.9375, learning_rate 0.000446534\n","2023-06-27T18:07:24.733790: step 3530, loss 0.0362574, acc 1, learning_rate 0.000446297\n","2023-06-27T18:07:24.930163: step 3531, loss 0.0264043, acc 1, learning_rate 0.000446059\n","2023-06-27T18:07:25.119587: step 3532, loss 0.0111783, acc 1, learning_rate 0.000445822\n","2023-06-27T18:07:25.376158: step 3533, loss 0.129335, acc 0.9375, learning_rate 0.000445585\n","2023-06-27T18:07:25.594699: step 3534, loss 0.101208, acc 0.96875, learning_rate 0.000445348\n","2023-06-27T18:07:25.810373: step 3535, loss 0.280806, acc 0.96875, learning_rate 0.000445111\n","2023-06-27T18:07:26.003047: step 3536, loss 0.00912228, acc 1, learning_rate 0.000444874\n","2023-06-27T18:07:26.224619: step 3537, loss 0.1367, acc 0.96875, learning_rate 0.000444638\n","2023-06-27T18:07:26.434185: step 3538, loss 0.0386024, acc 1, learning_rate 0.000444401\n","2023-06-27T18:07:26.648353: step 3539, loss 0.206598, acc 0.90625, learning_rate 0.000444165\n","2023-06-27T18:07:26.875381: step 3540, loss 0.0466828, acc 1, learning_rate 0.000443929\n","2023-06-27T18:07:27.088157: step 3541, loss 0.00915901, acc 1, learning_rate 0.000443693\n","2023-06-27T18:07:27.304430: step 3542, loss 0.0757407, acc 0.96875, learning_rate 0.000443458\n","2023-06-27T18:07:27.488269: step 3543, loss 0.0683254, acc 0.96875, learning_rate 0.000443222\n","2023-06-27T18:07:27.696594: step 3544, loss 0.0329062, acc 1, learning_rate 0.000442987\n","2023-06-27T18:07:27.916309: step 3545, loss 0.0754984, acc 0.96875, learning_rate 0.000442752\n","2023-06-27T18:07:28.150764: step 3546, loss 0.0214867, acc 1, learning_rate 0.000442517\n","2023-06-27T18:07:28.375468: step 3547, loss 0.0337806, acc 1, learning_rate 0.000442282\n","2023-06-27T18:07:28.580088: step 3548, loss 0.121668, acc 0.9375, learning_rate 0.000442047\n","2023-06-27T18:07:28.774496: step 3549, loss 0.15184, acc 0.9375, learning_rate 0.000441813\n","2023-06-27T18:07:29.002996: step 3550, loss 0.082805, acc 0.96875, learning_rate 0.000441578\n","2023-06-27T18:07:29.182738: step 3551, loss 0.0637243, acc 0.96875, learning_rate 0.000441344\n","2023-06-27T18:07:29.377527: step 3552, loss 0.0399457, acc 0.96875, learning_rate 0.00044111\n","2023-06-27T18:07:29.592233: step 3553, loss 0.0920831, acc 1, learning_rate 0.000440876\n","2023-06-27T18:07:29.798053: step 3554, loss 0.0656426, acc 0.96875, learning_rate 0.000440642\n","2023-06-27T18:07:29.984953: step 3555, loss 0.120651, acc 0.96875, learning_rate 0.000440409\n","2023-06-27T18:07:30.168785: step 3556, loss 0.0159395, acc 1, learning_rate 0.000440175\n","2023-06-27T18:07:30.374969: step 3557, loss 0.0275017, acc 1, learning_rate 0.000439942\n","2023-06-27T18:07:30.622765: step 3558, loss 0.0172107, acc 1, learning_rate 0.000439709\n","2023-06-27T18:07:30.840898: step 3559, loss 0.0687798, acc 0.96875, learning_rate 0.000439476\n","2023-06-27T18:07:31.107147: step 3560, loss 0.139905, acc 0.9375, learning_rate 0.000439243\n","2023-06-27T18:07:31.346525: step 3561, loss 0.0781488, acc 0.96875, learning_rate 0.00043901\n","2023-06-27T18:07:31.586637: step 3562, loss 0.077449, acc 0.96875, learning_rate 0.000438778\n","2023-06-27T18:07:31.884051: step 3563, loss 0.0264955, acc 1, learning_rate 0.000438546\n","2023-06-27T18:07:32.130972: step 3564, loss 0.0540381, acc 0.96875, learning_rate 0.000438314\n","2023-06-27T18:07:32.372804: step 3565, loss 0.0491693, acc 0.96875, learning_rate 0.000438082\n","2023-06-27T18:07:32.585958: step 3566, loss 0.0700161, acc 0.96875, learning_rate 0.00043785\n","2023-06-27T18:07:32.837551: step 3567, loss 0.0178, acc 1, learning_rate 0.000437618\n","2023-06-27T18:07:33.101989: step 3568, loss 0.0417298, acc 0.96875, learning_rate 0.000437386\n","2023-06-27T18:07:33.400702: step 3569, loss 0.0172305, acc 1, learning_rate 0.000437155\n","2023-06-27T18:07:33.630887: step 3570, loss 0.183573, acc 0.90625, learning_rate 0.000436924\n","2023-06-27T18:07:33.866904: step 3571, loss 0.027604, acc 1, learning_rate 0.000436693\n","2023-06-27T18:07:34.100289: step 3572, loss 0.0837344, acc 0.9375, learning_rate 0.000436462\n","2023-06-27T18:07:34.340879: step 3573, loss 0.0194025, acc 1, learning_rate 0.000436231\n","2023-06-27T18:07:34.572503: step 3574, loss 0.0180047, acc 1, learning_rate 0.000436001\n","2023-06-27T18:07:34.858952: step 3575, loss 0.0285504, acc 1, learning_rate 0.00043577\n","2023-06-27T18:07:35.075398: step 3576, loss 0.015462, acc 1, learning_rate 0.00043554\n","2023-06-27T18:07:35.312912: step 3577, loss 0.0798211, acc 0.9375, learning_rate 0.00043531\n","2023-06-27T18:07:35.521549: step 3578, loss 0.0644325, acc 0.96875, learning_rate 0.00043508\n","2023-06-27T18:07:35.794902: step 3579, loss 0.0484125, acc 1, learning_rate 0.00043485\n","2023-06-27T18:07:36.054199: step 3580, loss 0.146902, acc 0.9375, learning_rate 0.000434621\n","2023-06-27T18:07:36.297119: step 3581, loss 0.0108959, acc 1, learning_rate 0.000434391\n","2023-06-27T18:07:36.486821: step 3582, loss 0.0152675, acc 1, learning_rate 0.000434162\n","2023-06-27T18:07:36.727035: step 3583, loss 0.0119837, acc 1, learning_rate 0.000433933\n","2023-06-27T18:07:36.939355: step 3584, loss 0.110726, acc 0.96875, learning_rate 0.000433704\n","2023-06-27T18:07:37.167408: step 3585, loss 0.0431285, acc 1, learning_rate 0.000433475\n","2023-06-27T18:07:37.407174: step 3586, loss 0.0429191, acc 1, learning_rate 0.000433246\n","2023-06-27T18:07:37.593392: step 3587, loss 0.0164049, acc 1, learning_rate 0.000433018\n","2023-06-27T18:07:37.767460: step 3588, loss 0.117476, acc 0.9375, learning_rate 0.000432789\n","2023-06-27T18:07:37.954399: step 3589, loss 0.0338433, acc 1, learning_rate 0.000432561\n","2023-06-27T18:07:38.138598: step 3590, loss 0.182549, acc 0.90625, learning_rate 0.000432333\n","2023-06-27T18:07:38.338966: step 3591, loss 0.0125409, acc 1, learning_rate 0.000432105\n","2023-06-27T18:07:38.538523: step 3592, loss 0.0349352, acc 0.96875, learning_rate 0.000431878\n","2023-06-27T18:07:38.739968: step 3593, loss 0.0362925, acc 1, learning_rate 0.00043165\n","2023-06-27T18:07:38.962211: step 3594, loss 0.077636, acc 0.96875, learning_rate 0.000431423\n","2023-06-27T18:07:39.154461: step 3595, loss 0.13845, acc 0.9375, learning_rate 0.000431195\n","2023-06-27T18:07:39.358582: step 3596, loss 0.176821, acc 0.90625, learning_rate 0.000430968\n","2023-06-27T18:07:39.556176: step 3597, loss 0.02638, acc 1, learning_rate 0.000430741\n","2023-06-27T18:07:39.759635: step 3598, loss 0.0419879, acc 1, learning_rate 0.000430514\n","2023-06-27T18:07:39.956056: step 3599, loss 0.183152, acc 0.9375, learning_rate 0.000430288\n","\n","Evaluation:\n","2023-06-27T18:07:41.259930: step 3600, loss 0.750889, acc 0.800815\n","\n","Saved model checkpoint to /content/gdrive/MyDrive/lightweighted-cnn/train/runs/1687888658/checkpoints/model-3600\n","\n","2023-06-27T18:07:41.609171: step 3600, loss 0.11973, acc 0.96875, learning_rate 0.000430061\n","2023-06-27T18:07:41.799185: step 3601, loss 0.0444766, acc 0.96875, learning_rate 0.000429835\n","2023-06-27T18:07:41.999366: step 3602, loss 0.0306023, acc 1, learning_rate 0.000429609\n","2023-06-27T18:07:42.199660: step 3603, loss 0.104086, acc 0.9375, learning_rate 0.000429383\n","2023-06-27T18:07:42.392537: step 3604, loss 0.0788192, acc 1, learning_rate 0.000429157\n","2023-06-27T18:07:42.581736: step 3605, loss 0.0478329, acc 0.96875, learning_rate 0.000428931\n","2023-06-27T18:07:42.772725: step 3606, loss 0.0303723, acc 1, learning_rate 0.000428706\n","2023-06-27T18:07:42.952054: step 3607, loss 0.0374417, acc 1, learning_rate 0.00042848\n","2023-06-27T18:07:43.159764: step 3608, loss 0.0546383, acc 1, learning_rate 0.000428255\n","2023-06-27T18:07:43.368910: step 3609, loss 0.0205403, acc 1, learning_rate 0.00042803\n","2023-06-27T18:07:43.572084: step 3610, loss 0.0362357, acc 1, learning_rate 0.000427805\n","2023-06-27T18:07:43.780666: step 3611, loss 0.149028, acc 0.9375, learning_rate 0.00042758\n","2023-06-27T18:07:43.975619: step 3612, loss 0.152818, acc 0.96875, learning_rate 0.000427356\n","2023-06-27T18:07:44.168286: step 3613, loss 0.0596935, acc 0.96875, learning_rate 0.000427131\n","2023-06-27T18:07:44.334304: step 3614, loss 0.145211, acc 0.90625, learning_rate 0.000426907\n","2023-06-27T18:07:44.461049: step 3615, loss 0.130227, acc 0.96875, learning_rate 0.000426683\n","2023-06-27T18:07:44.593067: step 3616, loss 0.0436088, acc 1, learning_rate 0.000426459\n","2023-06-27T18:07:44.737702: step 3617, loss 0.0834275, acc 0.96875, learning_rate 0.000426235\n","2023-06-27T18:07:44.860764: step 3618, loss 0.122441, acc 0.9375, learning_rate 0.000426011\n","2023-06-27T18:07:44.979690: step 3619, loss 0.0918741, acc 0.96875, learning_rate 0.000425787\n","2023-06-27T18:07:45.114411: step 3620, loss 0.118614, acc 0.96875, learning_rate 0.000425564\n","2023-06-27T18:07:45.239613: step 3621, loss 0.0372139, acc 1, learning_rate 0.000425341\n","2023-06-27T18:07:45.375243: step 3622, loss 0.0479013, acc 1, learning_rate 0.000425118\n","2023-06-27T18:07:45.502147: step 3623, loss 0.0526716, acc 1, learning_rate 0.000424895\n","2023-06-27T18:07:45.621782: step 3624, loss 0.0837449, acc 0.96875, learning_rate 0.000424672\n","2023-06-27T18:07:45.773247: step 3625, loss 0.0489241, acc 0.96875, learning_rate 0.000424449\n","2023-06-27T18:07:45.893260: step 3626, loss 0.0170524, acc 1, learning_rate 0.000424227\n","2023-06-27T18:07:46.009613: step 3627, loss 0.0963521, acc 1, learning_rate 0.000424005\n","2023-06-27T18:07:46.132568: step 3628, loss 0.0677312, acc 1, learning_rate 0.000423782\n","2023-06-27T18:07:46.256525: step 3629, loss 0.141727, acc 0.96875, learning_rate 0.00042356\n","2023-06-27T18:07:46.395652: step 3630, loss 0.09068, acc 0.96875, learning_rate 0.000423338\n","2023-06-27T18:07:46.509885: step 3631, loss 0.0960422, acc 0.9375, learning_rate 0.000423117\n","2023-06-27T18:07:46.636623: step 3632, loss 0.00925987, acc 1, learning_rate 0.000422895\n","2023-06-27T18:07:46.769657: step 3633, loss 0.0949768, acc 0.96875, learning_rate 0.000422674\n","2023-06-27T18:07:46.891501: step 3634, loss 0.0567234, acc 0.96875, learning_rate 0.000422453\n","2023-06-27T18:07:47.009008: step 3635, loss 0.0862543, acc 0.96875, learning_rate 0.000422231\n","2023-06-27T18:07:47.127243: step 3636, loss 0.0467941, acc 1, learning_rate 0.00042201\n","2023-06-27T18:07:47.259104: step 3637, loss 0.0239523, acc 1, learning_rate 0.00042179\n","2023-06-27T18:07:47.387498: step 3638, loss 0.213139, acc 0.90625, learning_rate 0.000421569\n","2023-06-27T18:07:47.585083: step 3639, loss 0.0877302, acc 0.96875, learning_rate 0.000421348\n","2023-06-27T18:07:47.824362: step 3640, loss 0.0183753, acc 1, learning_rate 0.000421128\n","2023-06-27T18:07:48.018036: step 3641, loss 0.184388, acc 0.90625, learning_rate 0.000420908\n","2023-06-27T18:07:48.235911: step 3642, loss 0.114101, acc 0.9375, learning_rate 0.000420688\n","2023-06-27T18:07:48.485567: step 3643, loss 0.0498253, acc 1, learning_rate 0.000420468\n","2023-06-27T18:07:48.721813: step 3644, loss 0.110632, acc 0.9375, learning_rate 0.000420248\n","2023-06-27T18:07:48.945273: step 3645, loss 0.0320613, acc 1, learning_rate 0.000420029\n","2023-06-27T18:07:49.164884: step 3646, loss 0.0575272, acc 0.96875, learning_rate 0.000419809\n","2023-06-27T18:07:49.362977: step 3647, loss 0.0510602, acc 1, learning_rate 0.00041959\n","2023-06-27T18:07:49.553027: step 3648, loss 0.0449313, acc 1, learning_rate 0.000419371\n","2023-06-27T18:07:49.746674: step 3649, loss 0.106526, acc 0.96875, learning_rate 0.000419152\n","2023-06-27T18:07:49.952983: step 3650, loss 0.0176638, acc 1, learning_rate 0.000418933\n","2023-06-27T18:07:50.181057: step 3651, loss 0.125225, acc 0.96875, learning_rate 0.000418714\n","2023-06-27T18:07:50.407218: step 3652, loss 0.0583341, acc 0.96875, learning_rate 0.000418496\n","2023-06-27T18:07:50.619084: step 3653, loss 0.00760839, acc 1, learning_rate 0.000418277\n","2023-06-27T18:07:50.809960: step 3654, loss 0.0303581, acc 1, learning_rate 0.000418059\n","2023-06-27T18:07:51.049996: step 3655, loss 0.0988041, acc 0.96875, learning_rate 0.000417841\n","2023-06-27T18:07:51.272739: step 3656, loss 0.100023, acc 0.9375, learning_rate 0.000417623\n","2023-06-27T18:07:51.480123: step 3657, loss 0.138163, acc 0.9375, learning_rate 0.000417405\n","2023-06-27T18:07:51.688173: step 3658, loss 0.100722, acc 0.9375, learning_rate 0.000417187\n","2023-06-27T18:07:51.878772: step 3659, loss 0.0124027, acc 1, learning_rate 0.00041697\n","2023-06-27T18:07:52.062891: step 3660, loss 0.0706732, acc 0.96875, learning_rate 0.000416753\n","2023-06-27T18:07:52.264765: step 3661, loss 0.00983893, acc 1, learning_rate 0.000416535\n","2023-06-27T18:07:52.502876: step 3662, loss 0.0223094, acc 1, learning_rate 0.000416318\n","2023-06-27T18:07:52.716813: step 3663, loss 0.0294746, acc 1, learning_rate 0.000416101\n","2023-06-27T18:07:52.914402: step 3664, loss 0.0781408, acc 1, learning_rate 0.000415885\n","2023-06-27T18:07:53.106443: step 3665, loss 0.0746586, acc 0.96875, learning_rate 0.000415668\n","2023-06-27T18:07:53.300198: step 3666, loss 0.0982204, acc 0.96875, learning_rate 0.000415452\n","2023-06-27T18:07:53.466485: step 3667, loss 0.0659607, acc 0.96875, learning_rate 0.000415235\n","2023-06-27T18:07:53.659670: step 3668, loss 0.0234243, acc 1, learning_rate 0.000415019\n","2023-06-27T18:07:53.856290: step 3669, loss 0.0382877, acc 1, learning_rate 0.000414803\n","2023-06-27T18:07:54.051070: step 3670, loss 0.0893792, acc 0.96875, learning_rate 0.000414587\n","2023-06-27T18:07:54.243155: step 3671, loss 0.0131186, acc 1, learning_rate 0.000414371\n","2023-06-27T18:07:54.443926: step 3672, loss 0.0803739, acc 0.96875, learning_rate 0.000414156\n","2023-06-27T18:07:54.650767: step 3673, loss 0.0704275, acc 0.9375, learning_rate 0.00041394\n","2023-06-27T18:07:54.842273: step 3674, loss 0.106977, acc 0.96875, learning_rate 0.000413725\n","2023-06-27T18:07:55.031568: step 3675, loss 0.0853678, acc 0.96875, learning_rate 0.00041351\n","2023-06-27T18:07:55.216092: step 3676, loss 0.0134238, acc 1, learning_rate 0.000413295\n","2023-06-27T18:07:55.423650: step 3677, loss 0.206378, acc 0.90625, learning_rate 0.00041308\n","2023-06-27T18:07:55.619274: step 3678, loss 0.0029938, acc 1, learning_rate 0.000412866\n","2023-06-27T18:07:55.811340: step 3679, loss 0.106143, acc 0.96875, learning_rate 0.000412651\n","2023-06-27T18:07:55.985454: step 3680, loss 0.0195079, acc 1, learning_rate 0.000412437\n","2023-06-27T18:07:56.188649: step 3681, loss 0.0761583, acc 0.96875, learning_rate 0.000412222\n","2023-06-27T18:07:56.395503: step 3682, loss 0.148297, acc 0.9375, learning_rate 0.000412008\n","2023-06-27T18:07:56.584555: step 3683, loss 0.0302806, acc 1, learning_rate 0.000411794\n","2023-06-27T18:07:56.783219: step 3684, loss 0.0278841, acc 1, learning_rate 0.000411581\n","2023-06-27T18:07:56.970574: step 3685, loss 0.100991, acc 0.9375, learning_rate 0.000411367\n","2023-06-27T18:07:57.182549: step 3686, loss 0.0143814, acc 1, learning_rate 0.000411153\n","2023-06-27T18:07:57.385031: step 3687, loss 0.0943639, acc 0.9375, learning_rate 0.00041094\n","2023-06-27T18:07:57.589028: step 3688, loss 0.0316846, acc 1, learning_rate 0.000410727\n","2023-06-27T18:07:57.806281: step 3689, loss 0.0635791, acc 0.96875, learning_rate 0.000410514\n","2023-06-27T18:07:57.997049: step 3690, loss 0.0603077, acc 1, learning_rate 0.000410301\n","2023-06-27T18:07:58.192489: step 3691, loss 0.0647202, acc 0.96875, learning_rate 0.000410088\n","2023-06-27T18:07:58.399256: step 3692, loss 0.184779, acc 0.90625, learning_rate 0.000409875\n","2023-06-27T18:07:58.512620: step 3693, loss 0.0435168, acc 0.96875, learning_rate 0.000409663\n","2023-06-27T18:07:58.630630: step 3694, loss 0.0606831, acc 0.96875, learning_rate 0.000409451\n","2023-06-27T18:07:58.748576: step 3695, loss 0.0413675, acc 0.96875, learning_rate 0.000409238\n","2023-06-27T18:07:58.876913: step 3696, loss 0.0551972, acc 0.96875, learning_rate 0.000409026\n","2023-06-27T18:07:59.004346: step 3697, loss 0.0337006, acc 1, learning_rate 0.000408814\n","2023-06-27T18:07:59.125327: step 3698, loss 0.0198655, acc 1, learning_rate 0.000408603\n","2023-06-27T18:07:59.260203: step 3699, loss 0.0772785, acc 0.96875, learning_rate 0.000408391\n","\n","Evaluation:\n","2023-06-27T18:07:59.998379: step 3700, loss 0.742116, acc 0.801458\n","\n","Saved model checkpoint to /content/gdrive/MyDrive/lightweighted-cnn/train/runs/1687888658/checkpoints/model-3700\n","\n","2023-06-27T18:08:00.232461: step 3700, loss 0.0833854, acc 0.96875, learning_rate 0.00040818\n","2023-06-27T18:08:00.381165: step 3701, loss 0.00842173, acc 1, learning_rate 0.000407968\n","2023-06-27T18:08:00.513110: step 3702, loss 0.0246648, acc 1, learning_rate 0.000407757\n","2023-06-27T18:08:00.623537: step 3703, loss 0.0299707, acc 1, learning_rate 0.000407546\n","2023-06-27T18:08:00.743362: step 3704, loss 0.109439, acc 0.96875, learning_rate 0.000407335\n","2023-06-27T18:08:00.861737: step 3705, loss 0.0592728, acc 0.96875, learning_rate 0.000407124\n","2023-06-27T18:08:00.997260: step 3706, loss 0.0347623, acc 1, learning_rate 0.000406914\n","2023-06-27T18:08:01.123424: step 3707, loss 0.0324668, acc 1, learning_rate 0.000406703\n","2023-06-27T18:08:01.242350: step 3708, loss 0.0908323, acc 0.96875, learning_rate 0.000406493\n","2023-06-27T18:08:01.366599: step 3709, loss 0.0109522, acc 1, learning_rate 0.000406283\n","2023-06-27T18:08:01.488153: step 3710, loss 0.0270668, acc 1, learning_rate 0.000406073\n","2023-06-27T18:08:01.598777: step 3711, loss 0.020716, acc 1, learning_rate 0.000405863\n","2023-06-27T18:08:01.715972: step 3712, loss 0.0608472, acc 0.96875, learning_rate 0.000405653\n","2023-06-27T18:08:01.834844: step 3713, loss 0.0442514, acc 0.96875, learning_rate 0.000405444\n","2023-06-27T18:08:01.956894: step 3714, loss 0.0400528, acc 1, learning_rate 0.000405234\n","2023-06-27T18:08:02.079865: step 3715, loss 0.022971, acc 1, learning_rate 0.000405025\n","2023-06-27T18:08:02.192782: step 3716, loss 0.0409842, acc 0.96875, learning_rate 0.000404816\n","2023-06-27T18:08:02.306283: step 3717, loss 0.0739948, acc 0.96875, learning_rate 0.000404607\n","2023-06-27T18:08:02.443926: step 3718, loss 0.0136754, acc 1, learning_rate 0.000404398\n","2023-06-27T18:08:02.561037: step 3719, loss 0.0637646, acc 0.96875, learning_rate 0.000404189\n","2023-06-27T18:08:02.685744: step 3720, loss 0.110056, acc 0.9375, learning_rate 0.00040398\n","2023-06-27T18:08:02.796072: step 3721, loss 0.0385183, acc 1, learning_rate 0.000403772\n","2023-06-27T18:08:02.911954: step 3722, loss 0.00568683, acc 1, learning_rate 0.000403564\n","2023-06-27T18:08:03.031250: step 3723, loss 0.0302032, acc 1, learning_rate 0.000403356\n","2023-06-27T18:08:03.147962: step 3724, loss 0.028871, acc 1, learning_rate 0.000403148\n","2023-06-27T18:08:03.283556: step 3725, loss 0.0651628, acc 0.96875, learning_rate 0.00040294\n","2023-06-27T18:08:03.407404: step 3726, loss 0.0177671, acc 1, learning_rate 0.000402732\n","2023-06-27T18:08:03.517061: step 3727, loss 0.0274751, acc 1, learning_rate 0.000402524\n","2023-06-27T18:08:03.633175: step 3728, loss 0.0252809, acc 1, learning_rate 0.000402317\n","2023-06-27T18:08:03.751128: step 3729, loss 0.224104, acc 0.90625, learning_rate 0.00040211\n","2023-06-27T18:08:03.883501: step 3730, loss 0.038779, acc 1, learning_rate 0.000401902\n","2023-06-27T18:08:04.014132: step 3731, loss 0.0150471, acc 1, learning_rate 0.000401695\n","2023-06-27T18:08:04.127719: step 3732, loss 0.0873701, acc 0.9375, learning_rate 0.000401488\n","2023-06-27T18:08:04.253458: step 3733, loss 0.031195, acc 1, learning_rate 0.000401282\n","2023-06-27T18:08:04.376892: step 3734, loss 0.0482775, acc 0.96875, learning_rate 0.000401075\n","2023-06-27T18:08:04.512331: step 3735, loss 0.118672, acc 0.96875, learning_rate 0.000400869\n","2023-06-27T18:08:04.631856: step 3736, loss 0.0629718, acc 0.96875, learning_rate 0.000400662\n","2023-06-27T18:08:04.763279: step 3737, loss 0.0433514, acc 1, learning_rate 0.000400456\n","2023-06-27T18:08:04.884670: step 3738, loss 0.0424951, acc 1, learning_rate 0.00040025\n","2023-06-27T18:08:04.998637: step 3739, loss 0.0327138, acc 1, learning_rate 0.000400044\n","2023-06-27T18:08:05.112815: step 3740, loss 0.0173512, acc 1, learning_rate 0.000399839\n","2023-06-27T18:08:05.228837: step 3741, loss 0.0473429, acc 0.96875, learning_rate 0.000399633\n","2023-06-27T18:08:05.365680: step 3742, loss 0.043044, acc 1, learning_rate 0.000399427\n","2023-06-27T18:08:05.526552: step 3743, loss 0.0935891, acc 0.96875, learning_rate 0.000399222\n","2023-06-27T18:08:05.650697: step 3744, loss 0.0157338, acc 1, learning_rate 0.000399017\n","2023-06-27T18:08:05.776797: step 3745, loss 0.104786, acc 0.96875, learning_rate 0.000398812\n","2023-06-27T18:08:05.900793: step 3746, loss 0.0740637, acc 0.96875, learning_rate 0.000398607\n","2023-06-27T18:08:06.010204: step 3747, loss 0.0204102, acc 1, learning_rate 0.000398402\n","2023-06-27T18:08:06.114693: step 3748, loss 0.0499288, acc 0.96875, learning_rate 0.000398198\n","2023-06-27T18:08:06.250820: step 3749, loss 0.0239163, acc 1, learning_rate 0.000397993\n","2023-06-27T18:08:06.372120: step 3750, loss 0.183841, acc 0.9375, learning_rate 0.000397789\n","2023-06-27T18:08:06.513357: step 3751, loss 0.151318, acc 0.9375, learning_rate 0.000397585\n","2023-06-27T18:08:06.636206: step 3752, loss 0.0541139, acc 1, learning_rate 0.000397381\n","2023-06-27T18:08:06.765728: step 3753, loss 0.0890615, acc 0.96875, learning_rate 0.000397177\n","2023-06-27T18:08:06.906183: step 3754, loss 0.15348, acc 0.90625, learning_rate 0.000396973\n","2023-06-27T18:08:07.015337: step 3755, loss 0.0501685, acc 1, learning_rate 0.000396769\n","2023-06-27T18:08:07.136902: step 3756, loss 0.016492, acc 1, learning_rate 0.000396566\n","2023-06-27T18:08:07.255620: step 3757, loss 0.112649, acc 0.9375, learning_rate 0.000396362\n","2023-06-27T18:08:07.383690: step 3758, loss 0.027982, acc 1, learning_rate 0.000396159\n","2023-06-27T18:08:07.514812: step 3759, loss 0.0270212, acc 1, learning_rate 0.000395956\n","2023-06-27T18:08:07.632431: step 3760, loss 0.0696565, acc 0.96875, learning_rate 0.000395753\n","2023-06-27T18:08:07.763680: step 3761, loss 0.0760827, acc 1, learning_rate 0.00039555\n","2023-06-27T18:08:07.873246: step 3762, loss 0.133721, acc 0.90625, learning_rate 0.000395348\n","2023-06-27T18:08:07.990536: step 3763, loss 0.0604938, acc 1, learning_rate 0.000395145\n","2023-06-27T18:08:08.106942: step 3764, loss 0.0304386, acc 1, learning_rate 0.000394943\n","2023-06-27T18:08:08.229522: step 3765, loss 0.0418849, acc 1, learning_rate 0.00039474\n","2023-06-27T18:08:08.362436: step 3766, loss 0.0125014, acc 1, learning_rate 0.000394538\n","2023-06-27T18:08:08.554489: step 3767, loss 0.0148545, acc 1, learning_rate 0.000394336\n","2023-06-27T18:08:08.762233: step 3768, loss 0.0336481, acc 1, learning_rate 0.000394135\n","2023-06-27T18:08:08.966794: step 3769, loss 0.0163045, acc 1, learning_rate 0.000393933\n","2023-06-27T18:08:09.169192: step 3770, loss 0.0150296, acc 1, learning_rate 0.000393731\n","2023-06-27T18:08:09.398396: step 3771, loss 0.118602, acc 0.96875, learning_rate 0.00039353\n","2023-06-27T18:08:09.611424: step 3772, loss 0.0275585, acc 1, learning_rate 0.000393329\n","2023-06-27T18:08:09.818259: step 3773, loss 0.0775048, acc 0.96875, learning_rate 0.000393127\n","2023-06-27T18:08:10.020601: step 3774, loss 0.0542325, acc 0.96875, learning_rate 0.000392926\n","2023-06-27T18:08:10.218819: step 3775, loss 0.0817889, acc 1, learning_rate 0.000392726\n","2023-06-27T18:08:10.422746: step 3776, loss 0.0707762, acc 0.96875, learning_rate 0.000392525\n","2023-06-27T18:08:10.624060: step 3777, loss 0.159527, acc 0.90625, learning_rate 0.000392324\n","2023-06-27T18:08:10.837196: step 3778, loss 0.0799388, acc 0.9375, learning_rate 0.000392124\n","2023-06-27T18:08:11.045793: step 3779, loss 0.0867164, acc 0.9375, learning_rate 0.000391923\n","2023-06-27T18:08:11.235487: step 3780, loss 0.0622232, acc 0.96875, learning_rate 0.000391723\n","2023-06-27T18:08:11.436647: step 3781, loss 0.0579432, acc 0.96875, learning_rate 0.000391523\n","2023-06-27T18:08:11.654420: step 3782, loss 0.0301308, acc 1, learning_rate 0.000391323\n","2023-06-27T18:08:11.872808: step 3783, loss 0.0525925, acc 1, learning_rate 0.000391124\n","2023-06-27T18:08:12.061369: step 3784, loss 0.299133, acc 0.875, learning_rate 0.000390924\n","2023-06-27T18:08:12.263039: step 3785, loss 0.0168284, acc 1, learning_rate 0.000390724\n","2023-06-27T18:08:12.462993: step 3786, loss 0.0610557, acc 0.96875, learning_rate 0.000390525\n","2023-06-27T18:08:12.658086: step 3787, loss 0.0363779, acc 1, learning_rate 0.000390326\n","2023-06-27T18:08:12.870327: step 3788, loss 0.0694027, acc 0.96875, learning_rate 0.000390127\n","2023-06-27T18:08:13.058550: step 3789, loss 0.0558083, acc 1, learning_rate 0.000389928\n","2023-06-27T18:08:13.256580: step 3790, loss 0.0821685, acc 0.96875, learning_rate 0.000389729\n","2023-06-27T18:08:13.461882: step 3791, loss 0.00840188, acc 1, learning_rate 0.00038953\n","2023-06-27T18:08:13.630730: step 3792, loss 0.0912746, acc 0.96875, learning_rate 0.000389332\n","2023-06-27T18:08:13.816831: step 3793, loss 0.0721362, acc 0.96875, learning_rate 0.000389133\n","2023-06-27T18:08:14.017098: step 3794, loss 0.0190346, acc 1, learning_rate 0.000388935\n","2023-06-27T18:08:14.212886: step 3795, loss 0.0827909, acc 0.96875, learning_rate 0.000388737\n","2023-06-27T18:08:14.410542: step 3796, loss 0.195261, acc 0.9375, learning_rate 0.000388539\n","2023-06-27T18:08:14.623052: step 3797, loss 0.027436, acc 1, learning_rate 0.000388341\n","2023-06-27T18:08:14.815665: step 3798, loss 0.279874, acc 0.9375, learning_rate 0.000388143\n","2023-06-27T18:08:15.015414: step 3799, loss 0.0431545, acc 1, learning_rate 0.000387946\n","\n","Evaluation:\n","2023-06-27T18:08:16.308596: step 3800, loss 0.756059, acc 0.799743\n","\n","Saved model checkpoint to /content/gdrive/MyDrive/lightweighted-cnn/train/runs/1687888658/checkpoints/model-3800\n","\n","2023-06-27T18:08:16.648701: step 3800, loss 0.024507, acc 1, learning_rate 0.000387748\n","2023-06-27T18:08:16.819478: step 3801, loss 0.188161, acc 0.90625, learning_rate 0.000387551\n","2023-06-27T18:08:17.017770: step 3802, loss 0.0159156, acc 1, learning_rate 0.000387354\n","2023-06-27T18:08:17.221612: step 3803, loss 0.159159, acc 0.96875, learning_rate 0.000387157\n","2023-06-27T18:08:17.406704: step 3804, loss 0.0323468, acc 1, learning_rate 0.00038696\n","2023-06-27T18:08:17.599534: step 3805, loss 0.00377512, acc 1, learning_rate 0.000386763\n","2023-06-27T18:08:17.771577: step 3806, loss 0.0972171, acc 0.96875, learning_rate 0.000386567\n","2023-06-27T18:08:17.976441: step 3807, loss 0.0409535, acc 1, learning_rate 0.00038637\n","2023-06-27T18:08:18.163758: step 3808, loss 0.16107, acc 0.96875, learning_rate 0.000386174\n","2023-06-27T18:08:18.363560: step 3809, loss 0.159126, acc 0.9375, learning_rate 0.000385977\n","2023-06-27T18:08:18.588683: step 3810, loss 0.0650488, acc 0.96875, learning_rate 0.000385781\n","2023-06-27T18:08:18.792095: step 3811, loss 0.181558, acc 0.9375, learning_rate 0.000385585\n","2023-06-27T18:08:18.981451: step 3812, loss 0.00764862, acc 1, learning_rate 0.00038539\n","2023-06-27T18:08:19.162481: step 3813, loss 0.112608, acc 0.9375, learning_rate 0.000385194\n","2023-06-27T18:08:19.362395: step 3814, loss 0.106958, acc 0.96875, learning_rate 0.000384998\n","2023-06-27T18:08:19.481278: step 3815, loss 0.0420136, acc 1, learning_rate 0.000384803\n","2023-06-27T18:08:19.591421: step 3816, loss 0.134131, acc 0.90625, learning_rate 0.000384608\n","2023-06-27T18:08:19.727426: step 3817, loss 0.099181, acc 0.96875, learning_rate 0.000384412\n","2023-06-27T18:08:19.848920: step 3818, loss 0.0782736, acc 0.96875, learning_rate 0.000384217\n","2023-06-27T18:08:19.969986: step 3819, loss 0.165257, acc 0.96875, learning_rate 0.000384022\n","2023-06-27T18:08:20.086962: step 3820, loss 0.0232083, acc 1, learning_rate 0.000383828\n","2023-06-27T18:08:20.206955: step 3821, loss 0.147811, acc 0.9375, learning_rate 0.000383633\n","2023-06-27T18:08:20.329971: step 3822, loss 0.0636831, acc 0.96875, learning_rate 0.000383439\n","2023-06-27T18:08:20.443118: step 3823, loss 0.206853, acc 0.9375, learning_rate 0.000383244\n","2023-06-27T18:08:20.588462: step 3824, loss 0.0691124, acc 1, learning_rate 0.00038305\n","2023-06-27T18:08:20.718810: step 3825, loss 0.226258, acc 0.875, learning_rate 0.000382856\n","2023-06-27T18:08:20.826688: step 3826, loss 0.106284, acc 0.9375, learning_rate 0.000382662\n","2023-06-27T18:08:20.959671: step 3827, loss 0.0446595, acc 0.96875, learning_rate 0.000382468\n","2023-06-27T18:08:21.084835: step 3828, loss 0.114154, acc 0.9375, learning_rate 0.000382274\n","2023-06-27T18:08:21.211871: step 3829, loss 0.126067, acc 0.96875, learning_rate 0.000382081\n","2023-06-27T18:08:21.354430: step 3830, loss 0.204293, acc 0.90625, learning_rate 0.000381887\n","2023-06-27T18:08:21.485198: step 3831, loss 0.14873, acc 0.90625, learning_rate 0.000381694\n","2023-06-27T18:08:21.609832: step 3832, loss 0.175418, acc 0.9375, learning_rate 0.000381501\n","2023-06-27T18:08:21.732677: step 3833, loss 0.0716101, acc 0.96875, learning_rate 0.000381308\n","2023-06-27T18:08:21.854718: step 3834, loss 0.0350704, acc 1, learning_rate 0.000381115\n","2023-06-27T18:08:21.973769: step 3835, loss 0.0334808, acc 1, learning_rate 0.000380922\n","2023-06-27T18:08:22.101550: step 3836, loss 0.0203091, acc 1, learning_rate 0.00038073\n","2023-06-27T18:08:22.218712: step 3837, loss 0.118401, acc 0.9375, learning_rate 0.000380537\n","2023-06-27T18:08:22.342632: step 3838, loss 0.0301113, acc 1, learning_rate 0.000380345\n","2023-06-27T18:08:22.467174: step 3839, loss 0.0666525, acc 0.96875, learning_rate 0.000380153\n","2023-06-27T18:08:22.592401: step 3840, loss 0.0667241, acc 0.96875, learning_rate 0.00037996\n","2023-06-27T18:08:22.716058: step 3841, loss 0.0255298, acc 1, learning_rate 0.000379768\n","2023-06-27T18:08:22.848041: step 3842, loss 0.0331515, acc 0.96875, learning_rate 0.000379577\n","2023-06-27T18:08:22.958748: step 3843, loss 0.042239, acc 1, learning_rate 0.000379385\n","2023-06-27T18:08:23.102578: step 3844, loss 0.173927, acc 0.9375, learning_rate 0.000379193\n","2023-06-27T18:08:23.222464: step 3845, loss 0.0394844, acc 0.96875, learning_rate 0.000379002\n","2023-06-27T18:08:23.339537: step 3846, loss 0.0741537, acc 0.96875, learning_rate 0.000378811\n","2023-06-27T18:08:23.463122: step 3847, loss 0.107207, acc 0.9375, learning_rate 0.000378619\n","2023-06-27T18:08:23.582250: step 3848, loss 0.0185158, acc 1, learning_rate 0.000378428\n","2023-06-27T18:08:23.709842: step 3849, loss 0.0615888, acc 0.96875, learning_rate 0.000378237\n","2023-06-27T18:08:23.833520: step 3850, loss 0.0444561, acc 0.96875, learning_rate 0.000378047\n","2023-06-27T18:08:23.947066: step 3851, loss 0.0182828, acc 1, learning_rate 0.000377856\n","2023-06-27T18:08:24.068695: step 3852, loss 0.099236, acc 0.96875, learning_rate 0.000377665\n","2023-06-27T18:08:24.191125: step 3853, loss 0.0829719, acc 0.96875, learning_rate 0.000377475\n","2023-06-27T18:08:24.310339: step 3854, loss 0.0100365, acc 1, learning_rate 0.000377285\n","2023-06-27T18:08:24.432128: step 3855, loss 0.0250272, acc 1, learning_rate 0.000377095\n","2023-06-27T18:08:24.563303: step 3856, loss 0.0176002, acc 1, learning_rate 0.000376905\n","2023-06-27T18:08:24.687383: step 3857, loss 0.133407, acc 0.9375, learning_rate 0.000376715\n","2023-06-27T18:08:24.808951: step 3858, loss 0.0389662, acc 1, learning_rate 0.000376525\n","2023-06-27T18:08:24.933048: step 3859, loss 0.0332751, acc 0.96875, learning_rate 0.000376335\n","2023-06-27T18:08:25.056595: step 3860, loss 0.0409537, acc 0.96875, learning_rate 0.000376146\n","2023-06-27T18:08:25.196669: step 3861, loss 0.0460572, acc 0.96875, learning_rate 0.000375956\n","2023-06-27T18:08:25.318375: step 3862, loss 0.0274692, acc 1, learning_rate 0.000375767\n","2023-06-27T18:08:25.475975: step 3863, loss 0.0647102, acc 0.96875, learning_rate 0.000375578\n","2023-06-27T18:08:25.604592: step 3864, loss 0.0580671, acc 1, learning_rate 0.000375389\n","2023-06-27T18:08:25.726728: step 3865, loss 0.112778, acc 0.96875, learning_rate 0.0003752\n","2023-06-27T18:08:25.851113: step 3866, loss 0.199372, acc 0.9375, learning_rate 0.000375012\n","2023-06-27T18:08:25.974067: step 3867, loss 0.0522127, acc 0.96875, learning_rate 0.000374823\n","2023-06-27T18:08:26.094737: step 3868, loss 0.0363374, acc 1, learning_rate 0.000374635\n","2023-06-27T18:08:26.222188: step 3869, loss 0.0220372, acc 1, learning_rate 0.000374446\n","2023-06-27T18:08:26.336461: step 3870, loss 0.090348, acc 0.9375, learning_rate 0.000374258\n","2023-06-27T18:08:26.453314: step 3871, loss 0.118531, acc 0.96875, learning_rate 0.00037407\n","2023-06-27T18:08:26.580575: step 3872, loss 0.0833868, acc 0.96875, learning_rate 0.000373882\n","2023-06-27T18:08:26.709762: step 3873, loss 0.0672859, acc 0.96875, learning_rate 0.000373694\n","2023-06-27T18:08:26.817891: step 3874, loss 0.0553291, acc 0.96875, learning_rate 0.000373507\n","2023-06-27T18:08:26.942909: step 3875, loss 0.0749863, acc 0.9375, learning_rate 0.000373319\n","2023-06-27T18:08:27.062054: step 3876, loss 0.012868, acc 1, learning_rate 0.000373132\n","2023-06-27T18:08:27.184322: step 3877, loss 0.101431, acc 0.9375, learning_rate 0.000372944\n","2023-06-27T18:08:27.320202: step 3878, loss 0.0246133, acc 1, learning_rate 0.000372757\n","2023-06-27T18:08:27.447602: step 3879, loss 0.0938485, acc 0.9375, learning_rate 0.00037257\n","2023-06-27T18:08:27.569804: step 3880, loss 0.0569002, acc 0.96875, learning_rate 0.000372383\n","2023-06-27T18:08:27.685546: step 3881, loss 0.0267023, acc 1, learning_rate 0.000372196\n","2023-06-27T18:08:27.807374: step 3882, loss 0.0526626, acc 1, learning_rate 0.00037201\n","2023-06-27T18:08:27.931633: step 3883, loss 0.0714061, acc 0.96875, learning_rate 0.000371823\n","2023-06-27T18:08:28.045721: step 3884, loss 0.228284, acc 0.90625, learning_rate 0.000371637\n","2023-06-27T18:08:28.170949: step 3885, loss 0.0315066, acc 1, learning_rate 0.000371451\n","2023-06-27T18:08:28.306948: step 3886, loss 0.064191, acc 1, learning_rate 0.000371264\n","2023-06-27T18:08:28.422297: step 3887, loss 0.262331, acc 0.9375, learning_rate 0.000371078\n","2023-06-27T18:08:28.552287: step 3888, loss 0.107088, acc 0.9375, learning_rate 0.000370893\n","2023-06-27T18:08:28.691677: step 3889, loss 0.0474811, acc 1, learning_rate 0.000370707\n","2023-06-27T18:08:28.820518: step 3890, loss 0.0868053, acc 0.96875, learning_rate 0.000370521\n","2023-06-27T18:08:28.941208: step 3891, loss 0.141094, acc 0.9375, learning_rate 0.000370336\n","2023-06-27T18:08:29.052396: step 3892, loss 0.0576057, acc 1, learning_rate 0.00037015\n","2023-06-27T18:08:29.186583: step 3893, loss 0.0954469, acc 0.96875, learning_rate 0.000369965\n","2023-06-27T18:08:29.315377: step 3894, loss 0.0641089, acc 0.96875, learning_rate 0.00036978\n","2023-06-27T18:08:29.472216: step 3895, loss 0.129513, acc 0.9375, learning_rate 0.000369595\n","2023-06-27T18:08:29.662339: step 3896, loss 0.0187236, acc 1, learning_rate 0.00036941\n","2023-06-27T18:08:29.865381: step 3897, loss 0.201745, acc 0.9375, learning_rate 0.000369225\n","2023-06-27T18:08:30.066190: step 3898, loss 0.053925, acc 0.96875, learning_rate 0.000369041\n","2023-06-27T18:08:30.282452: step 3899, loss 0.0437305, acc 0.96875, learning_rate 0.000368856\n","\n","Evaluation:\n","2023-06-27T18:08:31.689127: step 3900, loss 0.755175, acc 0.802101\n","\n","Saved model checkpoint to /content/gdrive/MyDrive/lightweighted-cnn/train/runs/1687888658/checkpoints/model-3900\n","\n","2023-06-27T18:08:32.059880: step 3900, loss 0.0507195, acc 0.96875, learning_rate 0.000368672\n","2023-06-27T18:08:32.258309: step 3901, loss 0.115887, acc 0.96875, learning_rate 0.000368488\n","2023-06-27T18:08:32.478145: step 3902, loss 0.0938057, acc 0.9375, learning_rate 0.000368303\n","2023-06-27T18:08:32.685107: step 3903, loss 0.0987214, acc 0.96875, learning_rate 0.00036812\n","2023-06-27T18:08:32.906170: step 3904, loss 0.0631289, acc 1, learning_rate 0.000367936\n","2023-06-27T18:08:33.120646: step 3905, loss 0.0531242, acc 1, learning_rate 0.000367752\n","2023-06-27T18:08:33.333377: step 3906, loss 0.0267089, acc 1, learning_rate 0.000367568\n","2023-06-27T18:08:33.517006: step 3907, loss 0.0110971, acc 1, learning_rate 0.000367385\n","2023-06-27T18:08:33.714192: step 3908, loss 0.0247283, acc 1, learning_rate 0.000367201\n","2023-06-27T18:08:33.920414: step 3909, loss 0.0220413, acc 1, learning_rate 0.000367018\n","2023-06-27T18:08:34.108917: step 3910, loss 0.0284841, acc 1, learning_rate 0.000366835\n","2023-06-27T18:08:34.311436: step 3911, loss 0.0937886, acc 0.96875, learning_rate 0.000366652\n","2023-06-27T18:08:34.494993: step 3912, loss 0.0246335, acc 1, learning_rate 0.000366469\n","2023-06-27T18:08:34.672809: step 3913, loss 0.0119805, acc 1, learning_rate 0.000366287\n","2023-06-27T18:08:34.856029: step 3914, loss 0.0431203, acc 1, learning_rate 0.000366104\n","2023-06-27T18:08:35.042217: step 3915, loss 0.0898129, acc 0.96875, learning_rate 0.000365922\n","2023-06-27T18:08:35.231274: step 3916, loss 0.0874302, acc 0.9375, learning_rate 0.000365739\n","2023-06-27T18:08:35.453158: step 3917, loss 0.0431136, acc 0.96875, learning_rate 0.000365557\n","2023-06-27T18:08:35.634375: step 3918, loss 0.0989617, acc 0.96875, learning_rate 0.000365375\n","2023-06-27T18:08:35.834687: step 3919, loss 0.0513865, acc 0.96875, learning_rate 0.000365193\n","2023-06-27T18:08:36.022981: step 3920, loss 0.0371904, acc 1, learning_rate 0.000365011\n","2023-06-27T18:08:36.224234: step 3921, loss 0.0463195, acc 0.96875, learning_rate 0.000364829\n","2023-06-27T18:08:36.421257: step 3922, loss 0.105503, acc 0.96875, learning_rate 0.000364648\n","2023-06-27T18:08:36.628027: step 3923, loss 0.0594731, acc 0.96875, learning_rate 0.000364466\n","2023-06-27T18:08:36.836755: step 3924, loss 0.065475, acc 1, learning_rate 0.000364285\n","2023-06-27T18:08:37.022953: step 3925, loss 0.210458, acc 0.90625, learning_rate 0.000364104\n","2023-06-27T18:08:37.254131: step 3926, loss 0.051333, acc 1, learning_rate 0.000363923\n","2023-06-27T18:08:37.446451: step 3927, loss 0.0178983, acc 1, learning_rate 0.000363742\n","2023-06-27T18:08:37.638321: step 3928, loss 0.0706593, acc 0.96875, learning_rate 0.000363561\n","2023-06-27T18:08:37.818028: step 3929, loss 0.124528, acc 0.9375, learning_rate 0.00036338\n","2023-06-27T18:08:38.001431: step 3930, loss 0.041031, acc 0.96875, learning_rate 0.000363199\n","2023-06-27T18:08:38.186808: step 3931, loss 0.0886214, acc 0.96875, learning_rate 0.000363019\n","2023-06-27T18:08:38.392046: step 3932, loss 0.0613445, acc 0.96875, learning_rate 0.000362839\n","2023-06-27T18:08:38.577851: step 3933, loss 0.0580129, acc 0.96875, learning_rate 0.000362658\n","2023-06-27T18:08:38.786413: step 3934, loss 0.0377156, acc 1, learning_rate 0.000362478\n","2023-06-27T18:08:38.954665: step 3935, loss 0.0512454, acc 0.96875, learning_rate 0.000362298\n","2023-06-27T18:08:39.143425: step 3936, loss 0.0643809, acc 0.96875, learning_rate 0.000362118\n","2023-06-27T18:08:39.341888: step 3937, loss 0.224943, acc 0.90625, learning_rate 0.000361939\n","2023-06-27T18:08:39.536980: step 3938, loss 0.219541, acc 0.9375, learning_rate 0.000361759\n","2023-06-27T18:08:39.742464: step 3939, loss 0.0161032, acc 1, learning_rate 0.00036158\n","2023-06-27T18:08:39.938222: step 3940, loss 0.134278, acc 0.96875, learning_rate 0.0003614\n","2023-06-27T18:08:40.143312: step 3941, loss 0.0530648, acc 0.96875, learning_rate 0.000361221\n","2023-06-27T18:08:40.349327: step 3942, loss 0.196227, acc 0.9375, learning_rate 0.000361042\n","2023-06-27T18:08:40.541191: step 3943, loss 0.0706867, acc 0.96875, learning_rate 0.000360863\n","2023-06-27T18:08:40.684936: step 3944, loss 0.00499078, acc 1, learning_rate 0.000360684\n","2023-06-27T18:08:40.810231: step 3945, loss 0.0783549, acc 1, learning_rate 0.000360505\n","2023-06-27T18:08:40.936767: step 3946, loss 0.0934808, acc 0.96875, learning_rate 0.000360326\n","2023-06-27T18:08:41.052715: step 3947, loss 0.0716125, acc 0.96875, learning_rate 0.000360148\n","2023-06-27T18:08:41.173783: step 3948, loss 0.0457627, acc 0.96875, learning_rate 0.00035997\n","2023-06-27T18:08:41.302135: step 3949, loss 0.022493, acc 1, learning_rate 0.000359791\n","2023-06-27T18:08:41.418837: step 3950, loss 0.0675594, acc 0.96875, learning_rate 0.000359613\n","2023-06-27T18:08:41.543473: step 3951, loss 0.0463593, acc 1, learning_rate 0.000359435\n","2023-06-27T18:08:41.662420: step 3952, loss 0.132982, acc 0.96875, learning_rate 0.000359257\n","2023-06-27T18:08:41.806637: step 3953, loss 0.12141, acc 0.9375, learning_rate 0.000359079\n","2023-06-27T18:08:41.924400: step 3954, loss 0.0463288, acc 1, learning_rate 0.000358902\n","2023-06-27T18:08:42.039090: step 3955, loss 0.11004, acc 0.9375, learning_rate 0.000358724\n","2023-06-27T18:08:42.165144: step 3956, loss 0.0273243, acc 1, learning_rate 0.000358547\n","2023-06-27T18:08:42.286917: step 3957, loss 0.0126807, acc 1, learning_rate 0.00035837\n","2023-06-27T18:08:42.426404: step 3958, loss 0.0121287, acc 1, learning_rate 0.000358192\n","2023-06-27T18:08:42.558375: step 3959, loss 0.0866576, acc 0.96875, learning_rate 0.000358015\n","2023-06-27T18:08:42.676099: step 3960, loss 0.0851115, acc 0.9375, learning_rate 0.000357838\n","2023-06-27T18:08:42.830737: step 3961, loss 0.0226974, acc 1, learning_rate 0.000357662\n","2023-06-27T18:08:42.949005: step 3962, loss 0.129933, acc 0.96875, learning_rate 0.000357485\n","2023-06-27T18:08:43.065778: step 3963, loss 0.0603825, acc 0.96875, learning_rate 0.000357308\n","2023-06-27T18:08:43.187370: step 3964, loss 0.0366263, acc 1, learning_rate 0.000357132\n","2023-06-27T18:08:43.313643: step 3965, loss 0.0994838, acc 0.96875, learning_rate 0.000356956\n","2023-06-27T18:08:43.434061: step 3966, loss 0.0523835, acc 1, learning_rate 0.000356779\n","2023-06-27T18:08:43.556191: step 3967, loss 0.0844088, acc 0.9375, learning_rate 0.000356603\n","2023-06-27T18:08:43.692622: step 3968, loss 0.0157135, acc 1, learning_rate 0.000356427\n","2023-06-27T18:08:43.828737: step 3969, loss 0.0917935, acc 0.9375, learning_rate 0.000356252\n","2023-06-27T18:08:43.947257: step 3970, loss 0.0693723, acc 0.96875, learning_rate 0.000356076\n","2023-06-27T18:08:44.064836: step 3971, loss 0.0527393, acc 0.96875, learning_rate 0.0003559\n","2023-06-27T18:08:44.177997: step 3972, loss 0.131901, acc 0.9375, learning_rate 0.000355725\n","2023-06-27T18:08:44.316517: step 3973, loss 0.110732, acc 0.96875, learning_rate 0.000355549\n","2023-06-27T18:08:44.444305: step 3974, loss 0.119654, acc 0.9375, learning_rate 0.000355374\n","2023-06-27T18:08:44.582900: step 3975, loss 0.15503, acc 0.90625, learning_rate 0.000355199\n","2023-06-27T18:08:44.708673: step 3976, loss 0.028987, acc 1, learning_rate 0.000355024\n","2023-06-27T18:08:44.835524: step 3977, loss 0.0394537, acc 1, learning_rate 0.000354849\n","2023-06-27T18:08:44.970687: step 3978, loss 0.0250915, acc 1, learning_rate 0.000354674\n","2023-06-27T18:08:45.084916: step 3979, loss 0.227873, acc 0.90625, learning_rate 0.0003545\n","2023-06-27T18:08:45.205880: step 3980, loss 0.102623, acc 0.96875, learning_rate 0.000354325\n","2023-06-27T18:08:45.350230: step 3981, loss 0.0577267, acc 1, learning_rate 0.000354151\n","2023-06-27T18:08:45.478356: step 3982, loss 0.0262046, acc 1, learning_rate 0.000353977\n","2023-06-27T18:08:45.620136: step 3983, loss 0.0290653, acc 1, learning_rate 0.000353802\n","2023-06-27T18:08:45.738955: step 3984, loss 0.0281643, acc 1, learning_rate 0.000353628\n","2023-06-27T18:08:45.880116: step 3985, loss 0.012269, acc 1, learning_rate 0.000353454\n","2023-06-27T18:08:45.996492: step 3986, loss 0.163949, acc 0.9375, learning_rate 0.000353281\n","2023-06-27T18:08:46.114153: step 3987, loss 0.0915966, acc 0.96875, learning_rate 0.000353107\n","2023-06-27T18:08:46.237196: step 3988, loss 0.219239, acc 0.90625, learning_rate 0.000352933\n","2023-06-27T18:08:46.351227: step 3989, loss 0.0280547, acc 1, learning_rate 0.00035276\n","2023-06-27T18:08:46.487117: step 3990, loss 0.0836595, acc 0.96875, learning_rate 0.000352587\n","2023-06-27T18:08:46.611108: step 3991, loss 0.0413799, acc 0.96875, learning_rate 0.000352413\n","2023-06-27T18:08:46.726644: step 3992, loss 0.0357802, acc 1, learning_rate 0.00035224\n","2023-06-27T18:08:46.887067: step 3993, loss 0.0377654, acc 1, learning_rate 0.000352067\n","2023-06-27T18:08:46.995390: step 3994, loss 0.0415229, acc 1, learning_rate 0.000351895\n","2023-06-27T18:08:47.126395: step 3995, loss 0.102652, acc 0.9375, learning_rate 0.000351722\n","2023-06-27T18:08:47.262617: step 3996, loss 0.0753971, acc 0.96875, learning_rate 0.000351549\n","2023-06-27T18:08:47.376029: step 3997, loss 0.0125313, acc 1, learning_rate 0.000351377\n","2023-06-27T18:08:47.513271: step 3998, loss 0.0294386, acc 1, learning_rate 0.000351204\n","2023-06-27T18:08:47.640193: step 3999, loss 0.0738665, acc 0.96875, learning_rate 0.000351032\n","\n","Evaluation:\n","2023-06-27T18:08:48.419715: step 4000, loss 0.757011, acc 0.804031\n","\n","Saved model checkpoint to /content/gdrive/MyDrive/lightweighted-cnn/train/runs/1687888658/checkpoints/model-4000\n","\n","2023-06-27T18:08:48.628160: step 4000, loss 0.119642, acc 1, learning_rate 0.00035086\n","2023-06-27T18:08:48.764450: step 4001, loss 0.0237819, acc 1, learning_rate 0.000350688\n","2023-06-27T18:08:48.875131: step 4002, loss 0.0339097, acc 1, learning_rate 0.000350516\n","2023-06-27T18:08:49.009414: step 4003, loss 0.152376, acc 0.90625, learning_rate 0.000350344\n","2023-06-27T18:08:49.127917: step 4004, loss 0.0924618, acc 0.96875, learning_rate 0.000350173\n","2023-06-27T18:08:49.247193: step 4005, loss 0.0811312, acc 1, learning_rate 0.000350001\n","2023-06-27T18:08:49.363018: step 4006, loss 0.062584, acc 1, learning_rate 0.00034983\n","2023-06-27T18:08:49.482404: step 4007, loss 0.0765307, acc 0.9375, learning_rate 0.000349658\n","2023-06-27T18:08:49.606497: step 4008, loss 0.0132845, acc 1, learning_rate 0.000349487\n","2023-06-27T18:08:49.723124: step 4009, loss 0.0159372, acc 1, learning_rate 0.000349316\n","2023-06-27T18:08:49.846688: step 4010, loss 0.0231841, acc 1, learning_rate 0.000349145\n","2023-06-27T18:08:49.995118: step 4011, loss 0.358943, acc 0.875, learning_rate 0.000348974\n","2023-06-27T18:08:50.109583: step 4012, loss 0.123975, acc 0.9375, learning_rate 0.000348803\n","2023-06-27T18:08:50.222646: step 4013, loss 0.02864, acc 1, learning_rate 0.000348633\n","2023-06-27T18:08:50.366840: step 4014, loss 0.181871, acc 0.96875, learning_rate 0.000348462\n","2023-06-27T18:08:50.501250: step 4015, loss 0.0804187, acc 0.96875, learning_rate 0.000348292\n","2023-06-27T18:08:50.686837: step 4016, loss 0.0806098, acc 0.96875, learning_rate 0.000348122\n","2023-06-27T18:08:50.887536: step 4017, loss 0.0340956, acc 1, learning_rate 0.000347952\n","2023-06-27T18:08:51.105267: step 4018, loss 0.0340281, acc 1, learning_rate 0.000347782\n","2023-06-27T18:08:51.302567: step 4019, loss 0.00922544, acc 1, learning_rate 0.000347612\n","2023-06-27T18:08:51.496867: step 4020, loss 0.0425413, acc 0.96875, learning_rate 0.000347442\n","2023-06-27T18:08:51.684278: step 4021, loss 0.226847, acc 0.9375, learning_rate 0.000347272\n","2023-06-27T18:08:51.882094: step 4022, loss 0.00327261, acc 1, learning_rate 0.000347103\n","2023-06-27T18:08:52.079109: step 4023, loss 0.221406, acc 0.875, learning_rate 0.000346933\n","2023-06-27T18:08:52.268461: step 4024, loss 0.0308656, acc 0.96875, learning_rate 0.000346764\n","2023-06-27T18:08:52.472592: step 4025, loss 0.0108174, acc 1, learning_rate 0.000346595\n","2023-06-27T18:08:52.679178: step 4026, loss 0.0747898, acc 0.9375, learning_rate 0.000346426\n","2023-06-27T18:08:52.885671: step 4027, loss 0.0819847, acc 0.96875, learning_rate 0.000346257\n","2023-06-27T18:08:53.095494: step 4028, loss 0.0989146, acc 0.9375, learning_rate 0.000346088\n","2023-06-27T18:08:53.303605: step 4029, loss 0.0126965, acc 1, learning_rate 0.000345919\n","2023-06-27T18:08:53.521766: step 4030, loss 0.0305112, acc 1, learning_rate 0.00034575\n","2023-06-27T18:08:53.723915: step 4031, loss 0.160421, acc 0.96875, learning_rate 0.000345582\n","2023-06-27T18:08:53.944501: step 4032, loss 0.153759, acc 0.96875, learning_rate 0.000345413\n","2023-06-27T18:08:54.156311: step 4033, loss 0.0240366, acc 1, learning_rate 0.000345245\n","2023-06-27T18:08:54.341342: step 4034, loss 0.0254881, acc 1, learning_rate 0.000345077\n","2023-06-27T18:08:54.548253: step 4035, loss 0.0185278, acc 1, learning_rate 0.000344909\n","2023-06-27T18:08:54.748029: step 4036, loss 0.00943566, acc 1, learning_rate 0.000344741\n","2023-06-27T18:08:54.950746: step 4037, loss 0.0298255, acc 1, learning_rate 0.000344573\n","2023-06-27T18:08:55.154212: step 4038, loss 0.0451121, acc 1, learning_rate 0.000344405\n","2023-06-27T18:08:55.337637: step 4039, loss 0.255891, acc 0.84375, learning_rate 0.000344238\n","2023-06-27T18:08:55.619759: step 4040, loss 0.102376, acc 0.9375, learning_rate 0.00034407\n","2023-06-27T18:08:55.816275: step 4041, loss 0.0185983, acc 1, learning_rate 0.000343903\n","2023-06-27T18:08:56.007836: step 4042, loss 0.24177, acc 0.96875, learning_rate 0.000343736\n","2023-06-27T18:08:56.203092: step 4043, loss 0.0487164, acc 0.96875, learning_rate 0.000343569\n","2023-06-27T18:08:56.384714: step 4044, loss 0.0807003, acc 0.96875, learning_rate 0.000343402\n","2023-06-27T18:08:56.611462: step 4045, loss 0.0586953, acc 0.96875, learning_rate 0.000343235\n","2023-06-27T18:08:56.798620: step 4046, loss 0.0318919, acc 1, learning_rate 0.000343068\n","2023-06-27T18:08:56.984925: step 4047, loss 0.104759, acc 0.96875, learning_rate 0.000342901\n","2023-06-27T18:08:57.197278: step 4048, loss 0.0158504, acc 1, learning_rate 0.000342735\n","2023-06-27T18:08:57.385622: step 4049, loss 0.0720456, acc 0.96875, learning_rate 0.000342568\n","2023-06-27T18:08:57.607766: step 4050, loss 0.078167, acc 0.96875, learning_rate 0.000342402\n","2023-06-27T18:08:57.812726: step 4051, loss 0.0258135, acc 1, learning_rate 0.000342236\n","2023-06-27T18:08:57.992945: step 4052, loss 0.0558492, acc 0.96875, learning_rate 0.000342069\n","2023-06-27T18:08:58.194948: step 4053, loss 0.0326022, acc 1, learning_rate 0.000341904\n","2023-06-27T18:08:58.399362: step 4054, loss 0.223254, acc 0.9375, learning_rate 0.000341738\n","2023-06-27T18:08:58.611904: step 4055, loss 0.0724511, acc 0.96875, learning_rate 0.000341572\n","2023-06-27T18:08:58.821116: step 4056, loss 0.0397391, acc 1, learning_rate 0.000341406\n","2023-06-27T18:08:59.023218: step 4057, loss 0.175094, acc 0.9375, learning_rate 0.000341241\n","2023-06-27T18:08:59.225151: step 4058, loss 0.010888, acc 1, learning_rate 0.000341075\n","2023-06-27T18:08:59.414675: step 4059, loss 0.0181479, acc 1, learning_rate 0.00034091\n","2023-06-27T18:08:59.602038: step 4060, loss 0.0971663, acc 0.96875, learning_rate 0.000340745\n","2023-06-27T18:08:59.810714: step 4061, loss 0.113967, acc 0.9375, learning_rate 0.00034058\n","2023-06-27T18:08:59.998533: step 4062, loss 0.126486, acc 0.9375, learning_rate 0.000340415\n","2023-06-27T18:09:00.209742: step 4063, loss 0.088452, acc 0.9375, learning_rate 0.00034025\n","2023-06-27T18:09:00.398821: step 4064, loss 0.0371498, acc 1, learning_rate 0.000340085\n","2023-06-27T18:09:00.588772: step 4065, loss 0.0705147, acc 0.96875, learning_rate 0.00033992\n","2023-06-27T18:09:00.803345: step 4066, loss 0.0538364, acc 0.96875, learning_rate 0.000339756\n","2023-06-27T18:09:01.004246: step 4067, loss 0.0648476, acc 0.96875, learning_rate 0.000339592\n","2023-06-27T18:09:01.222490: step 4068, loss 0.130547, acc 0.90625, learning_rate 0.000339427\n","2023-06-27T18:09:01.360295: step 4069, loss 0.0189271, acc 1, learning_rate 0.000339263\n","2023-06-27T18:09:01.502557: step 4070, loss 0.17466, acc 0.90625, learning_rate 0.000339099\n","2023-06-27T18:09:01.637126: step 4071, loss 0.165426, acc 0.9375, learning_rate 0.000338935\n","2023-06-27T18:09:01.755705: step 4072, loss 0.0393342, acc 1, learning_rate 0.000338771\n","2023-06-27T18:09:01.885883: step 4073, loss 0.0529106, acc 0.96875, learning_rate 0.000338607\n","2023-06-27T18:09:02.010094: step 4074, loss 0.0214755, acc 1, learning_rate 0.000338444\n","2023-06-27T18:09:02.124852: step 4075, loss 0.0236868, acc 1, learning_rate 0.00033828\n","2023-06-27T18:09:02.256574: step 4076, loss 0.0651516, acc 0.96875, learning_rate 0.000338117\n","2023-06-27T18:09:02.376835: step 4077, loss 0.0119405, acc 1, learning_rate 0.000337954\n","2023-06-27T18:09:02.524620: step 4078, loss 0.0730799, acc 0.96875, learning_rate 0.00033779\n","2023-06-27T18:09:02.642177: step 4079, loss 0.0735815, acc 0.96875, learning_rate 0.000337627\n","2023-06-27T18:09:02.761142: step 4080, loss 0.0175032, acc 1, learning_rate 0.000337464\n","2023-06-27T18:09:02.888682: step 4081, loss 0.156911, acc 0.9375, learning_rate 0.000337302\n","2023-06-27T18:09:03.012808: step 4082, loss 0.122651, acc 0.96875, learning_rate 0.000337139\n","2023-06-27T18:09:03.123518: step 4083, loss 0.0360371, acc 1, learning_rate 0.000336976\n","2023-06-27T18:09:03.239844: step 4084, loss 0.0992335, acc 0.96875, learning_rate 0.000336814\n","2023-06-27T18:09:03.367149: step 4085, loss 0.029733, acc 1, learning_rate 0.000336651\n","2023-06-27T18:09:03.499340: step 4086, loss 0.0405008, acc 0.96875, learning_rate 0.000336489\n","2023-06-27T18:09:03.604249: step 4087, loss 0.0164253, acc 1, learning_rate 0.000336327\n","2023-06-27T18:09:03.725127: step 4088, loss 0.0150997, acc 1, learning_rate 0.000336165\n","2023-06-27T18:09:03.844951: step 4089, loss 0.0189685, acc 1, learning_rate 0.000336003\n","2023-06-27T18:09:03.979999: step 4090, loss 0.161754, acc 0.96875, learning_rate 0.000335841\n","2023-06-27T18:09:04.110178: step 4091, loss 0.194914, acc 0.90625, learning_rate 0.000335679\n","2023-06-27T18:09:04.250604: step 4092, loss 0.0125231, acc 1, learning_rate 0.000335518\n","2023-06-27T18:09:04.381696: step 4093, loss 0.00287202, acc 1, learning_rate 0.000335356\n","2023-06-27T18:09:04.513731: step 4094, loss 0.0748907, acc 0.96875, learning_rate 0.000335195\n","2023-06-27T18:09:04.636298: step 4095, loss 0.131931, acc 0.96875, learning_rate 0.000335034\n","2023-06-27T18:09:04.754058: step 4096, loss 0.0674477, acc 0.96875, learning_rate 0.000334872\n","2023-06-27T18:09:04.888295: step 4097, loss 0.0756354, acc 0.96875, learning_rate 0.000334711\n","2023-06-27T18:09:05.015670: step 4098, loss 0.169509, acc 0.9375, learning_rate 0.00033455\n","2023-06-27T18:09:05.134840: step 4099, loss 0.172809, acc 0.9375, learning_rate 0.00033439\n","\n","Evaluation:\n","2023-06-27T18:09:05.904990: step 4100, loss 0.757294, acc 0.801244\n","\n","Saved model checkpoint to /content/gdrive/MyDrive/lightweighted-cnn/train/runs/1687888658/checkpoints/model-4100\n","\n","2023-06-27T18:09:06.120093: step 4100, loss 0.208104, acc 0.90625, learning_rate 0.000334229\n","2023-06-27T18:09:06.236975: step 4101, loss 0.225131, acc 0.9375, learning_rate 0.000334068\n","2023-06-27T18:09:06.355754: step 4102, loss 0.080266, acc 1, learning_rate 0.000333908\n","2023-06-27T18:09:06.497317: step 4103, loss 0.00881195, acc 1, learning_rate 0.000333747\n","2023-06-27T18:09:06.633127: step 4104, loss 0.0796385, acc 0.96875, learning_rate 0.000333587\n","2023-06-27T18:09:06.762078: step 4105, loss 0.0222718, acc 1, learning_rate 0.000333427\n","2023-06-27T18:09:06.886625: step 4106, loss 0.0392776, acc 0.96875, learning_rate 0.000333267\n","2023-06-27T18:09:07.007969: step 4107, loss 0.016915, acc 1, learning_rate 0.000333107\n","2023-06-27T18:09:07.125390: step 4108, loss 0.0645823, acc 0.96875, learning_rate 0.000332947\n","2023-06-27T18:09:07.250838: step 4109, loss 0.0334898, acc 1, learning_rate 0.000332787\n","2023-06-27T18:09:07.372337: step 4110, loss 0.0790084, acc 0.96875, learning_rate 0.000332628\n","2023-06-27T18:09:07.486372: step 4111, loss 0.0960252, acc 0.96875, learning_rate 0.000332468\n","2023-06-27T18:09:07.622675: step 4112, loss 0.0321402, acc 1, learning_rate 0.000332309\n","2023-06-27T18:09:07.748805: step 4113, loss 0.0991535, acc 0.96875, learning_rate 0.000332149\n","2023-06-27T18:09:07.872178: step 4114, loss 0.0413721, acc 1, learning_rate 0.00033199\n","2023-06-27T18:09:08.001000: step 4115, loss 0.104958, acc 0.96875, learning_rate 0.000331831\n","2023-06-27T18:09:08.128922: step 4116, loss 0.0194715, acc 1, learning_rate 0.000331672\n","2023-06-27T18:09:08.270784: step 4117, loss 0.00324798, acc 1, learning_rate 0.000331513\n","2023-06-27T18:09:08.401816: step 4118, loss 0.158249, acc 0.9375, learning_rate 0.000331355\n","2023-06-27T18:09:08.537643: step 4119, loss 0.0143671, acc 1, learning_rate 0.000331196\n","2023-06-27T18:09:08.665178: step 4120, loss 0.133647, acc 0.9375, learning_rate 0.000331037\n","2023-06-27T18:09:08.777633: step 4121, loss 0.205231, acc 0.9375, learning_rate 0.000330879\n","2023-06-27T18:09:08.898607: step 4122, loss 0.146989, acc 0.90625, learning_rate 0.000330721\n","2023-06-27T18:09:09.026622: step 4123, loss 0.012063, acc 1, learning_rate 0.000330562\n","2023-06-27T18:09:09.141831: step 4124, loss 0.00617932, acc 1, learning_rate 0.000330404\n","2023-06-27T18:09:09.262543: step 4125, loss 0.0244702, acc 1, learning_rate 0.000330246\n","2023-06-27T18:09:09.377989: step 4126, loss 0.202989, acc 0.9375, learning_rate 0.000330088\n","2023-06-27T18:09:09.502362: step 4127, loss 0.151665, acc 0.9375, learning_rate 0.000329931\n","2023-06-27T18:09:09.645340: step 4128, loss 0.0164369, acc 1, learning_rate 0.000329773\n","2023-06-27T18:09:09.777871: step 4129, loss 0.0331816, acc 1, learning_rate 0.000329615\n","2023-06-27T18:09:09.895453: step 4130, loss 0.0112311, acc 1, learning_rate 0.000329458\n","2023-06-27T18:09:10.014862: step 4131, loss 0.0632925, acc 0.96875, learning_rate 0.000329301\n","2023-06-27T18:09:10.137153: step 4132, loss 0.0969023, acc 0.96875, learning_rate 0.000329143\n","2023-06-27T18:09:10.253975: step 4133, loss 0.021568, acc 1, learning_rate 0.000328986\n","2023-06-27T18:09:10.379672: step 4134, loss 0.0502225, acc 0.96875, learning_rate 0.000328829\n","2023-06-27T18:09:10.500198: step 4135, loss 0.0147794, acc 1, learning_rate 0.000328672\n","2023-06-27T18:09:10.617703: step 4136, loss 0.0897374, acc 0.9375, learning_rate 0.000328516\n","2023-06-27T18:09:10.740672: step 4137, loss 0.103142, acc 0.9375, learning_rate 0.000328359\n","2023-06-27T18:09:10.858616: step 4138, loss 0.0881543, acc 0.96875, learning_rate 0.000328202\n","2023-06-27T18:09:10.974307: step 4139, loss 0.0553534, acc 0.96875, learning_rate 0.000328046\n","2023-06-27T18:09:11.095321: step 4140, loss 0.0108483, acc 1, learning_rate 0.000327889\n","2023-06-27T18:09:11.221577: step 4141, loss 0.0211716, acc 1, learning_rate 0.000327733\n","2023-06-27T18:09:11.389227: step 4142, loss 0.0953329, acc 1, learning_rate 0.000327577\n","2023-06-27T18:09:11.588671: step 4143, loss 0.158704, acc 0.9375, learning_rate 0.000327421\n","2023-06-27T18:09:11.766257: step 4144, loss 0.110883, acc 0.96875, learning_rate 0.000327265\n","2023-06-27T18:09:11.967520: step 4145, loss 0.0228585, acc 1, learning_rate 0.000327109\n","2023-06-27T18:09:12.168218: step 4146, loss 0.0379417, acc 0.96875, learning_rate 0.000326953\n","2023-06-27T18:09:12.393919: step 4147, loss 0.0155758, acc 1, learning_rate 0.000326798\n","2023-06-27T18:09:12.601034: step 4148, loss 0.105835, acc 0.9375, learning_rate 0.000326642\n","2023-06-27T18:09:12.825875: step 4149, loss 0.0310748, acc 1, learning_rate 0.000326487\n","2023-06-27T18:09:13.049424: step 4150, loss 0.0127535, acc 1, learning_rate 0.000326332\n","2023-06-27T18:09:13.261743: step 4151, loss 0.0132443, acc 1, learning_rate 0.000326176\n","2023-06-27T18:09:13.484416: step 4152, loss 0.06224, acc 0.96875, learning_rate 0.000326021\n","2023-06-27T18:09:13.695969: step 4153, loss 0.0386612, acc 0.96875, learning_rate 0.000325866\n","2023-06-27T18:09:13.910890: step 4154, loss 0.0144783, acc 1, learning_rate 0.000325711\n","2023-06-27T18:09:14.107690: step 4155, loss 0.0539612, acc 1, learning_rate 0.000325557\n","2023-06-27T18:09:14.311186: step 4156, loss 0.0802052, acc 0.96875, learning_rate 0.000325402\n","2023-06-27T18:09:14.521408: step 4157, loss 0.00961419, acc 1, learning_rate 0.000325247\n","2023-06-27T18:09:14.719139: step 4158, loss 0.111552, acc 0.96875, learning_rate 0.000325093\n","2023-06-27T18:09:14.909736: step 4159, loss 0.0993116, acc 0.9375, learning_rate 0.000324939\n","2023-06-27T18:09:15.085481: step 4160, loss 0.0671426, acc 0.96875, learning_rate 0.000324784\n","2023-06-27T18:09:15.278008: step 4161, loss 0.0445779, acc 1, learning_rate 0.00032463\n","2023-06-27T18:09:15.524403: step 4162, loss 0.0375195, acc 1, learning_rate 0.000324476\n","2023-06-27T18:09:15.715043: step 4163, loss 0.0673396, acc 0.96875, learning_rate 0.000324322\n","2023-06-27T18:09:15.922962: step 4164, loss 0.0398552, acc 0.96875, learning_rate 0.000324168\n","2023-06-27T18:09:16.107373: step 4165, loss 0.18768, acc 0.9375, learning_rate 0.000324015\n","2023-06-27T18:09:16.309613: step 4166, loss 0.0592234, acc 1, learning_rate 0.000323861\n","2023-06-27T18:09:16.506265: step 4167, loss 0.0214683, acc 1, learning_rate 0.000323708\n","2023-06-27T18:09:16.706290: step 4168, loss 0.106433, acc 0.9375, learning_rate 0.000323554\n","2023-06-27T18:09:16.902952: step 4169, loss 0.0860453, acc 0.96875, learning_rate 0.000323401\n","2023-06-27T18:09:17.091467: step 4170, loss 0.083785, acc 0.96875, learning_rate 0.000323248\n","2023-06-27T18:09:17.269226: step 4171, loss 0.0550428, acc 1, learning_rate 0.000323095\n","2023-06-27T18:09:17.440281: step 4172, loss 0.0549094, acc 0.96875, learning_rate 0.000322942\n","2023-06-27T18:09:17.621690: step 4173, loss 0.0501006, acc 1, learning_rate 0.000322789\n","2023-06-27T18:09:17.816389: step 4174, loss 0.0280911, acc 1, learning_rate 0.000322636\n","2023-06-27T18:09:18.025517: step 4175, loss 0.0601474, acc 1, learning_rate 0.000322483\n","2023-06-27T18:09:18.240768: step 4176, loss 0.127697, acc 0.9375, learning_rate 0.000322331\n","2023-06-27T18:09:18.446635: step 4177, loss 0.0767147, acc 0.96875, learning_rate 0.000322178\n","2023-06-27T18:09:18.656644: step 4178, loss 0.0180084, acc 1, learning_rate 0.000322026\n","2023-06-27T18:09:18.859540: step 4179, loss 0.03265, acc 1, learning_rate 0.000321874\n","2023-06-27T18:09:19.059977: step 4180, loss 0.21301, acc 0.875, learning_rate 0.000321721\n","2023-06-27T18:09:19.268292: step 4181, loss 0.0216124, acc 1, learning_rate 0.000321569\n","2023-06-27T18:09:19.461605: step 4182, loss 0.0258507, acc 1, learning_rate 0.000321418\n","2023-06-27T18:09:19.665791: step 4183, loss 0.066793, acc 0.96875, learning_rate 0.000321266\n","2023-06-27T18:09:19.859069: step 4184, loss 0.0254959, acc 1, learning_rate 0.000321114\n","2023-06-27T18:09:20.038208: step 4185, loss 0.0545156, acc 1, learning_rate 0.000320962\n","2023-06-27T18:09:20.238077: step 4186, loss 0.0433723, acc 1, learning_rate 0.000320811\n","2023-06-27T18:09:20.415009: step 4187, loss 0.0839015, acc 0.96875, learning_rate 0.000320659\n","2023-06-27T18:09:20.627813: step 4188, loss 0.0601381, acc 1, learning_rate 0.000320508\n","2023-06-27T18:09:20.848201: step 4189, loss 0.0756228, acc 0.96875, learning_rate 0.000320357\n","2023-06-27T18:09:21.053414: step 4190, loss 0.145435, acc 0.90625, learning_rate 0.000320206\n","2023-06-27T18:09:21.240950: step 4191, loss 0.0224409, acc 1, learning_rate 0.000320055\n","2023-06-27T18:09:21.444543: step 4192, loss 0.0715048, acc 0.96875, learning_rate 0.000319904\n","2023-06-27T18:09:21.636461: step 4193, loss 0.0791228, acc 1, learning_rate 0.000319753\n","2023-06-27T18:09:21.831630: step 4194, loss 0.0541517, acc 1, learning_rate 0.000319602\n","2023-06-27T18:09:22.038468: step 4195, loss 0.0454874, acc 1, learning_rate 0.000319452\n","2023-06-27T18:09:22.175873: step 4196, loss 0.10458, acc 1, learning_rate 0.000319301\n","2023-06-27T18:09:22.291996: step 4197, loss 0.04195, acc 1, learning_rate 0.000319151\n","2023-06-27T18:09:22.411769: step 4198, loss 0.0509433, acc 0.96875, learning_rate 0.000319001\n","2023-06-27T18:09:22.519731: step 4199, loss 0.0364647, acc 1, learning_rate 0.000318851\n","\n","Evaluation:\n","2023-06-27T18:09:23.256473: step 4200, loss 0.772319, acc 0.799528\n","\n","Saved model checkpoint to /content/gdrive/MyDrive/lightweighted-cnn/train/runs/1687888658/checkpoints/model-4200\n","\n","2023-06-27T18:09:23.479304: step 4200, loss 0.0899655, acc 0.96875, learning_rate 0.0003187\n","2023-06-27T18:09:23.615769: step 4201, loss 0.214722, acc 0.9375, learning_rate 0.00031855\n","2023-06-27T18:09:23.736577: step 4202, loss 0.0231579, acc 1, learning_rate 0.000318401\n","2023-06-27T18:09:23.867585: step 4203, loss 0.019029, acc 1, learning_rate 0.000318251\n","2023-06-27T18:09:23.995223: step 4204, loss 0.0163111, acc 1, learning_rate 0.000318101\n","2023-06-27T18:09:24.103092: step 4205, loss 0.040773, acc 0.96875, learning_rate 0.000317952\n","2023-06-27T18:09:24.237433: step 4206, loss 0.0432578, acc 0.96875, learning_rate 0.000317802\n","2023-06-27T18:09:24.366414: step 4207, loss 0.0745867, acc 0.9375, learning_rate 0.000317653\n","2023-06-27T18:09:24.494587: step 4208, loss 0.110818, acc 0.9375, learning_rate 0.000317504\n","2023-06-27T18:09:24.619767: step 4209, loss 0.0239248, acc 1, learning_rate 0.000317354\n","2023-06-27T18:09:24.756915: step 4210, loss 0.0865738, acc 0.96875, learning_rate 0.000317205\n","2023-06-27T18:09:24.871393: step 4211, loss 0.110237, acc 0.96875, learning_rate 0.000317056\n","2023-06-27T18:09:24.990927: step 4212, loss 0.0520026, acc 1, learning_rate 0.000316908\n","2023-06-27T18:09:25.099375: step 4213, loss 0.0118703, acc 1, learning_rate 0.000316759\n","2023-06-27T18:09:25.229244: step 4214, loss 0.0129855, acc 1, learning_rate 0.00031661\n","2023-06-27T18:09:25.361849: step 4215, loss 0.0452877, acc 0.96875, learning_rate 0.000316462\n","2023-06-27T18:09:25.505125: step 4216, loss 0.0121127, acc 1, learning_rate 0.000316313\n","2023-06-27T18:09:25.635726: step 4217, loss 0.104951, acc 0.96875, learning_rate 0.000316165\n","2023-06-27T18:09:25.756889: step 4218, loss 0.0200684, acc 1, learning_rate 0.000316017\n","2023-06-27T18:09:25.871009: step 4219, loss 0.153883, acc 0.96875, learning_rate 0.000315869\n","2023-06-27T18:09:26.001645: step 4220, loss 0.076957, acc 0.96875, learning_rate 0.000315721\n","2023-06-27T18:09:26.125476: step 4221, loss 0.0293215, acc 1, learning_rate 0.000315573\n","2023-06-27T18:09:26.256494: step 4222, loss 0.0289919, acc 1, learning_rate 0.000315425\n","2023-06-27T18:09:26.377287: step 4223, loss 0.0263711, acc 1, learning_rate 0.000315277\n","2023-06-27T18:09:26.494416: step 4224, loss 0.0444642, acc 1, learning_rate 0.000315129\n","2023-06-27T18:09:26.608322: step 4225, loss 0.0340902, acc 1, learning_rate 0.000314982\n","2023-06-27T18:09:26.738135: step 4226, loss 0.103006, acc 0.96875, learning_rate 0.000314834\n","2023-06-27T18:09:26.871396: step 4227, loss 0.0135742, acc 1, learning_rate 0.000314687\n","2023-06-27T18:09:27.007751: step 4228, loss 0.0198316, acc 1, learning_rate 0.00031454\n","2023-06-27T18:09:27.130214: step 4229, loss 0.0486983, acc 1, learning_rate 0.000314393\n","2023-06-27T18:09:27.262914: step 4230, loss 0.0793481, acc 0.9375, learning_rate 0.000314246\n","2023-06-27T18:09:27.387650: step 4231, loss 0.0881102, acc 1, learning_rate 0.000314099\n","2023-06-27T18:09:27.494221: step 4232, loss 0.0282205, acc 1, learning_rate 0.000313952\n","2023-06-27T18:09:27.623423: step 4233, loss 0.0465565, acc 1, learning_rate 0.000313805\n","2023-06-27T18:09:27.739072: step 4234, loss 0.0503257, acc 1, learning_rate 0.000313659\n","2023-06-27T18:09:27.857060: step 4235, loss 0.068179, acc 1, learning_rate 0.000313512\n","2023-06-27T18:09:27.981536: step 4236, loss 0.00281483, acc 1, learning_rate 0.000313366\n","2023-06-27T18:09:28.096342: step 4237, loss 0.228818, acc 0.875, learning_rate 0.00031322\n","2023-06-27T18:09:28.212206: step 4238, loss 0.0969188, acc 0.96875, learning_rate 0.000313073\n","2023-06-27T18:09:28.355043: step 4239, loss 0.0236826, acc 1, learning_rate 0.000312927\n","2023-06-27T18:09:28.482749: step 4240, loss 0.0274452, acc 1, learning_rate 0.000312781\n","2023-06-27T18:09:28.607779: step 4241, loss 0.0597093, acc 0.96875, learning_rate 0.000312635\n","2023-06-27T18:09:28.724949: step 4242, loss 0.0603939, acc 1, learning_rate 0.00031249\n","2023-06-27T18:09:28.839760: step 4243, loss 0.0613082, acc 0.96875, learning_rate 0.000312344\n","2023-06-27T18:09:28.968050: step 4244, loss 0.120213, acc 0.90625, learning_rate 0.000312198\n","2023-06-27T18:09:29.084960: step 4245, loss 0.0772472, acc 0.9375, learning_rate 0.000312053\n","2023-06-27T18:09:29.205270: step 4246, loss 0.0195852, acc 1, learning_rate 0.000311907\n","2023-06-27T18:09:29.333030: step 4247, loss 0.0283807, acc 1, learning_rate 0.000311762\n","2023-06-27T18:09:29.447197: step 4248, loss 0.0554171, acc 1, learning_rate 0.000311617\n","2023-06-27T18:09:29.576306: step 4249, loss 0.0350828, acc 1, learning_rate 0.000311472\n","2023-06-27T18:09:29.698419: step 4250, loss 0.0331853, acc 1, learning_rate 0.000311327\n","2023-06-27T18:09:29.808460: step 4251, loss 0.0515556, acc 1, learning_rate 0.000311182\n","2023-06-27T18:09:29.926486: step 4252, loss 0.0247672, acc 1, learning_rate 0.000311037\n","2023-06-27T18:09:30.040858: step 4253, loss 0.0361889, acc 1, learning_rate 0.000310892\n","2023-06-27T18:09:30.162934: step 4254, loss 0.196496, acc 0.90625, learning_rate 0.000310748\n","2023-06-27T18:09:30.272436: step 4255, loss 0.0129498, acc 1, learning_rate 0.000310603\n","2023-06-27T18:09:30.416853: step 4256, loss 0.133009, acc 0.9375, learning_rate 0.000310459\n","2023-06-27T18:09:30.562035: step 4257, loss 0.0302465, acc 1, learning_rate 0.000310314\n","2023-06-27T18:09:30.674601: step 4258, loss 0.0769639, acc 1, learning_rate 0.00031017\n","2023-06-27T18:09:30.798013: step 4259, loss 0.133104, acc 0.96875, learning_rate 0.000310026\n","2023-06-27T18:09:30.906704: step 4260, loss 0.0206672, acc 1, learning_rate 0.000309882\n","2023-06-27T18:09:31.023844: step 4261, loss 0.106127, acc 0.9375, learning_rate 0.000309738\n","2023-06-27T18:09:31.138234: step 4262, loss 0.0171151, acc 1, learning_rate 0.000309594\n","2023-06-27T18:09:31.269677: step 4263, loss 0.0181713, acc 1, learning_rate 0.000309451\n","2023-06-27T18:09:31.401681: step 4264, loss 0.0830524, acc 0.96875, learning_rate 0.000309307\n","2023-06-27T18:09:31.511030: step 4265, loss 0.0131231, acc 1, learning_rate 0.000309163\n","2023-06-27T18:09:31.638141: step 4266, loss 0.124266, acc 0.96875, learning_rate 0.00030902\n","2023-06-27T18:09:31.755216: step 4267, loss 0.174208, acc 0.90625, learning_rate 0.000308877\n","2023-06-27T18:09:31.898387: step 4268, loss 0.00310799, acc 1, learning_rate 0.000308733\n","2023-06-27T18:09:32.020537: step 4269, loss 0.022734, acc 1, learning_rate 0.00030859\n","2023-06-27T18:09:32.202720: step 4270, loss 0.0446653, acc 1, learning_rate 0.000308447\n","2023-06-27T18:09:32.424815: step 4271, loss 0.146266, acc 0.9375, learning_rate 0.000308304\n","2023-06-27T18:09:32.636411: step 4272, loss 0.0573068, acc 0.96875, learning_rate 0.000308161\n","2023-06-27T18:09:32.837411: step 4273, loss 0.0525746, acc 0.96875, learning_rate 0.000308019\n","2023-06-27T18:09:33.047701: step 4274, loss 0.00435542, acc 1, learning_rate 0.000307876\n","2023-06-27T18:09:33.258672: step 4275, loss 0.0933424, acc 0.96875, learning_rate 0.000307733\n","2023-06-27T18:09:33.481016: step 4276, loss 0.095675, acc 0.9375, learning_rate 0.000307591\n","2023-06-27T18:09:33.684505: step 4277, loss 0.0551186, acc 1, learning_rate 0.000307449\n","2023-06-27T18:09:33.901986: step 4278, loss 0.110847, acc 0.9375, learning_rate 0.000307306\n","2023-06-27T18:09:34.083199: step 4279, loss 0.0203956, acc 1, learning_rate 0.000307164\n","2023-06-27T18:09:34.305008: step 4280, loss 0.0671339, acc 0.96875, learning_rate 0.000307022\n","2023-06-27T18:09:34.520013: step 4281, loss 0.0699067, acc 0.96875, learning_rate 0.00030688\n","2023-06-27T18:09:34.724974: step 4282, loss 0.00327445, acc 1, learning_rate 0.000306738\n","2023-06-27T18:09:34.911353: step 4283, loss 0.0319285, acc 1, learning_rate 0.000306597\n","2023-06-27T18:09:35.095145: step 4284, loss 0.0290877, acc 1, learning_rate 0.000306455\n","2023-06-27T18:09:35.283074: step 4285, loss 0.0389456, acc 0.96875, learning_rate 0.000306313\n","2023-06-27T18:09:35.504327: step 4286, loss 0.0205434, acc 1, learning_rate 0.000306172\n","2023-06-27T18:09:35.705970: step 4287, loss 0.0947217, acc 0.9375, learning_rate 0.000306031\n","2023-06-27T18:09:35.898423: step 4288, loss 0.0611061, acc 1, learning_rate 0.000305889\n","2023-06-27T18:09:36.086595: step 4289, loss 0.0833226, acc 0.96875, learning_rate 0.000305748\n","2023-06-27T18:09:36.266002: step 4290, loss 0.139728, acc 0.90625, learning_rate 0.000305607\n","2023-06-27T18:09:36.461836: step 4291, loss 0.0361052, acc 1, learning_rate 0.000305466\n","2023-06-27T18:09:36.663498: step 4292, loss 0.114121, acc 0.9375, learning_rate 0.000305325\n","2023-06-27T18:09:36.857254: step 4293, loss 0.228907, acc 0.875, learning_rate 0.000305184\n","2023-06-27T18:09:37.056777: step 4294, loss 0.0179896, acc 1, learning_rate 0.000305044\n","2023-06-27T18:09:37.237613: step 4295, loss 0.0738752, acc 0.96875, learning_rate 0.000304903\n","2023-06-27T18:09:37.431267: step 4296, loss 0.0181183, acc 1, learning_rate 0.000304763\n","2023-06-27T18:09:37.617573: step 4297, loss 0.099126, acc 0.96875, learning_rate 0.000304622\n","2023-06-27T18:09:37.810567: step 4298, loss 0.165193, acc 0.90625, learning_rate 0.000304482\n","2023-06-27T18:09:38.008793: step 4299, loss 0.081259, acc 1, learning_rate 0.000304342\n","\n","Evaluation:\n","2023-06-27T18:09:39.352177: step 4300, loss 0.770031, acc 0.802101\n","\n","Saved model checkpoint to /content/gdrive/MyDrive/lightweighted-cnn/train/runs/1687888658/checkpoints/model-4300\n","\n","2023-06-27T18:09:39.707728: step 4300, loss 0.09553, acc 0.9375, learning_rate 0.000304201\n","2023-06-27T18:09:39.884548: step 4301, loss 0.0209973, acc 1, learning_rate 0.000304061\n","2023-06-27T18:09:40.068114: step 4302, loss 0.0857499, acc 0.96875, learning_rate 0.000303921\n","2023-06-27T18:09:40.279665: step 4303, loss 0.0422548, acc 1, learning_rate 0.000303782\n","2023-06-27T18:09:40.458498: step 4304, loss 0.0618585, acc 0.96875, learning_rate 0.000303642\n","2023-06-27T18:09:40.658445: step 4305, loss 0.0425496, acc 0.96875, learning_rate 0.000303502\n","2023-06-27T18:09:40.840495: step 4306, loss 0.00671676, acc 1, learning_rate 0.000303363\n","2023-06-27T18:09:41.035423: step 4307, loss 0.0350892, acc 1, learning_rate 0.000303223\n","2023-06-27T18:09:41.222139: step 4308, loss 0.0777085, acc 0.96875, learning_rate 0.000303084\n","2023-06-27T18:09:41.403681: step 4309, loss 0.0305174, acc 0.96875, learning_rate 0.000302945\n","2023-06-27T18:09:41.600595: step 4310, loss 0.0819652, acc 0.96875, learning_rate 0.000302805\n","2023-06-27T18:09:41.793984: step 4311, loss 0.0685214, acc 0.96875, learning_rate 0.000302666\n","2023-06-27T18:09:41.987546: step 4312, loss 0.118261, acc 0.96875, learning_rate 0.000302527\n","2023-06-27T18:09:42.181533: step 4313, loss 0.104717, acc 0.96875, learning_rate 0.000302389\n","2023-06-27T18:09:42.382487: step 4314, loss 0.148708, acc 0.9375, learning_rate 0.00030225\n","2023-06-27T18:09:42.552773: step 4315, loss 0.0163185, acc 1, learning_rate 0.000302111\n","2023-06-27T18:09:42.743585: step 4316, loss 0.0583822, acc 1, learning_rate 0.000301973\n","2023-06-27T18:09:42.943084: step 4317, loss 0.0266623, acc 1, learning_rate 0.000301834\n","2023-06-27T18:09:43.060263: step 4318, loss 0.0639041, acc 0.96875, learning_rate 0.000301696\n","2023-06-27T18:09:43.174384: step 4319, loss 0.0457894, acc 1, learning_rate 0.000301557\n","2023-06-27T18:09:43.298787: step 4320, loss 0.0365425, acc 1, learning_rate 0.000301419\n","2023-06-27T18:09:43.423873: step 4321, loss 0.0196867, acc 1, learning_rate 0.000301281\n","2023-06-27T18:09:43.568064: step 4322, loss 0.0599479, acc 1, learning_rate 0.000301143\n","2023-06-27T18:09:43.685813: step 4323, loss 0.0340853, acc 1, learning_rate 0.000301005\n","2023-06-27T18:09:43.803142: step 4324, loss 0.126494, acc 0.96875, learning_rate 0.000300867\n","2023-06-27T18:09:43.945095: step 4325, loss 0.00850346, acc 1, learning_rate 0.000300729\n","2023-06-27T18:09:44.061285: step 4326, loss 0.140499, acc 0.96875, learning_rate 0.000300592\n","2023-06-27T18:09:44.190087: step 4327, loss 0.0128846, acc 1, learning_rate 0.000300454\n","2023-06-27T18:09:44.328598: step 4328, loss 0.034585, acc 1, learning_rate 0.000300317\n","2023-06-27T18:09:44.451966: step 4329, loss 0.0428801, acc 1, learning_rate 0.000300179\n","2023-06-27T18:09:44.570455: step 4330, loss 0.00622789, acc 1, learning_rate 0.000300042\n","2023-06-27T18:09:44.701502: step 4331, loss 0.426397, acc 0.90625, learning_rate 0.000299905\n","2023-06-27T18:09:44.820180: step 4332, loss 0.0566706, acc 0.96875, learning_rate 0.000299768\n","2023-06-27T18:09:44.944195: step 4333, loss 0.0519771, acc 0.96875, learning_rate 0.000299631\n","2023-06-27T18:09:45.062177: step 4334, loss 0.0918717, acc 0.96875, learning_rate 0.000299494\n","2023-06-27T18:09:45.180257: step 4335, loss 0.0987378, acc 0.9375, learning_rate 0.000299357\n","2023-06-27T18:09:45.319344: step 4336, loss 0.00937006, acc 1, learning_rate 0.000299221\n","2023-06-27T18:09:45.482882: step 4337, loss 0.0541144, acc 1, learning_rate 0.000299084\n","2023-06-27T18:09:45.606857: step 4338, loss 0.0199629, acc 1, learning_rate 0.000298947\n","2023-06-27T18:09:45.726385: step 4339, loss 0.0841039, acc 0.96875, learning_rate 0.000298811\n","2023-06-27T18:09:45.856490: step 4340, loss 0.0216629, acc 1, learning_rate 0.000298675\n","2023-06-27T18:09:45.985935: step 4341, loss 0.266301, acc 0.90625, learning_rate 0.000298538\n","2023-06-27T18:09:46.093147: step 4342, loss 0.0770303, acc 0.96875, learning_rate 0.000298402\n","2023-06-27T18:09:46.220060: step 4343, loss 0.0283012, acc 1, learning_rate 0.000298266\n","2023-06-27T18:09:46.339384: step 4344, loss 0.126642, acc 0.9375, learning_rate 0.00029813\n","2023-06-27T18:09:46.463318: step 4345, loss 0.0793631, acc 0.96875, learning_rate 0.000297994\n","2023-06-27T18:09:46.582879: step 4346, loss 0.010073, acc 1, learning_rate 0.000297859\n","2023-06-27T18:09:46.691221: step 4347, loss 0.113503, acc 0.96875, learning_rate 0.000297723\n","2023-06-27T18:09:46.815455: step 4348, loss 0.0801422, acc 0.96875, learning_rate 0.000297587\n","2023-06-27T18:09:46.933962: step 4349, loss 0.0924788, acc 0.9375, learning_rate 0.000297452\n","2023-06-27T18:09:47.058370: step 4350, loss 0.0886316, acc 0.96875, learning_rate 0.000297316\n","2023-06-27T18:09:47.174903: step 4351, loss 0.162942, acc 0.9375, learning_rate 0.000297181\n","2023-06-27T18:09:47.307935: step 4352, loss 0.0173485, acc 1, learning_rate 0.000297046\n","2023-06-27T18:09:47.432316: step 4353, loss 0.00917608, acc 1, learning_rate 0.000296911\n","2023-06-27T18:09:47.572093: step 4354, loss 0.0736268, acc 0.96875, learning_rate 0.000296776\n","2023-06-27T18:09:47.692062: step 4355, loss 0.0334199, acc 1, learning_rate 0.000296641\n","2023-06-27T18:09:47.811913: step 4356, loss 0.0227737, acc 1, learning_rate 0.000296506\n","2023-06-27T18:09:47.938877: step 4357, loss 0.01764, acc 1, learning_rate 0.000296371\n","2023-06-27T18:09:48.062680: step 4358, loss 0.0207164, acc 1, learning_rate 0.000296237\n","2023-06-27T18:09:48.171731: step 4359, loss 0.086364, acc 0.96875, learning_rate 0.000296102\n","2023-06-27T18:09:48.280168: step 4360, loss 0.0609869, acc 0.96875, learning_rate 0.000295968\n","2023-06-27T18:09:48.408878: step 4361, loss 0.011155, acc 1, learning_rate 0.000295833\n","2023-06-27T18:09:48.517167: step 4362, loss 0.0660158, acc 0.96875, learning_rate 0.000295699\n","2023-06-27T18:09:48.628615: step 4363, loss 0.0838408, acc 0.96875, learning_rate 0.000295565\n","2023-06-27T18:09:48.754632: step 4364, loss 0.0557745, acc 1, learning_rate 0.000295431\n","2023-06-27T18:09:48.871870: step 4365, loss 0.0125023, acc 1, learning_rate 0.000295297\n","2023-06-27T18:09:48.989023: step 4366, loss 0.0688758, acc 0.96875, learning_rate 0.000295163\n","2023-06-27T18:09:49.129881: step 4367, loss 0.0420651, acc 1, learning_rate 0.000295029\n","2023-06-27T18:09:49.251247: step 4368, loss 0.0549113, acc 0.96875, learning_rate 0.000294895\n","2023-06-27T18:09:49.360214: step 4369, loss 0.120002, acc 0.96875, learning_rate 0.000294762\n","2023-06-27T18:09:49.487329: step 4370, loss 0.118119, acc 0.9375, learning_rate 0.000294628\n","2023-06-27T18:09:49.596901: step 4371, loss 0.126284, acc 0.90625, learning_rate 0.000294494\n","2023-06-27T18:09:49.723644: step 4372, loss 0.00853771, acc 1, learning_rate 0.000294361\n","2023-06-27T18:09:49.845604: step 4373, loss 0.0207162, acc 1, learning_rate 0.000294228\n","2023-06-27T18:09:49.953191: step 4374, loss 0.0420999, acc 0.96875, learning_rate 0.000294095\n","2023-06-27T18:09:50.089011: step 4375, loss 0.0190249, acc 1, learning_rate 0.000293962\n","2023-06-27T18:09:50.197987: step 4376, loss 0.124349, acc 0.96875, learning_rate 0.000293829\n","2023-06-27T18:09:50.320384: step 4377, loss 0.0711102, acc 1, learning_rate 0.000293696\n","2023-06-27T18:09:50.446383: step 4378, loss 0.309298, acc 0.875, learning_rate 0.000293563\n","2023-06-27T18:09:50.559254: step 4379, loss 0.00841711, acc 1, learning_rate 0.00029343\n","2023-06-27T18:09:50.694545: step 4380, loss 0.0570694, acc 0.96875, learning_rate 0.000293297\n","2023-06-27T18:09:50.818018: step 4381, loss 0.0712628, acc 0.96875, learning_rate 0.000293165\n","2023-06-27T18:09:50.936995: step 4382, loss 0.00854813, acc 1, learning_rate 0.000293032\n","2023-06-27T18:09:51.059341: step 4383, loss 0.0682701, acc 0.96875, learning_rate 0.0002929\n","2023-06-27T18:09:51.184897: step 4384, loss 0.0158483, acc 1, learning_rate 0.000292768\n","2023-06-27T18:09:51.315802: step 4385, loss 0.0192273, acc 1, learning_rate 0.000292636\n","2023-06-27T18:09:51.437615: step 4386, loss 0.014479, acc 1, learning_rate 0.000292504\n","2023-06-27T18:09:51.559711: step 4387, loss 0.0203217, acc 1, learning_rate 0.000292372\n","2023-06-27T18:09:51.691130: step 4388, loss 0.0678209, acc 0.96875, learning_rate 0.00029224\n","2023-06-27T18:09:51.813793: step 4389, loss 0.112877, acc 0.96875, learning_rate 0.000292108\n","2023-06-27T18:09:51.928253: step 4390, loss 0.0303082, acc 1, learning_rate 0.000291976\n","2023-06-27T18:09:52.052149: step 4391, loss 0.00666295, acc 1, learning_rate 0.000291844\n","2023-06-27T18:09:52.193089: step 4392, loss 0.0491779, acc 0.96875, learning_rate 0.000291713\n","2023-06-27T18:09:52.303996: step 4393, loss 0.0435969, acc 1, learning_rate 0.000291581\n","2023-06-27T18:09:52.417197: step 4394, loss 0.0391181, acc 1, learning_rate 0.00029145\n","2023-06-27T18:09:52.541251: step 4395, loss 0.243653, acc 0.90625, learning_rate 0.000291319\n","2023-06-27T18:09:52.657774: step 4396, loss 0.035279, acc 1, learning_rate 0.000291188\n","2023-06-27T18:09:52.781612: step 4397, loss 0.0354505, acc 1, learning_rate 0.000291056\n","2023-06-27T18:09:52.898088: step 4398, loss 0.141424, acc 0.90625, learning_rate 0.000290925\n","2023-06-27T18:09:53.081107: step 4399, loss 0.153616, acc 0.9375, learning_rate 0.000290795\n","\n","Evaluation:\n","2023-06-27T18:09:54.385878: step 4400, loss 0.77728, acc 0.800815\n","\n","Saved model checkpoint to /content/gdrive/MyDrive/lightweighted-cnn/train/runs/1687888658/checkpoints/model-4400\n","\n","2023-06-27T18:09:54.743003: step 4400, loss 0.07211, acc 0.96875, learning_rate 0.000290664\n","2023-06-27T18:09:54.944501: step 4401, loss 0.175649, acc 0.9375, learning_rate 0.000290533\n","2023-06-27T18:09:55.171977: step 4402, loss 0.0852416, acc 0.96875, learning_rate 0.000290402\n","2023-06-27T18:09:55.394734: step 4403, loss 0.0639144, acc 0.96875, learning_rate 0.000290272\n","2023-06-27T18:09:55.630555: step 4404, loss 0.020866, acc 1, learning_rate 0.000290141\n","2023-06-27T18:09:55.856876: step 4405, loss 0.019572, acc 1, learning_rate 0.000290011\n","2023-06-27T18:09:56.038321: step 4406, loss 0.0267884, acc 1, learning_rate 0.000289881\n","2023-06-27T18:09:56.239886: step 4407, loss 0.0997707, acc 0.9375, learning_rate 0.00028975\n","2023-06-27T18:09:56.456625: step 4408, loss 0.017269, acc 1, learning_rate 0.00028962\n","2023-06-27T18:09:56.654135: step 4409, loss 0.0301219, acc 1, learning_rate 0.00028949\n","2023-06-27T18:09:56.850421: step 4410, loss 0.0294358, acc 1, learning_rate 0.00028936\n","2023-06-27T18:09:57.039183: step 4411, loss 0.0313207, acc 1, learning_rate 0.00028923\n","2023-06-27T18:09:57.228858: step 4412, loss 0.0544848, acc 0.96875, learning_rate 0.000289101\n","2023-06-27T18:09:57.420986: step 4413, loss 0.0796849, acc 0.96875, learning_rate 0.000288971\n","2023-06-27T18:09:57.612113: step 4414, loss 0.0195496, acc 1, learning_rate 0.000288841\n","2023-06-27T18:09:57.791263: step 4415, loss 0.0323626, acc 1, learning_rate 0.000288712\n","2023-06-27T18:09:57.996251: step 4416, loss 0.0421884, acc 0.96875, learning_rate 0.000288583\n","2023-06-27T18:09:58.196064: step 4417, loss 0.0850195, acc 0.96875, learning_rate 0.000288453\n","2023-06-27T18:09:58.410045: step 4418, loss 0.0265729, acc 1, learning_rate 0.000288324\n","2023-06-27T18:09:58.575045: step 4419, loss 0.0352771, acc 1, learning_rate 0.000288195\n","2023-06-27T18:09:58.776368: step 4420, loss 0.070731, acc 0.96875, learning_rate 0.000288066\n","2023-06-27T18:09:58.968531: step 4421, loss 0.120396, acc 0.9375, learning_rate 0.000287937\n","2023-06-27T18:09:59.172034: step 4422, loss 0.0769228, acc 0.96875, learning_rate 0.000287808\n","2023-06-27T18:09:59.377132: step 4423, loss 0.113291, acc 0.96875, learning_rate 0.000287679\n","2023-06-27T18:09:59.580728: step 4424, loss 0.0356738, acc 1, learning_rate 0.00028755\n","2023-06-27T18:09:59.771301: step 4425, loss 0.0315167, acc 1, learning_rate 0.000287422\n","2023-06-27T18:09:59.960823: step 4426, loss 0.103559, acc 0.96875, learning_rate 0.000287293\n","2023-06-27T18:10:00.143145: step 4427, loss 0.0134848, acc 1, learning_rate 0.000287165\n","2023-06-27T18:10:00.346432: step 4428, loss 0.0786345, acc 1, learning_rate 0.000287037\n","2023-06-27T18:10:00.589400: step 4429, loss 0.0195702, acc 1, learning_rate 0.000286908\n","2023-06-27T18:10:00.774821: step 4430, loss 0.0385401, acc 0.96875, learning_rate 0.00028678\n","2023-06-27T18:10:00.967027: step 4431, loss 0.0231325, acc 1, learning_rate 0.000286652\n","2023-06-27T18:10:01.158904: step 4432, loss 0.0183269, acc 1, learning_rate 0.000286524\n","2023-06-27T18:10:01.369263: step 4433, loss 0.0329154, acc 1, learning_rate 0.000286396\n","2023-06-27T18:10:01.569333: step 4434, loss 0.0172562, acc 1, learning_rate 0.000286268\n","2023-06-27T18:10:01.761526: step 4435, loss 0.00497055, acc 1, learning_rate 0.000286141\n","2023-06-27T18:10:01.959009: step 4436, loss 0.0910504, acc 0.96875, learning_rate 0.000286013\n","2023-06-27T18:10:02.158439: step 4437, loss 0.0325946, acc 1, learning_rate 0.000285885\n","2023-06-27T18:10:02.357856: step 4438, loss 0.0842828, acc 0.96875, learning_rate 0.000285758\n","2023-06-27T18:10:02.550692: step 4439, loss 0.0525453, acc 1, learning_rate 0.000285631\n","2023-06-27T18:10:02.735330: step 4440, loss 0.0790436, acc 0.96875, learning_rate 0.000285503\n","2023-06-27T18:10:02.931858: step 4441, loss 0.0675259, acc 0.96875, learning_rate 0.000285376\n","2023-06-27T18:10:03.111533: step 4442, loss 0.0389767, acc 1, learning_rate 0.000285249\n","2023-06-27T18:10:03.330503: step 4443, loss 0.05621, acc 0.96875, learning_rate 0.000285122\n","2023-06-27T18:10:03.537719: step 4444, loss 0.0563719, acc 0.96875, learning_rate 0.000284995\n","2023-06-27T18:10:03.735381: step 4445, loss 0.0142311, acc 1, learning_rate 0.000284868\n","2023-06-27T18:10:03.940133: step 4446, loss 0.12199, acc 0.9375, learning_rate 0.000284741\n","2023-06-27T18:10:04.091404: step 4447, loss 0.120507, acc 0.9375, learning_rate 0.000284615\n","2023-06-27T18:10:04.210684: step 4448, loss 0.0277276, acc 1, learning_rate 0.000284488\n","2023-06-27T18:10:04.353756: step 4449, loss 0.0566291, acc 0.96875, learning_rate 0.000284362\n","2023-06-27T18:10:04.476341: step 4450, loss 0.0802517, acc 0.96875, learning_rate 0.000284235\n","2023-06-27T18:10:04.622590: step 4451, loss 0.0438509, acc 0.96875, learning_rate 0.000284109\n","2023-06-27T18:10:04.748499: step 4452, loss 0.046461, acc 0.96875, learning_rate 0.000283983\n","2023-06-27T18:10:04.867347: step 4453, loss 0.219775, acc 0.875, learning_rate 0.000283856\n","2023-06-27T18:10:04.981017: step 4454, loss 0.155492, acc 0.9375, learning_rate 0.00028373\n","2023-06-27T18:10:05.094678: step 4455, loss 0.101918, acc 0.9375, learning_rate 0.000283604\n","2023-06-27T18:10:05.217552: step 4456, loss 0.0561321, acc 1, learning_rate 0.000283478\n","2023-06-27T18:10:05.334864: step 4457, loss 0.0183713, acc 1, learning_rate 0.000283353\n","2023-06-27T18:10:05.455700: step 4458, loss 0.133991, acc 0.96875, learning_rate 0.000283227\n","2023-06-27T18:10:05.602469: step 4459, loss 0.109256, acc 0.9375, learning_rate 0.000283101\n","2023-06-27T18:10:05.720847: step 4460, loss 0.0142414, acc 1, learning_rate 0.000282976\n","2023-06-27T18:10:05.836845: step 4461, loss 0.0777729, acc 0.96875, learning_rate 0.00028285\n","2023-06-27T18:10:05.958045: step 4462, loss 0.0716787, acc 0.96875, learning_rate 0.000282725\n","2023-06-27T18:10:06.072181: step 4463, loss 0.0598853, acc 0.96875, learning_rate 0.0002826\n","2023-06-27T18:10:06.198588: step 4464, loss 0.0476623, acc 0.96875, learning_rate 0.000282474\n","2023-06-27T18:10:06.312081: step 4465, loss 0.0490321, acc 1, learning_rate 0.000282349\n","2023-06-27T18:10:06.427496: step 4466, loss 0.00887628, acc 1, learning_rate 0.000282224\n","2023-06-27T18:10:06.548988: step 4467, loss 0.0537223, acc 0.96875, learning_rate 0.000282099\n","2023-06-27T18:10:06.678931: step 4468, loss 0.0696277, acc 0.96875, learning_rate 0.000281974\n","2023-06-27T18:10:06.811056: step 4469, loss 0.0935612, acc 0.96875, learning_rate 0.00028185\n","2023-06-27T18:10:06.940836: step 4470, loss 0.131847, acc 0.96875, learning_rate 0.000281725\n","2023-06-27T18:10:07.061538: step 4471, loss 0.0473514, acc 0.96875, learning_rate 0.0002816\n","2023-06-27T18:10:07.188619: step 4472, loss 0.0592217, acc 1, learning_rate 0.000281476\n","2023-06-27T18:10:07.316301: step 4473, loss 0.0955858, acc 0.96875, learning_rate 0.000281351\n","2023-06-27T18:10:07.442291: step 4474, loss 0.0157535, acc 1, learning_rate 0.000281227\n","2023-06-27T18:10:07.555103: step 4475, loss 0.130989, acc 0.9375, learning_rate 0.000281103\n","2023-06-27T18:10:07.673919: step 4476, loss 0.0976357, acc 0.96875, learning_rate 0.000280978\n","2023-06-27T18:10:07.792187: step 4477, loss 0.00420536, acc 1, learning_rate 0.000280854\n","2023-06-27T18:10:07.899385: step 4478, loss 0.0499727, acc 1, learning_rate 0.00028073\n","2023-06-27T18:10:08.020897: step 4479, loss 0.082775, acc 0.96875, learning_rate 0.000280606\n","2023-06-27T18:10:08.134122: step 4480, loss 0.00721472, acc 1, learning_rate 0.000280483\n","2023-06-27T18:10:08.255048: step 4481, loss 0.01893, acc 1, learning_rate 0.000280359\n","2023-06-27T18:10:08.385472: step 4482, loss 0.102531, acc 0.96875, learning_rate 0.000280235\n","2023-06-27T18:10:08.510370: step 4483, loss 0.0782867, acc 0.96875, learning_rate 0.000280112\n","2023-06-27T18:10:08.639137: step 4484, loss 0.0622828, acc 0.96875, learning_rate 0.000279988\n","2023-06-27T18:10:08.760008: step 4485, loss 0.030797, acc 1, learning_rate 0.000279865\n","2023-06-27T18:10:08.884643: step 4486, loss 0.0423887, acc 1, learning_rate 0.000279741\n","2023-06-27T18:10:08.999092: step 4487, loss 0.0481864, acc 0.96875, learning_rate 0.000279618\n","2023-06-27T18:10:09.115716: step 4488, loss 0.100223, acc 0.96875, learning_rate 0.000279495\n","2023-06-27T18:10:09.274547: step 4489, loss 0.0151052, acc 1, learning_rate 0.000279372\n","2023-06-27T18:10:09.384100: step 4490, loss 0.0343052, acc 1, learning_rate 0.000279249\n","2023-06-27T18:10:09.507172: step 4491, loss 0.0716923, acc 0.96875, learning_rate 0.000279126\n","2023-06-27T18:10:09.642988: step 4492, loss 0.18891, acc 0.875, learning_rate 0.000279003\n","2023-06-27T18:10:09.781914: step 4493, loss 0.0137395, acc 1, learning_rate 0.00027888\n","2023-06-27T18:10:09.890539: step 4494, loss 0.15746, acc 0.96875, learning_rate 0.000278758\n","2023-06-27T18:10:10.007791: step 4495, loss 0.0290002, acc 1, learning_rate 0.000278635\n","2023-06-27T18:10:10.140252: step 4496, loss 0.056463, acc 0.96875, learning_rate 0.000278513\n","2023-06-27T18:10:10.265886: step 4497, loss 0.077348, acc 1, learning_rate 0.00027839\n","2023-06-27T18:10:10.398925: step 4498, loss 0.00225762, acc 1, learning_rate 0.000278268\n","2023-06-27T18:10:10.524873: step 4499, loss 0.0623007, acc 0.96875, learning_rate 0.000278146\n","\n","Evaluation:\n","2023-06-27T18:10:11.270959: step 4500, loss 0.794133, acc 0.800172\n","\n","Saved model checkpoint to /content/gdrive/MyDrive/lightweighted-cnn/train/runs/1687888658/checkpoints/model-4500\n","\n","2023-06-27T18:10:11.484385: step 4500, loss 0.0613432, acc 1, learning_rate 0.000278023\n","2023-06-27T18:10:11.615653: step 4501, loss 0.0765848, acc 0.96875, learning_rate 0.000277901\n","2023-06-27T18:10:11.731855: step 4502, loss 0.228273, acc 0.9375, learning_rate 0.000277779\n","2023-06-27T18:10:11.851772: step 4503, loss 0.0355084, acc 1, learning_rate 0.000277657\n","2023-06-27T18:10:11.980324: step 4504, loss 0.149638, acc 0.96875, learning_rate 0.000277536\n","2023-06-27T18:10:12.119523: step 4505, loss 0.130462, acc 0.9375, learning_rate 0.000277414\n","2023-06-27T18:10:12.240335: step 4506, loss 0.0454949, acc 1, learning_rate 0.000277292\n","2023-06-27T18:10:12.376134: step 4507, loss 0.0857133, acc 0.9375, learning_rate 0.000277171\n","2023-06-27T18:10:12.494526: step 4508, loss 0.0193068, acc 1, learning_rate 0.000277049\n","2023-06-27T18:10:12.615380: step 4509, loss 0.050338, acc 0.96875, learning_rate 0.000276928\n","2023-06-27T18:10:12.728653: step 4510, loss 0.0764508, acc 0.96875, learning_rate 0.000276806\n","2023-06-27T18:10:12.856239: step 4511, loss 0.0294158, acc 1, learning_rate 0.000276685\n","2023-06-27T18:10:12.971057: step 4512, loss 0.0137269, acc 1, learning_rate 0.000276564\n","2023-06-27T18:10:13.092621: step 4513, loss 0.130549, acc 0.96875, learning_rate 0.000276443\n","2023-06-27T18:10:13.218525: step 4514, loss 0.0826253, acc 0.9375, learning_rate 0.000276322\n","2023-06-27T18:10:13.340691: step 4515, loss 0.255069, acc 0.9375, learning_rate 0.000276201\n","2023-06-27T18:10:13.462380: step 4516, loss 0.0210789, acc 1, learning_rate 0.00027608\n","2023-06-27T18:10:13.588524: step 4517, loss 0.0429093, acc 0.96875, learning_rate 0.000275959\n","2023-06-27T18:10:13.708921: step 4518, loss 0.0754803, acc 0.96875, learning_rate 0.000275839\n","2023-06-27T18:10:13.831983: step 4519, loss 0.0342268, acc 1, learning_rate 0.000275718\n","2023-06-27T18:10:13.961844: step 4520, loss 0.0236892, acc 1, learning_rate 0.000275598\n","2023-06-27T18:10:14.129480: step 4521, loss 0.00669034, acc 1, learning_rate 0.000275477\n","2023-06-27T18:10:14.309708: step 4522, loss 0.132047, acc 0.9375, learning_rate 0.000275357\n","2023-06-27T18:10:14.502319: step 4523, loss 0.149283, acc 0.9375, learning_rate 0.000275237\n","2023-06-27T18:10:14.717375: step 4524, loss 0.0411895, acc 1, learning_rate 0.000275117\n","2023-06-27T18:10:14.906639: step 4525, loss 0.384693, acc 0.84375, learning_rate 0.000274997\n","2023-06-27T18:10:15.113613: step 4526, loss 0.0336419, acc 1, learning_rate 0.000274877\n","2023-06-27T18:10:15.328971: step 4527, loss 0.00774302, acc 1, learning_rate 0.000274757\n","2023-06-27T18:10:15.536270: step 4528, loss 0.0219278, acc 1, learning_rate 0.000274637\n","2023-06-27T18:10:15.752050: step 4529, loss 0.00751717, acc 1, learning_rate 0.000274517\n","2023-06-27T18:10:15.971815: step 4530, loss 0.0237993, acc 1, learning_rate 0.000274397\n","2023-06-27T18:10:16.159297: step 4531, loss 0.0388912, acc 1, learning_rate 0.000274278\n","2023-06-27T18:10:16.369985: step 4532, loss 0.0208788, acc 1, learning_rate 0.000274158\n","2023-06-27T18:10:16.593170: step 4533, loss 0.0272307, acc 1, learning_rate 0.000274039\n","2023-06-27T18:10:16.804099: step 4534, loss 0.112, acc 0.96875, learning_rate 0.000273919\n","2023-06-27T18:10:16.997462: step 4535, loss 0.0257035, acc 1, learning_rate 0.0002738\n","2023-06-27T18:10:17.234700: step 4536, loss 0.00409003, acc 1, learning_rate 0.000273681\n","2023-06-27T18:10:17.430226: step 4537, loss 0.0384466, acc 0.96875, learning_rate 0.000273562\n","2023-06-27T18:10:17.645007: step 4538, loss 0.0334244, acc 1, learning_rate 0.000273443\n","2023-06-27T18:10:17.851099: step 4539, loss 0.169513, acc 0.96875, learning_rate 0.000273324\n","2023-06-27T18:10:18.048369: step 4540, loss 0.0653891, acc 1, learning_rate 0.000273205\n","2023-06-27T18:10:18.225621: step 4541, loss 0.0794356, acc 0.96875, learning_rate 0.000273086\n","2023-06-27T18:10:18.420683: step 4542, loss 0.0850578, acc 0.9375, learning_rate 0.000272968\n","2023-06-27T18:10:18.616970: step 4543, loss 0.0665665, acc 0.96875, learning_rate 0.000272849\n","2023-06-27T18:10:18.832026: step 4544, loss 0.138886, acc 0.90625, learning_rate 0.000272731\n","2023-06-27T18:10:19.022328: step 4545, loss 0.138432, acc 0.9375, learning_rate 0.000272612\n","2023-06-27T18:10:19.204447: step 4546, loss 0.208983, acc 0.875, learning_rate 0.000272494\n","2023-06-27T18:10:19.391608: step 4547, loss 0.0809795, acc 0.96875, learning_rate 0.000272375\n","2023-06-27T18:10:19.583483: step 4548, loss 0.0342288, acc 1, learning_rate 0.000272257\n","2023-06-27T18:10:19.765433: step 4549, loss 0.0338933, acc 0.96875, learning_rate 0.000272139\n","2023-06-27T18:10:19.968049: step 4550, loss 0.012608, acc 1, learning_rate 0.000272021\n","2023-06-27T18:10:20.165177: step 4551, loss 0.0420901, acc 0.96875, learning_rate 0.000271903\n","2023-06-27T18:10:20.360132: step 4552, loss 0.0300628, acc 1, learning_rate 0.000271785\n","2023-06-27T18:10:20.544372: step 4553, loss 0.0844097, acc 0.96875, learning_rate 0.000271667\n","2023-06-27T18:10:20.755093: step 4554, loss 0.0520476, acc 0.96875, learning_rate 0.00027155\n","2023-06-27T18:10:20.933857: step 4555, loss 0.0956063, acc 0.96875, learning_rate 0.000271432\n","2023-06-27T18:10:21.131596: step 4556, loss 0.0837271, acc 0.96875, learning_rate 0.000271315\n","2023-06-27T18:10:21.320533: step 4557, loss 0.0756866, acc 0.96875, learning_rate 0.000271197\n","2023-06-27T18:10:21.522636: step 4558, loss 0.0644664, acc 0.96875, learning_rate 0.00027108\n","2023-06-27T18:10:21.714244: step 4559, loss 0.0603721, acc 1, learning_rate 0.000270962\n","2023-06-27T18:10:21.917490: step 4560, loss 0.0515055, acc 0.96875, learning_rate 0.000270845\n","2023-06-27T18:10:22.119067: step 4561, loss 0.0536762, acc 0.96875, learning_rate 0.000270728\n","2023-06-27T18:10:22.309964: step 4562, loss 0.0675903, acc 0.96875, learning_rate 0.000270611\n","2023-06-27T18:10:22.475095: step 4563, loss 0.0436883, acc 0.96875, learning_rate 0.000270494\n","2023-06-27T18:10:22.710733: step 4564, loss 0.109902, acc 0.96875, learning_rate 0.000270377\n","2023-06-27T18:10:22.903476: step 4565, loss 0.0462664, acc 1, learning_rate 0.00027026\n","2023-06-27T18:10:23.103534: step 4566, loss 0.122272, acc 0.96875, learning_rate 0.000270143\n","2023-06-27T18:10:23.313856: step 4567, loss 0.247362, acc 0.96875, learning_rate 0.000270027\n","2023-06-27T18:10:23.505829: step 4568, loss 0.0400488, acc 0.96875, learning_rate 0.00026991\n","2023-06-27T18:10:23.708722: step 4569, loss 0.10323, acc 1, learning_rate 0.000269794\n","2023-06-27T18:10:23.889837: step 4570, loss 0.0683791, acc 0.96875, learning_rate 0.000269677\n","2023-06-27T18:10:24.083205: step 4571, loss 0.0235826, acc 1, learning_rate 0.000269561\n","2023-06-27T18:10:24.277186: step 4572, loss 0.0387803, acc 1, learning_rate 0.000269445\n","2023-06-27T18:10:24.474141: step 4573, loss 0.122625, acc 0.875, learning_rate 0.000269328\n","2023-06-27T18:10:24.686744: step 4574, loss 0.0181521, acc 1, learning_rate 0.000269212\n","2023-06-27T18:10:24.884897: step 4575, loss 0.0139809, acc 1, learning_rate 0.000269096\n","2023-06-27T18:10:25.056804: step 4576, loss 0.0654054, acc 1, learning_rate 0.00026898\n","2023-06-27T18:10:25.170197: step 4577, loss 0.0499212, acc 0.96875, learning_rate 0.000268864\n","2023-06-27T18:10:25.299412: step 4578, loss 0.0498954, acc 0.96875, learning_rate 0.000268749\n","2023-06-27T18:10:25.427608: step 4579, loss 0.0167793, acc 1, learning_rate 0.000268633\n","2023-06-27T18:10:25.549525: step 4580, loss 0.0812855, acc 0.96875, learning_rate 0.000268517\n","2023-06-27T18:10:25.679836: step 4581, loss 0.0119324, acc 1, learning_rate 0.000268402\n","2023-06-27T18:10:25.819079: step 4582, loss 0.0840591, acc 0.96875, learning_rate 0.000268286\n","2023-06-27T18:10:25.952899: step 4583, loss 0.0482173, acc 1, learning_rate 0.000268171\n","2023-06-27T18:10:26.070716: step 4584, loss 0.00123111, acc 1, learning_rate 0.000268056\n","2023-06-27T18:10:26.181752: step 4585, loss 0.0823822, acc 1, learning_rate 0.00026794\n","2023-06-27T18:10:26.322481: step 4586, loss 0.0606987, acc 0.96875, learning_rate 0.000267825\n","2023-06-27T18:10:26.439010: step 4587, loss 0.0734099, acc 0.96875, learning_rate 0.00026771\n","2023-06-27T18:10:26.552500: step 4588, loss 0.0442043, acc 0.96875, learning_rate 0.000267595\n","2023-06-27T18:10:26.680778: step 4589, loss 0.102306, acc 0.9375, learning_rate 0.00026748\n","2023-06-27T18:10:26.812465: step 4590, loss 0.0285274, acc 1, learning_rate 0.000267365\n","2023-06-27T18:10:26.928664: step 4591, loss 0.249927, acc 0.90625, learning_rate 0.000267251\n","2023-06-27T18:10:27.059831: step 4592, loss 0.0713181, acc 0.96875, learning_rate 0.000267136\n","2023-06-27T18:10:27.174449: step 4593, loss 0.162902, acc 0.90625, learning_rate 0.000267021\n","2023-06-27T18:10:27.304214: step 4594, loss 0.0897398, acc 0.96875, learning_rate 0.000266907\n","2023-06-27T18:10:27.425036: step 4595, loss 0.0514261, acc 0.96875, learning_rate 0.000266792\n","2023-06-27T18:10:27.549556: step 4596, loss 0.0359824, acc 1, learning_rate 0.000266678\n","2023-06-27T18:10:27.674678: step 4597, loss 0.080031, acc 0.96875, learning_rate 0.000266564\n","2023-06-27T18:10:27.789679: step 4598, loss 0.0600145, acc 0.96875, learning_rate 0.000266449\n","2023-06-27T18:10:27.915835: step 4599, loss 0.0722288, acc 0.96875, learning_rate 0.000266335\n","\n","Evaluation:\n","2023-06-27T18:10:28.684128: step 4600, loss 0.786055, acc 0.801029\n","\n","Saved model checkpoint to /content/gdrive/MyDrive/lightweighted-cnn/train/runs/1687888658/checkpoints/model-4600\n","\n","2023-06-27T18:10:28.908025: step 4600, loss 0.0649466, acc 1, learning_rate 0.000266221\n","2023-06-27T18:10:29.037953: step 4601, loss 0.0763754, acc 0.96875, learning_rate 0.000266107\n","2023-06-27T18:10:29.152504: step 4602, loss 0.0337515, acc 1, learning_rate 0.000265993\n","2023-06-27T18:10:29.297933: step 4603, loss 0.016007, acc 1, learning_rate 0.000265879\n","2023-06-27T18:10:29.435681: step 4604, loss 0.0551, acc 1, learning_rate 0.000265766\n","2023-06-27T18:10:29.563073: step 4605, loss 0.0338865, acc 1, learning_rate 0.000265652\n","2023-06-27T18:10:29.688962: step 4606, loss 0.164563, acc 0.90625, learning_rate 0.000265538\n","2023-06-27T18:10:29.817253: step 4607, loss 0.139178, acc 0.9375, learning_rate 0.000265425\n","2023-06-27T18:10:29.947726: step 4608, loss 0.0418233, acc 1, learning_rate 0.000265311\n","2023-06-27T18:10:30.064566: step 4609, loss 0.067567, acc 1, learning_rate 0.000265198\n","2023-06-27T18:10:30.180493: step 4610, loss 0.0266293, acc 1, learning_rate 0.000265085\n","2023-06-27T18:10:30.312876: step 4611, loss 0.00267275, acc 1, learning_rate 0.000264972\n","2023-06-27T18:10:30.456765: step 4612, loss 0.0173385, acc 1, learning_rate 0.000264859\n","2023-06-27T18:10:30.578112: step 4613, loss 0.0911471, acc 0.9375, learning_rate 0.000264745\n","2023-06-27T18:10:30.722848: step 4614, loss 0.0312215, acc 1, learning_rate 0.000264633\n","2023-06-27T18:10:30.845755: step 4615, loss 0.0895796, acc 0.96875, learning_rate 0.00026452\n","2023-06-27T18:10:30.974175: step 4616, loss 0.0237294, acc 1, learning_rate 0.000264407\n","2023-06-27T18:10:31.092521: step 4617, loss 0.279843, acc 0.875, learning_rate 0.000264294\n","2023-06-27T18:10:31.202259: step 4618, loss 0.00893151, acc 1, learning_rate 0.000264181\n","2023-06-27T18:10:31.326810: step 4619, loss 0.0525564, acc 0.96875, learning_rate 0.000264069\n","2023-06-27T18:10:31.459086: step 4620, loss 0.0943412, acc 0.9375, learning_rate 0.000263956\n","2023-06-27T18:10:31.584453: step 4621, loss 0.0335128, acc 1, learning_rate 0.000263844\n","2023-06-27T18:10:31.711443: step 4622, loss 0.0769152, acc 0.96875, learning_rate 0.000263732\n","2023-06-27T18:10:31.824607: step 4623, loss 0.0711177, acc 0.96875, learning_rate 0.000263619\n","2023-06-27T18:10:31.948406: step 4624, loss 0.0155253, acc 1, learning_rate 0.000263507\n","2023-06-27T18:10:32.078995: step 4625, loss 0.0574033, acc 0.96875, learning_rate 0.000263395\n","2023-06-27T18:10:32.204427: step 4626, loss 0.0508256, acc 0.96875, learning_rate 0.000263283\n","2023-06-27T18:10:32.318909: step 4627, loss 0.0456271, acc 0.96875, learning_rate 0.000263171\n","2023-06-27T18:10:32.478636: step 4628, loss 0.0531948, acc 1, learning_rate 0.000263059\n","2023-06-27T18:10:32.596798: step 4629, loss 0.0238635, acc 1, learning_rate 0.000262947\n","2023-06-27T18:10:32.725341: step 4630, loss 0.0468435, acc 0.96875, learning_rate 0.000262835\n","2023-06-27T18:10:32.855635: step 4631, loss 0.00781203, acc 1, learning_rate 0.000262724\n","2023-06-27T18:10:32.978349: step 4632, loss 0.0347095, acc 0.96875, learning_rate 0.000262612\n","2023-06-27T18:10:33.092197: step 4633, loss 0.0237134, acc 1, learning_rate 0.000262501\n","2023-06-27T18:10:33.202772: step 4634, loss 0.00358277, acc 1, learning_rate 0.000262389\n","2023-06-27T18:10:33.331795: step 4635, loss 0.0506949, acc 0.96875, learning_rate 0.000262278\n","2023-06-27T18:10:33.455472: step 4636, loss 0.0413122, acc 1, learning_rate 0.000262167\n","2023-06-27T18:10:33.574534: step 4637, loss 0.0474576, acc 0.96875, learning_rate 0.000262055\n","2023-06-27T18:10:33.682563: step 4638, loss 0.129987, acc 0.9375, learning_rate 0.000261944\n","2023-06-27T18:10:33.819289: step 4639, loss 0.0194319, acc 1, learning_rate 0.000261833\n","2023-06-27T18:10:33.951940: step 4640, loss 0.096306, acc 0.96875, learning_rate 0.000261722\n","2023-06-27T18:10:34.084363: step 4641, loss 0.0575716, acc 1, learning_rate 0.000261611\n","2023-06-27T18:10:34.214367: step 4642, loss 0.0543323, acc 1, learning_rate 0.000261501\n","2023-06-27T18:10:34.338162: step 4643, loss 0.0157218, acc 1, learning_rate 0.00026139\n","2023-06-27T18:10:34.471401: step 4644, loss 0.100029, acc 0.96875, learning_rate 0.000261279\n","2023-06-27T18:10:34.605292: step 4645, loss 0.0143593, acc 1, learning_rate 0.000261169\n","2023-06-27T18:10:34.731199: step 4646, loss 0.032047, acc 1, learning_rate 0.000261058\n","2023-06-27T18:10:34.853415: step 4647, loss 0.0374477, acc 1, learning_rate 0.000260948\n","2023-06-27T18:10:34.976592: step 4648, loss 0.035722, acc 1, learning_rate 0.000260837\n","2023-06-27T18:10:35.117064: step 4649, loss 0.0100672, acc 1, learning_rate 0.000260727\n","2023-06-27T18:10:35.304173: step 4650, loss 0.014924, acc 1, learning_rate 0.000260617\n","2023-06-27T18:10:35.563905: step 4651, loss 0.0598667, acc 0.96875, learning_rate 0.000260507\n","2023-06-27T18:10:35.752057: step 4652, loss 0.0207494, acc 1, learning_rate 0.000260397\n","2023-06-27T18:10:35.959728: step 4653, loss 0.0104792, acc 1, learning_rate 0.000260287\n","2023-06-27T18:10:36.162337: step 4654, loss 0.0234155, acc 1, learning_rate 0.000260177\n","2023-06-27T18:10:36.381752: step 4655, loss 0.277051, acc 0.9375, learning_rate 0.000260067\n","2023-06-27T18:10:36.614919: step 4656, loss 0.0281622, acc 1, learning_rate 0.000259957\n","2023-06-27T18:10:36.812188: step 4657, loss 0.153584, acc 0.96875, learning_rate 0.000259847\n","2023-06-27T18:10:37.019112: step 4658, loss 0.129168, acc 0.96875, learning_rate 0.000259738\n","2023-06-27T18:10:37.228825: step 4659, loss 0.0296529, acc 1, learning_rate 0.000259628\n","2023-06-27T18:10:37.417400: step 4660, loss 0.0518632, acc 1, learning_rate 0.000259519\n","2023-06-27T18:10:37.623177: step 4661, loss 0.0377363, acc 1, learning_rate 0.000259409\n","2023-06-27T18:10:37.821324: step 4662, loss 0.118817, acc 0.9375, learning_rate 0.0002593\n","2023-06-27T18:10:38.006777: step 4663, loss 0.0645306, acc 0.96875, learning_rate 0.000259191\n","2023-06-27T18:10:38.215546: step 4664, loss 0.0506923, acc 0.96875, learning_rate 0.000259082\n","2023-06-27T18:10:38.436496: step 4665, loss 0.0357059, acc 1, learning_rate 0.000258973\n","2023-06-27T18:10:38.648930: step 4666, loss 0.0293295, acc 1, learning_rate 0.000258864\n","2023-06-27T18:10:38.833341: step 4667, loss 0.0119813, acc 1, learning_rate 0.000258755\n","2023-06-27T18:10:39.034175: step 4668, loss 0.0681244, acc 0.96875, learning_rate 0.000258646\n","2023-06-27T18:10:39.247193: step 4669, loss 0.0533496, acc 0.96875, learning_rate 0.000258537\n","2023-06-27T18:10:39.443301: step 4670, loss 0.0703169, acc 0.9375, learning_rate 0.000258428\n","2023-06-27T18:10:39.613270: step 4671, loss 0.000313207, acc 1, learning_rate 0.00025832\n","2023-06-27T18:10:39.825692: step 4672, loss 0.0394769, acc 1, learning_rate 0.000258211\n","2023-06-27T18:10:40.007266: step 4673, loss 0.012415, acc 1, learning_rate 0.000258103\n","2023-06-27T18:10:40.192377: step 4674, loss 0.0378482, acc 1, learning_rate 0.000257994\n","2023-06-27T18:10:40.392385: step 4675, loss 0.0469687, acc 0.96875, learning_rate 0.000257886\n","2023-06-27T18:10:40.590536: step 4676, loss 0.0375567, acc 1, learning_rate 0.000257778\n","2023-06-27T18:10:40.809016: step 4677, loss 0.0637561, acc 0.96875, learning_rate 0.000257669\n","2023-06-27T18:10:40.991006: step 4678, loss 0.0230281, acc 1, learning_rate 0.000257561\n","2023-06-27T18:10:41.185817: step 4679, loss 0.0176049, acc 1, learning_rate 0.000257453\n","2023-06-27T18:10:41.376882: step 4680, loss 0.00642659, acc 1, learning_rate 0.000257345\n","2023-06-27T18:10:41.578703: step 4681, loss 0.166473, acc 0.9375, learning_rate 0.000257237\n","2023-06-27T18:10:41.767871: step 4682, loss 0.0434049, acc 1, learning_rate 0.00025713\n","2023-06-27T18:10:41.973788: step 4683, loss 0.0189587, acc 1, learning_rate 0.000257022\n","2023-06-27T18:10:42.162827: step 4684, loss 0.0665538, acc 0.96875, learning_rate 0.000256914\n","2023-06-27T18:10:42.356360: step 4685, loss 0.0305253, acc 1, learning_rate 0.000256807\n","2023-06-27T18:10:42.545629: step 4686, loss 0.251199, acc 0.90625, learning_rate 0.000256699\n","2023-06-27T18:10:42.735957: step 4687, loss 0.0439888, acc 1, learning_rate 0.000256592\n","2023-06-27T18:10:42.914606: step 4688, loss 0.00476278, acc 1, learning_rate 0.000256484\n","2023-06-27T18:10:43.093151: step 4689, loss 0.0199866, acc 1, learning_rate 0.000256377\n","2023-06-27T18:10:43.294341: step 4690, loss 0.0254333, acc 1, learning_rate 0.00025627\n","2023-06-27T18:10:43.496670: step 4691, loss 0.0266443, acc 1, learning_rate 0.000256162\n","2023-06-27T18:10:43.691621: step 4692, loss 0.104813, acc 0.9375, learning_rate 0.000256055\n","2023-06-27T18:10:43.873449: step 4693, loss 0.160868, acc 0.9375, learning_rate 0.000255948\n","2023-06-27T18:10:44.068195: step 4694, loss 0.0593962, acc 1, learning_rate 0.000255841\n","2023-06-27T18:10:44.272167: step 4695, loss 0.0620443, acc 1, learning_rate 0.000255735\n","2023-06-27T18:10:44.481246: step 4696, loss 0.0632936, acc 0.96875, learning_rate 0.000255628\n","2023-06-27T18:10:44.698468: step 4697, loss 0.00980055, acc 1, learning_rate 0.000255521\n","2023-06-27T18:10:44.904561: step 4698, loss 0.0145881, acc 1, learning_rate 0.000255414\n","2023-06-27T18:10:45.102229: step 4699, loss 0.133264, acc 0.96875, learning_rate 0.000255308\n","\n","Evaluation:\n","2023-06-27T18:10:46.184277: step 4700, loss 0.789763, acc 0.802101\n","\n","Saved model checkpoint to /content/gdrive/MyDrive/lightweighted-cnn/train/runs/1687888658/checkpoints/model-4700\n","\n","2023-06-27T18:10:46.398689: step 4700, loss 0.0491219, acc 0.96875, learning_rate 0.000255201\n","2023-06-27T18:10:46.538484: step 4701, loss 0.0579366, acc 1, learning_rate 0.000255095\n","2023-06-27T18:10:46.675376: step 4702, loss 0.222736, acc 0.90625, learning_rate 0.000254989\n","2023-06-27T18:10:46.793924: step 4703, loss 0.0152663, acc 1, learning_rate 0.000254882\n","2023-06-27T18:10:46.906305: step 4704, loss 0.0230481, acc 1, learning_rate 0.000254776\n","2023-06-27T18:10:47.039664: step 4705, loss 0.0530955, acc 0.96875, learning_rate 0.00025467\n","2023-06-27T18:10:47.164331: step 4706, loss 0.0923618, acc 0.9375, learning_rate 0.000254564\n","2023-06-27T18:10:47.284661: step 4707, loss 0.0487639, acc 1, learning_rate 0.000254458\n","2023-06-27T18:10:47.398525: step 4708, loss 0.102224, acc 0.9375, learning_rate 0.000254352\n","2023-06-27T18:10:47.519577: step 4709, loss 0.143164, acc 0.90625, learning_rate 0.000254246\n","2023-06-27T18:10:47.651148: step 4710, loss 0.0560513, acc 1, learning_rate 0.00025414\n","2023-06-27T18:10:47.777169: step 4711, loss 0.0656602, acc 1, learning_rate 0.000254035\n","2023-06-27T18:10:47.890839: step 4712, loss 0.115506, acc 0.96875, learning_rate 0.000253929\n","2023-06-27T18:10:48.023303: step 4713, loss 0.0165665, acc 1, learning_rate 0.000253823\n","2023-06-27T18:10:48.145707: step 4714, loss 0.07827, acc 0.9375, learning_rate 0.000253718\n","2023-06-27T18:10:48.265265: step 4715, loss 0.0205779, acc 1, learning_rate 0.000253613\n","2023-06-27T18:10:48.396053: step 4716, loss 0.165838, acc 0.96875, learning_rate 0.000253507\n","2023-06-27T18:10:48.514383: step 4717, loss 0.0418898, acc 1, learning_rate 0.000253402\n","2023-06-27T18:10:48.636008: step 4718, loss 0.00917002, acc 1, learning_rate 0.000253297\n","2023-06-27T18:10:48.747974: step 4719, loss 0.026202, acc 1, learning_rate 0.000253192\n","2023-06-27T18:10:48.868982: step 4720, loss 0.119294, acc 0.9375, learning_rate 0.000253087\n","2023-06-27T18:10:48.984460: step 4721, loss 0.0502616, acc 0.96875, learning_rate 0.000252982\n","2023-06-27T18:10:49.111698: step 4722, loss 0.00352763, acc 1, learning_rate 0.000252877\n","2023-06-27T18:10:49.238277: step 4723, loss 0.10219, acc 0.9375, learning_rate 0.000252772\n","2023-06-27T18:10:49.353316: step 4724, loss 0.0108259, acc 1, learning_rate 0.000252667\n","2023-06-27T18:10:49.478614: step 4725, loss 0.206807, acc 0.90625, learning_rate 0.000252562\n","2023-06-27T18:10:49.594192: step 4726, loss 0.0456887, acc 0.96875, learning_rate 0.000252458\n","2023-06-27T18:10:49.717736: step 4727, loss 0.0189397, acc 1, learning_rate 0.000252353\n","2023-06-27T18:10:49.836403: step 4728, loss 0.0211913, acc 1, learning_rate 0.000252249\n","2023-06-27T18:10:49.944618: step 4729, loss 0.0167813, acc 1, learning_rate 0.000252144\n","2023-06-27T18:10:50.082783: step 4730, loss 0.0566467, acc 0.96875, learning_rate 0.00025204\n","2023-06-27T18:10:50.221003: step 4731, loss 0.05512, acc 0.96875, learning_rate 0.000251936\n","2023-06-27T18:10:50.333619: step 4732, loss 0.0855394, acc 0.9375, learning_rate 0.000251832\n","2023-06-27T18:10:50.450975: step 4733, loss 0.0592137, acc 0.96875, learning_rate 0.000251728\n","2023-06-27T18:10:50.574035: step 4734, loss 0.0689632, acc 0.96875, learning_rate 0.000251624\n","2023-06-27T18:10:50.700844: step 4735, loss 0.0176328, acc 1, learning_rate 0.00025152\n","2023-06-27T18:10:50.820302: step 4736, loss 0.145076, acc 0.9375, learning_rate 0.000251416\n","2023-06-27T18:10:50.940634: step 4737, loss 0.0488538, acc 0.96875, learning_rate 0.000251312\n","2023-06-27T18:10:51.068548: step 4738, loss 0.0711649, acc 0.96875, learning_rate 0.000251208\n","2023-06-27T18:10:51.191356: step 4739, loss 0.054271, acc 1, learning_rate 0.000251104\n","2023-06-27T18:10:51.314085: step 4740, loss 0.0682056, acc 0.96875, learning_rate 0.000251001\n","2023-06-27T18:10:51.440683: step 4741, loss 0.0594723, acc 0.96875, learning_rate 0.000250897\n","2023-06-27T18:10:51.557419: step 4742, loss 0.0849617, acc 0.9375, learning_rate 0.000250794\n","2023-06-27T18:10:51.689746: step 4743, loss 0.0568697, acc 0.96875, learning_rate 0.00025069\n","2023-06-27T18:10:51.815497: step 4744, loss 0.038699, acc 1, learning_rate 0.000250587\n","2023-06-27T18:10:51.931705: step 4745, loss 0.0115978, acc 1, learning_rate 0.000250484\n","2023-06-27T18:10:52.048239: step 4746, loss 0.0949832, acc 0.96875, learning_rate 0.000250381\n","2023-06-27T18:10:52.203668: step 4747, loss 0.00938033, acc 1, learning_rate 0.000250277\n","2023-06-27T18:10:52.319542: step 4748, loss 0.0455322, acc 0.96875, learning_rate 0.000250174\n","2023-06-27T18:10:52.442386: step 4749, loss 0.0239622, acc 1, learning_rate 0.000250071\n","2023-06-27T18:10:52.563336: step 4750, loss 0.020968, acc 1, learning_rate 0.000249969\n","2023-06-27T18:10:52.679389: step 4751, loss 0.0775152, acc 0.96875, learning_rate 0.000249866\n","2023-06-27T18:10:52.794926: step 4752, loss 0.0762795, acc 0.96875, learning_rate 0.000249763\n","2023-06-27T18:10:52.913568: step 4753, loss 0.146066, acc 0.9375, learning_rate 0.00024966\n","2023-06-27T18:10:53.042779: step 4754, loss 0.00821712, acc 1, learning_rate 0.000249558\n","2023-06-27T18:10:53.178985: step 4755, loss 0.0169156, acc 1, learning_rate 0.000249455\n","2023-06-27T18:10:53.295313: step 4756, loss 0.0608012, acc 0.96875, learning_rate 0.000249353\n","2023-06-27T18:10:53.403771: step 4757, loss 0.0567224, acc 1, learning_rate 0.00024925\n","2023-06-27T18:10:53.527931: step 4758, loss 0.0468057, acc 1, learning_rate 0.000249148\n","2023-06-27T18:10:53.639931: step 4759, loss 0.093623, acc 0.9375, learning_rate 0.000249046\n","2023-06-27T18:10:53.762550: step 4760, loss 0.0560215, acc 0.96875, learning_rate 0.000248943\n","2023-06-27T18:10:53.873364: step 4761, loss 0.00541981, acc 1, learning_rate 0.000248841\n","2023-06-27T18:10:54.004913: step 4762, loss 0.0476193, acc 0.96875, learning_rate 0.000248739\n","2023-06-27T18:10:54.114351: step 4763, loss 0.107555, acc 0.9375, learning_rate 0.000248637\n","2023-06-27T18:10:54.238020: step 4764, loss 0.0328115, acc 1, learning_rate 0.000248535\n","2023-06-27T18:10:54.371732: step 4765, loss 0.0178537, acc 1, learning_rate 0.000248433\n","2023-06-27T18:10:54.485811: step 4766, loss 0.0657673, acc 1, learning_rate 0.000248332\n","2023-06-27T18:10:54.617764: step 4767, loss 0.0503901, acc 0.96875, learning_rate 0.00024823\n","2023-06-27T18:10:54.738485: step 4768, loss 0.0975974, acc 0.96875, learning_rate 0.000248128\n","2023-06-27T18:10:54.851813: step 4769, loss 0.10481, acc 0.9375, learning_rate 0.000248027\n","2023-06-27T18:10:54.967637: step 4770, loss 0.0524297, acc 0.96875, learning_rate 0.000247925\n","2023-06-27T18:10:55.091772: step 4771, loss 0.238857, acc 0.875, learning_rate 0.000247824\n","2023-06-27T18:10:55.231959: step 4772, loss 0.0334399, acc 1, learning_rate 0.000247722\n","2023-06-27T18:10:55.345264: step 4773, loss 0.086426, acc 0.96875, learning_rate 0.000247621\n","2023-06-27T18:10:55.483498: step 4774, loss 0.0773661, acc 0.96875, learning_rate 0.00024752\n","2023-06-27T18:10:55.639855: step 4775, loss 0.0190319, acc 1, learning_rate 0.000247419\n","2023-06-27T18:10:55.781220: step 4776, loss 0.0475457, acc 0.96875, learning_rate 0.000247318\n","2023-06-27T18:10:55.916849: step 4777, loss 0.0538658, acc 1, learning_rate 0.000247217\n","2023-06-27T18:10:56.087471: step 4778, loss 0.0103284, acc 1, learning_rate 0.000247116\n","2023-06-27T18:10:56.296238: step 4779, loss 0.0540053, acc 0.96875, learning_rate 0.000247015\n","2023-06-27T18:10:56.504818: step 4780, loss 0.0247752, acc 1, learning_rate 0.000246914\n","2023-06-27T18:10:56.715894: step 4781, loss 0.113145, acc 0.9375, learning_rate 0.000246813\n","2023-06-27T18:10:56.912580: step 4782, loss 0.0521191, acc 0.96875, learning_rate 0.000246712\n","2023-06-27T18:10:57.131314: step 4783, loss 0.0440106, acc 0.96875, learning_rate 0.000246612\n","2023-06-27T18:10:57.327927: step 4784, loss 0.0321991, acc 1, learning_rate 0.000246511\n","2023-06-27T18:10:57.516521: step 4785, loss 0.0652059, acc 0.96875, learning_rate 0.000246411\n","2023-06-27T18:10:57.710092: step 4786, loss 0.0262602, acc 1, learning_rate 0.00024631\n","2023-06-27T18:10:57.906365: step 4787, loss 0.114289, acc 0.96875, learning_rate 0.00024621\n","2023-06-27T18:10:58.107973: step 4788, loss 0.080775, acc 0.96875, learning_rate 0.00024611\n","2023-06-27T18:10:58.344013: step 4789, loss 0.0271827, acc 0.96875, learning_rate 0.00024601\n","2023-06-27T18:10:58.557095: step 4790, loss 0.013337, acc 1, learning_rate 0.00024591\n","2023-06-27T18:10:58.759692: step 4791, loss 0.032739, acc 1, learning_rate 0.000245809\n","2023-06-27T18:10:58.973916: step 4792, loss 0.013006, acc 1, learning_rate 0.00024571\n","2023-06-27T18:10:59.181789: step 4793, loss 0.00298518, acc 1, learning_rate 0.00024561\n","2023-06-27T18:10:59.398445: step 4794, loss 0.0122805, acc 1, learning_rate 0.00024551\n","2023-06-27T18:10:59.620438: step 4795, loss 0.0427259, acc 0.96875, learning_rate 0.00024541\n","2023-06-27T18:10:59.847248: step 4796, loss 0.0120883, acc 1, learning_rate 0.00024531\n","2023-06-27T18:11:00.038569: step 4797, loss 0.0631046, acc 0.96875, learning_rate 0.000245211\n","2023-06-27T18:11:00.227775: step 4798, loss 0.110176, acc 0.9375, learning_rate 0.000245111\n","2023-06-27T18:11:00.429578: step 4799, loss 0.04147, acc 1, learning_rate 0.000245012\n","\n","Evaluation:\n","2023-06-27T18:11:01.698242: step 4800, loss 0.799934, acc 0.801458\n","\n","Saved model checkpoint to /content/gdrive/MyDrive/lightweighted-cnn/train/runs/1687888658/checkpoints/model-4800\n","\n","2023-06-27T18:11:02.038747: step 4800, loss 0.036676, acc 1, learning_rate 0.000244912\n","2023-06-27T18:11:02.209848: step 4801, loss 0.0191643, acc 1, learning_rate 0.000244813\n","2023-06-27T18:11:02.406315: step 4802, loss 0.0654363, acc 0.96875, learning_rate 0.000244713\n","2023-06-27T18:11:02.591704: step 4803, loss 0.0176349, acc 1, learning_rate 0.000244614\n","2023-06-27T18:11:02.785856: step 4804, loss 0.0809861, acc 0.96875, learning_rate 0.000244515\n","2023-06-27T18:11:02.992755: step 4805, loss 0.0096575, acc 1, learning_rate 0.000244416\n","2023-06-27T18:11:03.184565: step 4806, loss 0.0723888, acc 0.96875, learning_rate 0.000244317\n","2023-06-27T18:11:03.376992: step 4807, loss 0.00992179, acc 1, learning_rate 0.000244218\n","2023-06-27T18:11:03.584199: step 4808, loss 0.124514, acc 0.96875, learning_rate 0.000244119\n","2023-06-27T18:11:03.750855: step 4809, loss 0.0304892, acc 1, learning_rate 0.00024402\n","2023-06-27T18:11:03.938070: step 4810, loss 0.0390525, acc 0.96875, learning_rate 0.000243921\n","2023-06-27T18:11:04.137680: step 4811, loss 0.0415921, acc 1, learning_rate 0.000243823\n","2023-06-27T18:11:04.348563: step 4812, loss 0.0163526, acc 1, learning_rate 0.000243724\n","2023-06-27T18:11:04.565373: step 4813, loss 0.0110129, acc 1, learning_rate 0.000243626\n","2023-06-27T18:11:04.780625: step 4814, loss 0.0196579, acc 1, learning_rate 0.000243527\n","2023-06-27T18:11:04.984333: step 4815, loss 0.17558, acc 0.9375, learning_rate 0.000243429\n","2023-06-27T18:11:05.165147: step 4816, loss 0.00760639, acc 1, learning_rate 0.00024333\n","2023-06-27T18:11:05.369759: step 4817, loss 0.0693726, acc 0.96875, learning_rate 0.000243232\n","2023-06-27T18:11:05.563213: step 4818, loss 0.167597, acc 0.90625, learning_rate 0.000243134\n","2023-06-27T18:11:05.732471: step 4819, loss 0.0681821, acc 0.96875, learning_rate 0.000243036\n","2023-06-27T18:11:05.943374: step 4820, loss 0.0195702, acc 1, learning_rate 0.000242938\n","2023-06-27T18:11:06.136846: step 4821, loss 0.037148, acc 1, learning_rate 0.00024284\n","2023-06-27T18:11:06.355492: step 4822, loss 0.014755, acc 1, learning_rate 0.000242742\n","2023-06-27T18:11:06.580888: step 4823, loss 0.0759859, acc 0.9375, learning_rate 0.000242644\n","2023-06-27T18:11:06.783312: step 4824, loss 0.10377, acc 0.9375, learning_rate 0.000242546\n","2023-06-27T18:11:06.979319: step 4825, loss 0.0860126, acc 0.96875, learning_rate 0.000242448\n","2023-06-27T18:11:07.117085: step 4826, loss 0.0130023, acc 1, learning_rate 0.000242351\n","2023-06-27T18:11:07.242953: step 4827, loss 0.0264167, acc 1, learning_rate 0.000242253\n","2023-06-27T18:11:07.361170: step 4828, loss 0.0131626, acc 1, learning_rate 0.000242155\n","2023-06-27T18:11:07.481345: step 4829, loss 0.0203289, acc 1, learning_rate 0.000242058\n","2023-06-27T18:11:07.614285: step 4830, loss 0.0457028, acc 0.96875, learning_rate 0.00024196\n","2023-06-27T18:11:07.741187: step 4831, loss 0.0172004, acc 1, learning_rate 0.000241863\n","2023-06-27T18:11:07.866806: step 4832, loss 0.0833315, acc 0.96875, learning_rate 0.000241766\n","2023-06-27T18:11:07.981009: step 4833, loss 0.0174124, acc 1, learning_rate 0.000241669\n","2023-06-27T18:11:08.101677: step 4834, loss 0.127766, acc 0.9375, learning_rate 0.000241571\n","2023-06-27T18:11:08.239614: step 4835, loss 0.0147938, acc 1, learning_rate 0.000241474\n","2023-06-27T18:11:08.357594: step 4836, loss 0.0456312, acc 0.96875, learning_rate 0.000241377\n","2023-06-27T18:11:08.474379: step 4837, loss 0.0470795, acc 0.96875, learning_rate 0.00024128\n","2023-06-27T18:11:08.592876: step 4838, loss 0.0187284, acc 1, learning_rate 0.000241184\n","2023-06-27T18:11:08.719365: step 4839, loss 0.0367198, acc 1, learning_rate 0.000241087\n","2023-06-27T18:11:08.840703: step 4840, loss 0.0456822, acc 1, learning_rate 0.00024099\n","2023-06-27T18:11:08.953197: step 4841, loss 0.0399612, acc 1, learning_rate 0.000240893\n","2023-06-27T18:11:09.066766: step 4842, loss 0.0140548, acc 1, learning_rate 0.000240797\n","2023-06-27T18:11:09.179284: step 4843, loss 0.0878182, acc 0.96875, learning_rate 0.0002407\n","2023-06-27T18:11:09.296215: step 4844, loss 0.111617, acc 0.9375, learning_rate 0.000240604\n","2023-06-27T18:11:09.413697: step 4845, loss 0.0293392, acc 1, learning_rate 0.000240507\n","2023-06-27T18:11:09.520722: step 4846, loss 0.0581387, acc 0.96875, learning_rate 0.000240411\n","2023-06-27T18:11:09.658489: step 4847, loss 0.0133041, acc 1, learning_rate 0.000240315\n","2023-06-27T18:11:09.795690: step 4848, loss 0.0611394, acc 0.96875, learning_rate 0.000240218\n","2023-06-27T18:11:09.908019: step 4849, loss 0.0585921, acc 0.96875, learning_rate 0.000240122\n","2023-06-27T18:11:10.023860: step 4850, loss 0.00281223, acc 1, learning_rate 0.000240026\n","2023-06-27T18:11:10.163393: step 4851, loss 0.153901, acc 0.90625, learning_rate 0.00023993\n","2023-06-27T18:11:10.286218: step 4852, loss 0.102445, acc 0.96875, learning_rate 0.000239834\n","2023-06-27T18:11:10.407445: step 4853, loss 0.0171215, acc 1, learning_rate 0.000239738\n","2023-06-27T18:11:10.562661: step 4854, loss 0.0419625, acc 1, learning_rate 0.000239642\n","2023-06-27T18:11:10.685913: step 4855, loss 0.0141475, acc 1, learning_rate 0.000239547\n","2023-06-27T18:11:10.819050: step 4856, loss 0.125916, acc 0.96875, learning_rate 0.000239451\n","2023-06-27T18:11:10.947809: step 4857, loss 0.120122, acc 0.96875, learning_rate 0.000239355\n","2023-06-27T18:11:11.053064: step 4858, loss 0.0231872, acc 1, learning_rate 0.00023926\n","2023-06-27T18:11:11.183395: step 4859, loss 0.0539716, acc 0.96875, learning_rate 0.000239164\n","2023-06-27T18:11:11.301525: step 4860, loss 0.0400407, acc 1, learning_rate 0.000239069\n","2023-06-27T18:11:11.417128: step 4861, loss 0.00940935, acc 1, learning_rate 0.000238974\n","2023-06-27T18:11:11.545686: step 4862, loss 0.0240184, acc 1, learning_rate 0.000238878\n","2023-06-27T18:11:11.659767: step 4863, loss 0.0225764, acc 1, learning_rate 0.000238783\n","2023-06-27T18:11:11.799026: step 4864, loss 0.0314371, acc 1, learning_rate 0.000238688\n","2023-06-27T18:11:11.923616: step 4865, loss 0.0657552, acc 0.96875, learning_rate 0.000238593\n","2023-06-27T18:11:12.041658: step 4866, loss 0.0238366, acc 1, learning_rate 0.000238498\n","2023-06-27T18:11:12.164770: step 4867, loss 0.00943354, acc 1, learning_rate 0.000238403\n","2023-06-27T18:11:12.281922: step 4868, loss 0.0419509, acc 0.96875, learning_rate 0.000238308\n","2023-06-27T18:11:12.401642: step 4869, loss 0.12825, acc 0.96875, learning_rate 0.000238213\n","2023-06-27T18:11:12.518919: step 4870, loss 0.0253331, acc 1, learning_rate 0.000238118\n","2023-06-27T18:11:12.633345: step 4871, loss 0.110732, acc 0.96875, learning_rate 0.000238024\n","2023-06-27T18:11:12.747720: step 4872, loss 0.0270815, acc 1, learning_rate 0.000237929\n","2023-06-27T18:11:12.874875: step 4873, loss 0.0672814, acc 0.96875, learning_rate 0.000237834\n","2023-06-27T18:11:13.004634: step 4874, loss 0.0234705, acc 1, learning_rate 0.00023774\n","2023-06-27T18:11:13.117075: step 4875, loss 0.164444, acc 0.9375, learning_rate 0.000237645\n","2023-06-27T18:11:13.243018: step 4876, loss 0.00725514, acc 1, learning_rate 0.000237551\n","2023-06-27T18:11:13.359794: step 4877, loss 0.0258657, acc 1, learning_rate 0.000237457\n","2023-06-27T18:11:13.489373: step 4878, loss 0.00194427, acc 1, learning_rate 0.000237362\n","2023-06-27T18:11:13.598705: step 4879, loss 0.0637877, acc 0.96875, learning_rate 0.000237268\n","2023-06-27T18:11:13.745620: step 4880, loss 0.0462341, acc 0.96875, learning_rate 0.000237174\n","2023-06-27T18:11:13.891376: step 4881, loss 0.0782562, acc 0.96875, learning_rate 0.00023708\n","2023-06-27T18:11:14.004996: step 4882, loss 0.0139522, acc 1, learning_rate 0.000236986\n","2023-06-27T18:11:14.119267: step 4883, loss 0.155534, acc 0.9375, learning_rate 0.000236892\n","2023-06-27T18:11:14.237619: step 4884, loss 0.00485639, acc 1, learning_rate 0.000236798\n","2023-06-27T18:11:14.355551: step 4885, loss 0.163557, acc 0.96875, learning_rate 0.000236704\n","2023-06-27T18:11:14.490004: step 4886, loss 0.0861273, acc 0.9375, learning_rate 0.000236611\n","2023-06-27T18:11:14.616389: step 4887, loss 0.0281739, acc 1, learning_rate 0.000236517\n","2023-06-27T18:11:14.749917: step 4888, loss 0.150245, acc 0.96875, learning_rate 0.000236423\n","2023-06-27T18:11:14.894407: step 4889, loss 0.144014, acc 0.9375, learning_rate 0.00023633\n","2023-06-27T18:11:15.025591: step 4890, loss 0.111773, acc 0.9375, learning_rate 0.000236236\n","2023-06-27T18:11:15.144428: step 4891, loss 0.0297675, acc 1, learning_rate 0.000236143\n","2023-06-27T18:11:15.260650: step 4892, loss 0.0867505, acc 0.96875, learning_rate 0.00023605\n","2023-06-27T18:11:15.383480: step 4893, loss 0.0205436, acc 1, learning_rate 0.000235956\n","2023-06-27T18:11:15.516686: step 4894, loss 0.00160417, acc 1, learning_rate 0.000235863\n","2023-06-27T18:11:15.636159: step 4895, loss 0.0425667, acc 0.96875, learning_rate 0.00023577\n","2023-06-27T18:11:15.771733: step 4896, loss 0.0974277, acc 0.9375, learning_rate 0.000235677\n","2023-06-27T18:11:15.908165: step 4897, loss 0.0382242, acc 0.96875, learning_rate 0.000235584\n","2023-06-27T18:11:16.031036: step 4898, loss 0.0353137, acc 1, learning_rate 0.000235491\n","2023-06-27T18:11:16.145373: step 4899, loss 0.0220309, acc 1, learning_rate 0.000235398\n","\n","Evaluation:\n","2023-06-27T18:11:16.908020: step 4900, loss 0.805348, acc 0.801458\n","\n","Saved model checkpoint to /content/gdrive/MyDrive/lightweighted-cnn/train/runs/1687888658/checkpoints/model-4900\n","\n","2023-06-27T18:11:17.236823: step 4900, loss 0.0209975, acc 1, learning_rate 0.000235305\n","2023-06-27T18:11:17.414943: step 4901, loss 0.0144467, acc 1, learning_rate 0.000235212\n","2023-06-27T18:11:17.639561: step 4902, loss 0.110811, acc 0.9375, learning_rate 0.000235119\n","2023-06-27T18:11:17.840645: step 4903, loss 0.0245808, acc 1, learning_rate 0.000235027\n","2023-06-27T18:11:18.054823: step 4904, loss 0.0782749, acc 0.96875, learning_rate 0.000234934\n","2023-06-27T18:11:18.246330: step 4905, loss 0.0386109, acc 0.96875, learning_rate 0.000234842\n","2023-06-27T18:11:18.447902: step 4906, loss 0.068236, acc 0.96875, learning_rate 0.000234749\n","2023-06-27T18:11:18.667086: step 4907, loss 0.0301685, acc 1, learning_rate 0.000234657\n","2023-06-27T18:11:18.873926: step 4908, loss 0.0508998, acc 1, learning_rate 0.000234565\n","2023-06-27T18:11:19.079124: step 4909, loss 0.0424373, acc 1, learning_rate 0.000234472\n","2023-06-27T18:11:19.285469: step 4910, loss 0.109449, acc 0.90625, learning_rate 0.00023438\n","2023-06-27T18:11:19.494504: step 4911, loss 0.0188159, acc 1, learning_rate 0.000234288\n","2023-06-27T18:11:19.709195: step 4912, loss 0.124322, acc 0.9375, learning_rate 0.000234196\n","2023-06-27T18:11:19.911008: step 4913, loss 0.018075, acc 1, learning_rate 0.000234104\n","2023-06-27T18:11:20.111962: step 4914, loss 0.00607528, acc 1, learning_rate 0.000234012\n","2023-06-27T18:11:20.317086: step 4915, loss 0.0481552, acc 0.96875, learning_rate 0.00023392\n","2023-06-27T18:11:20.537800: step 4916, loss 0.128065, acc 0.96875, learning_rate 0.000233828\n","2023-06-27T18:11:20.738331: step 4917, loss 0.0670002, acc 0.96875, learning_rate 0.000233736\n","2023-06-27T18:11:20.924852: step 4918, loss 0.0197162, acc 1, learning_rate 0.000233645\n","2023-06-27T18:11:21.115972: step 4919, loss 0.0549357, acc 0.96875, learning_rate 0.000233553\n","2023-06-27T18:11:21.291690: step 4920, loss 0.0502605, acc 1, learning_rate 0.000233461\n","2023-06-27T18:11:21.478737: step 4921, loss 0.00955736, acc 1, learning_rate 0.00023337\n","2023-06-27T18:11:21.706295: step 4922, loss 0.0879591, acc 0.9375, learning_rate 0.000233278\n","2023-06-27T18:11:21.911566: step 4923, loss 0.16697, acc 0.9375, learning_rate 0.000233187\n","2023-06-27T18:11:22.135436: step 4924, loss 0.0225079, acc 1, learning_rate 0.000233096\n","2023-06-27T18:11:22.329550: step 4925, loss 0.0867139, acc 0.9375, learning_rate 0.000233004\n","2023-06-27T18:11:22.533296: step 4926, loss 0.0323191, acc 1, learning_rate 0.000232913\n","2023-06-27T18:11:22.753794: step 4927, loss 0.0148331, acc 1, learning_rate 0.000232822\n","2023-06-27T18:11:22.920196: step 4928, loss 0.0789429, acc 0.96875, learning_rate 0.000232731\n","2023-06-27T18:11:23.102278: step 4929, loss 0.00440626, acc 1, learning_rate 0.00023264\n","2023-06-27T18:11:23.273286: step 4930, loss 0.00366867, acc 1, learning_rate 0.000232549\n","2023-06-27T18:11:23.444950: step 4931, loss 0.0203891, acc 1, learning_rate 0.000232458\n","2023-06-27T18:11:23.642724: step 4932, loss 0.0205118, acc 1, learning_rate 0.000232367\n","2023-06-27T18:11:23.825298: step 4933, loss 0.0562017, acc 0.96875, learning_rate 0.000232277\n","2023-06-27T18:11:24.003424: step 4934, loss 0.0313521, acc 1, learning_rate 0.000232186\n","2023-06-27T18:11:24.208541: step 4935, loss 0.00389596, acc 1, learning_rate 0.000232095\n","2023-06-27T18:11:24.390955: step 4936, loss 0.0342634, acc 1, learning_rate 0.000232005\n","2023-06-27T18:11:24.647247: step 4937, loss 0.0436821, acc 0.96875, learning_rate 0.000231914\n","2023-06-27T18:11:24.863050: step 4938, loss 0.0108534, acc 1, learning_rate 0.000231824\n","2023-06-27T18:11:25.087748: step 4939, loss 0.0559373, acc 0.96875, learning_rate 0.000231733\n","2023-06-27T18:11:25.313654: step 4940, loss 0.0391812, acc 1, learning_rate 0.000231643\n","2023-06-27T18:11:25.545768: step 4941, loss 0.0342913, acc 1, learning_rate 0.000231553\n","2023-06-27T18:11:25.816978: step 4942, loss 0.11282, acc 0.9375, learning_rate 0.000231462\n","2023-06-27T18:11:26.000951: step 4943, loss 0.281096, acc 0.9375, learning_rate 0.000231372\n","2023-06-27T18:11:26.250771: step 4944, loss 0.219659, acc 0.96875, learning_rate 0.000231282\n","2023-06-27T18:11:26.461320: step 4945, loss 0.0270404, acc 1, learning_rate 0.000231192\n","2023-06-27T18:11:26.703703: step 4946, loss 0.0249681, acc 1, learning_rate 0.000231102\n","2023-06-27T18:11:26.917207: step 4947, loss 0.0304689, acc 1, learning_rate 0.000231012\n","2023-06-27T18:11:27.152676: step 4948, loss 0.0164061, acc 1, learning_rate 0.000230922\n","2023-06-27T18:11:27.398993: step 4949, loss 0.0631666, acc 1, learning_rate 0.000230833\n","2023-06-27T18:11:27.649938: step 4950, loss 0.0222753, acc 1, learning_rate 0.000230743\n","2023-06-27T18:11:27.884674: step 4951, loss 0.0343014, acc 1, learning_rate 0.000230653\n","2023-06-27T18:11:28.154600: step 4952, loss 0.102579, acc 0.9375, learning_rate 0.000230564\n","2023-06-27T18:11:28.396034: step 4953, loss 0.0662445, acc 1, learning_rate 0.000230474\n","2023-06-27T18:11:28.604423: step 4954, loss 0.0396329, acc 1, learning_rate 0.000230385\n","2023-06-27T18:11:28.818423: step 4955, loss 0.0322231, acc 1, learning_rate 0.000230295\n","2023-06-27T18:11:29.077186: step 4956, loss 0.0388437, acc 0.96875, learning_rate 0.000230206\n","2023-06-27T18:11:29.298064: step 4957, loss 0.0277297, acc 1, learning_rate 0.000230117\n","2023-06-27T18:11:29.522311: step 4958, loss 0.0118783, acc 1, learning_rate 0.000230027\n","2023-06-27T18:11:29.763273: step 4959, loss 0.111445, acc 0.9375, learning_rate 0.000229938\n","2023-06-27T18:11:29.977742: step 4960, loss 0.0200564, acc 1, learning_rate 0.000229849\n","2023-06-27T18:11:30.188213: step 4961, loss 0.0323917, acc 0.96875, learning_rate 0.00022976\n","2023-06-27T18:11:30.410128: step 4962, loss 0.0845354, acc 0.96875, learning_rate 0.000229671\n","2023-06-27T18:11:30.646080: step 4963, loss 0.128522, acc 0.9375, learning_rate 0.000229582\n","2023-06-27T18:11:30.851333: step 4964, loss 0.0428691, acc 1, learning_rate 0.000229493\n","2023-06-27T18:11:31.068967: step 4965, loss 0.0107122, acc 1, learning_rate 0.000229405\n","2023-06-27T18:11:31.250311: step 4966, loss 0.029808, acc 1, learning_rate 0.000229316\n","2023-06-27T18:11:31.446272: step 4967, loss 0.0068778, acc 1, learning_rate 0.000229227\n","2023-06-27T18:11:31.645677: step 4968, loss 0.0767402, acc 0.96875, learning_rate 0.000229139\n","2023-06-27T18:11:31.847024: step 4969, loss 0.0255048, acc 1, learning_rate 0.00022905\n","2023-06-27T18:11:32.029420: step 4970, loss 0.100639, acc 0.96875, learning_rate 0.000228962\n","2023-06-27T18:11:32.237470: step 4971, loss 0.349492, acc 0.875, learning_rate 0.000228873\n","2023-06-27T18:11:32.456878: step 4972, loss 0.0820662, acc 0.96875, learning_rate 0.000228785\n","2023-06-27T18:11:32.657221: step 4973, loss 0.0585892, acc 0.96875, learning_rate 0.000228696\n","2023-06-27T18:11:32.835330: step 4974, loss 0.0959049, acc 0.9375, learning_rate 0.000228608\n","2023-06-27T18:11:33.040769: step 4975, loss 0.126062, acc 0.9375, learning_rate 0.00022852\n","2023-06-27T18:11:33.223079: step 4976, loss 0.0812815, acc 0.96875, learning_rate 0.000228432\n","2023-06-27T18:11:33.411065: step 4977, loss 0.052711, acc 0.96875, learning_rate 0.000228344\n","2023-06-27T18:11:33.597101: step 4978, loss 0.0471629, acc 1, learning_rate 0.000228256\n","2023-06-27T18:11:33.797309: step 4979, loss 0.00549479, acc 1, learning_rate 0.000228168\n","2023-06-27T18:11:34.003070: step 4980, loss 0.091988, acc 0.96875, learning_rate 0.00022808\n","2023-06-27T18:11:34.190929: step 4981, loss 0.0520905, acc 1, learning_rate 0.000227992\n","2023-06-27T18:11:34.392415: step 4982, loss 0.0263218, acc 1, learning_rate 0.000227904\n","2023-06-27T18:11:34.605590: step 4983, loss 0.036382, acc 1, learning_rate 0.000227817\n","2023-06-27T18:11:34.807607: step 4984, loss 0.0723867, acc 0.96875, learning_rate 0.000227729\n","2023-06-27T18:11:34.985348: step 4985, loss 0.0976548, acc 0.96875, learning_rate 0.000227641\n","2023-06-27T18:11:35.185801: step 4986, loss 0.143418, acc 0.9375, learning_rate 0.000227554\n","2023-06-27T18:11:35.375825: step 4987, loss 0.00562085, acc 1, learning_rate 0.000227466\n","2023-06-27T18:11:35.575891: step 4988, loss 0.0726353, acc 0.96875, learning_rate 0.000227379\n","2023-06-27T18:11:35.768758: step 4989, loss 0.0173669, acc 1, learning_rate 0.000227292\n","2023-06-27T18:11:35.977399: step 4990, loss 0.015029, acc 1, learning_rate 0.000227204\n","2023-06-27T18:11:36.162540: step 4991, loss 0.0351326, acc 1, learning_rate 0.000227117\n","2023-06-27T18:11:36.355587: step 4992, loss 0.0113264, acc 1, learning_rate 0.00022703\n","2023-06-27T18:11:36.566684: step 4993, loss 0.109945, acc 0.96875, learning_rate 0.000226943\n","2023-06-27T18:11:36.767899: step 4994, loss 0.0369642, acc 0.96875, learning_rate 0.000226856\n","2023-06-27T18:11:36.971828: step 4995, loss 0.0416828, acc 0.96875, learning_rate 0.000226769\n","2023-06-27T18:11:37.156136: step 4996, loss 0.0474898, acc 1, learning_rate 0.000226682\n","2023-06-27T18:11:37.351937: step 4997, loss 0.0512585, acc 1, learning_rate 0.000226595\n","2023-06-27T18:11:37.531005: step 4998, loss 0.0310676, acc 1, learning_rate 0.000226508\n","2023-06-27T18:11:37.655215: step 4999, loss 0.14016, acc 0.9375, learning_rate 0.000226421\n","\n","Evaluation:\n","2023-06-27T18:11:38.397232: step 5000, loss 0.80966, acc 0.798242\n","\n","Saved model checkpoint to /content/gdrive/MyDrive/lightweighted-cnn/train/runs/1687888658/checkpoints/model-5000\n","\n","2023-06-27T18:11:38.615718: step 5000, loss 0.0907828, acc 0.96875, learning_rate 0.000226335\n","2023-06-27T18:11:38.763095: step 5001, loss 0.149049, acc 0.90625, learning_rate 0.000226248\n","2023-06-27T18:11:38.902551: step 5002, loss 0.0719038, acc 0.96875, learning_rate 0.000226162\n","2023-06-27T18:11:39.031084: step 5003, loss 0.0184705, acc 1, learning_rate 0.000226075\n","2023-06-27T18:11:39.154849: step 5004, loss 0.0151131, acc 1, learning_rate 0.000225989\n","2023-06-27T18:11:39.272586: step 5005, loss 0.0682018, acc 0.96875, learning_rate 0.000225902\n","2023-06-27T18:11:39.398114: step 5006, loss 0.143108, acc 0.96875, learning_rate 0.000225816\n","2023-06-27T18:11:39.513812: step 5007, loss 0.131533, acc 0.96875, learning_rate 0.00022573\n","2023-06-27T18:11:39.632652: step 5008, loss 0.0260114, acc 1, learning_rate 0.000225643\n","2023-06-27T18:11:39.767466: step 5009, loss 0.102926, acc 0.96875, learning_rate 0.000225557\n","2023-06-27T18:11:39.893762: step 5010, loss 0.0321025, acc 1, learning_rate 0.000225471\n","2023-06-27T18:11:40.020461: step 5011, loss 0.0933196, acc 0.96875, learning_rate 0.000225385\n","2023-06-27T18:11:40.148074: step 5012, loss 0.0279145, acc 1, learning_rate 0.000225299\n","2023-06-27T18:11:40.266094: step 5013, loss 0.0939942, acc 0.9375, learning_rate 0.000225213\n","2023-06-27T18:11:40.383738: step 5014, loss 0.0460344, acc 1, learning_rate 0.000225127\n","2023-06-27T18:11:40.491238: step 5015, loss 0.057054, acc 0.96875, learning_rate 0.000225042\n","2023-06-27T18:11:40.613793: step 5016, loss 0.144439, acc 0.90625, learning_rate 0.000224956\n","2023-06-27T18:11:40.741598: step 5017, loss 0.0700622, acc 0.96875, learning_rate 0.00022487\n","2023-06-27T18:11:40.864916: step 5018, loss 0.0615408, acc 0.96875, learning_rate 0.000224784\n","2023-06-27T18:11:40.998900: step 5019, loss 0.0391334, acc 0.96875, learning_rate 0.000224699\n","2023-06-27T18:11:41.118648: step 5020, loss 0.208074, acc 0.875, learning_rate 0.000224613\n","2023-06-27T18:11:41.281857: step 5021, loss 0.0340123, acc 1, learning_rate 0.000224528\n","2023-06-27T18:11:41.473750: step 5022, loss 0.077427, acc 0.96875, learning_rate 0.000224443\n","2023-06-27T18:11:41.674829: step 5023, loss 0.0106057, acc 1, learning_rate 0.000224357\n","2023-06-27T18:11:41.877401: step 5024, loss 0.117187, acc 0.96875, learning_rate 0.000224272\n","2023-06-27T18:11:42.092466: step 5025, loss 0.00642651, acc 1, learning_rate 0.000224187\n","2023-06-27T18:11:42.300110: step 5026, loss 0.107298, acc 0.9375, learning_rate 0.000224102\n","2023-06-27T18:11:42.517157: step 5027, loss 0.0746683, acc 0.96875, learning_rate 0.000224016\n","2023-06-27T18:11:42.718286: step 5028, loss 0.0431755, acc 1, learning_rate 0.000223931\n","2023-06-27T18:11:42.918733: step 5029, loss 0.040563, acc 1, learning_rate 0.000223846\n","2023-06-27T18:11:43.124314: step 5030, loss 0.0336714, acc 1, learning_rate 0.000223762\n","2023-06-27T18:11:43.332313: step 5031, loss 0.0668244, acc 1, learning_rate 0.000223677\n","2023-06-27T18:11:43.535436: step 5032, loss 0.0814347, acc 0.96875, learning_rate 0.000223592\n","2023-06-27T18:11:43.750034: step 5033, loss 0.0517945, acc 0.96875, learning_rate 0.000223507\n","2023-06-27T18:11:43.977266: step 5034, loss 0.134346, acc 0.9375, learning_rate 0.000223422\n","2023-06-27T18:11:44.185709: step 5035, loss 0.200959, acc 0.9375, learning_rate 0.000223338\n","2023-06-27T18:11:44.398744: step 5036, loss 0.0821314, acc 0.96875, learning_rate 0.000223253\n","2023-06-27T18:11:44.600216: step 5037, loss 0.0675882, acc 1, learning_rate 0.000223169\n","2023-06-27T18:11:44.805994: step 5038, loss 0.0358913, acc 1, learning_rate 0.000223084\n","2023-06-27T18:11:45.005481: step 5039, loss 0.00396481, acc 1, learning_rate 0.000223\n","2023-06-27T18:11:45.223023: step 5040, loss 0.00782057, acc 1, learning_rate 0.000222915\n","2023-06-27T18:11:45.435605: step 5041, loss 0.0216052, acc 1, learning_rate 0.000222831\n","2023-06-27T18:11:45.692154: step 5042, loss 0.00979647, acc 1, learning_rate 0.000222747\n","2023-06-27T18:11:45.900017: step 5043, loss 0.0368997, acc 1, learning_rate 0.000222663\n","2023-06-27T18:11:46.097085: step 5044, loss 0.045693, acc 1, learning_rate 0.000222579\n","2023-06-27T18:11:46.289534: step 5045, loss 0.0906686, acc 0.9375, learning_rate 0.000222495\n","2023-06-27T18:11:46.503560: step 5046, loss 0.0271411, acc 1, learning_rate 0.000222411\n","2023-06-27T18:11:46.703831: step 5047, loss 0.01319, acc 1, learning_rate 0.000222327\n","2023-06-27T18:11:46.897068: step 5048, loss 0.0647439, acc 0.96875, learning_rate 0.000222243\n","2023-06-27T18:11:47.074791: step 5049, loss 0.0304493, acc 1, learning_rate 0.000222159\n","2023-06-27T18:11:47.275533: step 5050, loss 0.0249113, acc 1, learning_rate 0.000222075\n","2023-06-27T18:11:47.474223: step 5051, loss 0.092685, acc 0.9375, learning_rate 0.000221992\n","2023-06-27T18:11:47.679261: step 5052, loss 0.0592759, acc 0.96875, learning_rate 0.000221908\n","2023-06-27T18:11:47.874053: step 5053, loss 0.0271453, acc 1, learning_rate 0.000221824\n","2023-06-27T18:11:48.072711: step 5054, loss 0.116631, acc 0.9375, learning_rate 0.000221741\n","2023-06-27T18:11:48.257493: step 5055, loss 0.19589, acc 0.90625, learning_rate 0.000221657\n","2023-06-27T18:11:48.440362: step 5056, loss 0.0891955, acc 0.96875, learning_rate 0.000221574\n","2023-06-27T18:11:48.640444: step 5057, loss 0.113864, acc 0.9375, learning_rate 0.00022149\n","2023-06-27T18:11:48.834630: step 5058, loss 0.0470042, acc 0.96875, learning_rate 0.000221407\n","2023-06-27T18:11:49.006004: step 5059, loss 0.23109, acc 0.9375, learning_rate 0.000221324\n","2023-06-27T18:11:49.236289: step 5060, loss 0.0260801, acc 1, learning_rate 0.000221241\n","2023-06-27T18:11:49.412805: step 5061, loss 0.0434787, acc 1, learning_rate 0.000221158\n","2023-06-27T18:11:49.591873: step 5062, loss 0.045762, acc 1, learning_rate 0.000221074\n","2023-06-27T18:11:49.782744: step 5063, loss 0.0785846, acc 0.96875, learning_rate 0.000220991\n","2023-06-27T18:11:49.989676: step 5064, loss 0.0284881, acc 1, learning_rate 0.000220909\n","2023-06-27T18:11:50.184760: step 5065, loss 0.193052, acc 0.9375, learning_rate 0.000220826\n","2023-06-27T18:11:50.366446: step 5066, loss 0.0254404, acc 1, learning_rate 0.000220743\n","2023-06-27T18:11:50.583491: step 5067, loss 0.0268445, acc 1, learning_rate 0.00022066\n","2023-06-27T18:11:50.781073: step 5068, loss 0.0662197, acc 0.96875, learning_rate 0.000220577\n","2023-06-27T18:11:50.987088: step 5069, loss 0.0597886, acc 0.96875, learning_rate 0.000220495\n","2023-06-27T18:11:51.178764: step 5070, loss 0.0157824, acc 1, learning_rate 0.000220412\n","2023-06-27T18:11:51.367783: step 5071, loss 0.141863, acc 0.96875, learning_rate 0.000220329\n","2023-06-27T18:11:51.552433: step 5072, loss 0.034066, acc 1, learning_rate 0.000220247\n","2023-06-27T18:11:51.763294: step 5073, loss 0.00953398, acc 1, learning_rate 0.000220164\n","2023-06-27T18:11:51.924355: step 5074, loss 0.143583, acc 0.96875, learning_rate 0.000220082\n","2023-06-27T18:11:52.107433: step 5075, loss 0.181263, acc 0.875, learning_rate 0.00022\n","2023-06-27T18:11:52.243450: step 5076, loss 0.0242995, acc 1, learning_rate 0.000219917\n","2023-06-27T18:11:52.368174: step 5077, loss 0.00957094, acc 1, learning_rate 0.000219835\n","2023-06-27T18:11:52.494585: step 5078, loss 0.06884, acc 0.96875, learning_rate 0.000219753\n","2023-06-27T18:11:52.602246: step 5079, loss 0.0277823, acc 1, learning_rate 0.000219671\n","2023-06-27T18:11:52.711259: step 5080, loss 0.00765393, acc 1, learning_rate 0.000219589\n","2023-06-27T18:11:52.847029: step 5081, loss 0.0568211, acc 0.96875, learning_rate 0.000219507\n","2023-06-27T18:11:52.975353: step 5082, loss 0.0602216, acc 0.96875, learning_rate 0.000219425\n","2023-06-27T18:11:53.111790: step 5083, loss 0.106572, acc 0.96875, learning_rate 0.000219343\n","2023-06-27T18:11:53.240045: step 5084, loss 0.0224452, acc 1, learning_rate 0.000219261\n","2023-06-27T18:11:53.364741: step 5085, loss 0.0162253, acc 1, learning_rate 0.000219179\n","2023-06-27T18:11:53.483235: step 5086, loss 0.0340255, acc 1, learning_rate 0.000219098\n","2023-06-27T18:11:53.615413: step 5087, loss 0.064562, acc 0.96875, learning_rate 0.000219016\n","2023-06-27T18:11:53.737377: step 5088, loss 0.0404745, acc 1, learning_rate 0.000218934\n","2023-06-27T18:11:53.855444: step 5089, loss 0.0104359, acc 1, learning_rate 0.000218853\n","2023-06-27T18:11:53.974873: step 5090, loss 0.160887, acc 0.9375, learning_rate 0.000218771\n","2023-06-27T18:11:54.102946: step 5091, loss 0.0731954, acc 0.96875, learning_rate 0.00021869\n","2023-06-27T18:11:54.222121: step 5092, loss 0.0283932, acc 1, learning_rate 0.000218608\n","2023-06-27T18:11:54.362175: step 5093, loss 0.0991407, acc 0.9375, learning_rate 0.000218527\n","2023-06-27T18:11:54.489077: step 5094, loss 0.054423, acc 0.96875, learning_rate 0.000218446\n","2023-06-27T18:11:54.612239: step 5095, loss 0.0977708, acc 0.96875, learning_rate 0.000218365\n","2023-06-27T18:11:54.727679: step 5096, loss 0.026349, acc 1, learning_rate 0.000218283\n","2023-06-27T18:11:54.841288: step 5097, loss 0.114735, acc 0.9375, learning_rate 0.000218202\n","2023-06-27T18:11:54.969115: step 5098, loss 0.0122001, acc 1, learning_rate 0.000218121\n","2023-06-27T18:11:55.089207: step 5099, loss 0.0481627, acc 1, learning_rate 0.00021804\n","\n","Evaluation:\n","2023-06-27T18:11:55.862943: step 5100, loss 0.804364, acc 0.801887\n","\n","Saved model checkpoint to /content/gdrive/MyDrive/lightweighted-cnn/train/runs/1687888658/checkpoints/model-5100\n","\n","2023-06-27T18:11:56.079796: step 5100, loss 0.0536536, acc 0.96875, learning_rate 0.000217959\n","2023-06-27T18:11:56.222947: step 5101, loss 0.0278286, acc 1, learning_rate 0.000217878\n","2023-06-27T18:11:56.353357: step 5102, loss 0.113314, acc 0.9375, learning_rate 0.000217798\n","2023-06-27T18:11:56.472811: step 5103, loss 0.0232841, acc 1, learning_rate 0.000217717\n","2023-06-27T18:11:56.594817: step 5104, loss 0.0552614, acc 0.96875, learning_rate 0.000217636\n","2023-06-27T18:11:56.704817: step 5105, loss 0.0285701, acc 1, learning_rate 0.000217555\n","2023-06-27T18:11:56.832343: step 5106, loss 0.0607594, acc 0.96875, learning_rate 0.000217475\n","2023-06-27T18:11:56.965678: step 5107, loss 0.027803, acc 1, learning_rate 0.000217394\n","2023-06-27T18:11:57.086176: step 5108, loss 0.0490899, acc 0.96875, learning_rate 0.000217314\n","2023-06-27T18:11:57.193194: step 5109, loss 0.0533911, acc 0.96875, learning_rate 0.000217233\n","2023-06-27T18:11:57.317548: step 5110, loss 0.0216768, acc 1, learning_rate 0.000217153\n","2023-06-27T18:11:57.438208: step 5111, loss 0.0823241, acc 0.96875, learning_rate 0.000217073\n","2023-06-27T18:11:57.559183: step 5112, loss 0.0299437, acc 1, learning_rate 0.000216992\n","2023-06-27T18:11:57.689075: step 5113, loss 0.179668, acc 0.875, learning_rate 0.000216912\n","2023-06-27T18:11:57.806388: step 5114, loss 0.226848, acc 0.96875, learning_rate 0.000216832\n","2023-06-27T18:11:57.934905: step 5115, loss 0.0672963, acc 1, learning_rate 0.000216752\n","2023-06-27T18:11:58.052775: step 5116, loss 0.0554934, acc 1, learning_rate 0.000216672\n","2023-06-27T18:11:58.162640: step 5117, loss 0.0230375, acc 1, learning_rate 0.000216592\n","2023-06-27T18:11:58.289624: step 5118, loss 0.00333447, acc 1, learning_rate 0.000216512\n","2023-06-27T18:11:58.415171: step 5119, loss 0.00334035, acc 1, learning_rate 0.000216432\n","2023-06-27T18:11:58.549428: step 5120, loss 0.0191422, acc 1, learning_rate 0.000216352\n","2023-06-27T18:11:58.660655: step 5121, loss 0.186984, acc 0.96875, learning_rate 0.000216272\n","2023-06-27T18:11:58.783027: step 5122, loss 0.0251162, acc 1, learning_rate 0.000216193\n","2023-06-27T18:11:58.903887: step 5123, loss 0.00741984, acc 1, learning_rate 0.000216113\n","2023-06-27T18:11:59.027459: step 5124, loss 0.0471087, acc 1, learning_rate 0.000216033\n","2023-06-27T18:11:59.157249: step 5125, loss 0.0460642, acc 0.96875, learning_rate 0.000215954\n","2023-06-27T18:11:59.274862: step 5126, loss 0.0465515, acc 1, learning_rate 0.000215874\n","2023-06-27T18:11:59.385499: step 5127, loss 0.0668708, acc 0.96875, learning_rate 0.000215795\n","2023-06-27T18:11:59.510348: step 5128, loss 0.0521543, acc 0.96875, learning_rate 0.000215715\n","2023-06-27T18:11:59.638084: step 5129, loss 0.0557498, acc 0.96875, learning_rate 0.000215636\n","2023-06-27T18:11:59.761853: step 5130, loss 0.0857676, acc 0.96875, learning_rate 0.000215557\n","2023-06-27T18:11:59.886044: step 5131, loss 0.0506436, acc 1, learning_rate 0.000215477\n","2023-06-27T18:12:00.002365: step 5132, loss 0.018751, acc 1, learning_rate 0.000215398\n","2023-06-27T18:12:00.122423: step 5133, loss 0.0464091, acc 1, learning_rate 0.000215319\n","2023-06-27T18:12:00.252003: step 5134, loss 0.138865, acc 0.96875, learning_rate 0.00021524\n","2023-06-27T18:12:00.373421: step 5135, loss 0.152105, acc 0.9375, learning_rate 0.000215161\n","2023-06-27T18:12:00.510317: step 5136, loss 0.0193369, acc 1, learning_rate 0.000215082\n","2023-06-27T18:12:00.644796: step 5137, loss 0.103924, acc 0.96875, learning_rate 0.000215003\n","2023-06-27T18:12:00.767927: step 5138, loss 0.0148717, acc 1, learning_rate 0.000214924\n","2023-06-27T18:12:00.885487: step 5139, loss 0.116333, acc 0.96875, learning_rate 0.000214845\n","2023-06-27T18:12:01.017659: step 5140, loss 0.0948781, acc 0.96875, learning_rate 0.000214767\n","2023-06-27T18:12:01.135836: step 5141, loss 0.0102028, acc 1, learning_rate 0.000214688\n","2023-06-27T18:12:01.255242: step 5142, loss 0.0834782, acc 0.9375, learning_rate 0.000214609\n","2023-06-27T18:12:01.378565: step 5143, loss 0.0645382, acc 0.96875, learning_rate 0.000214531\n","2023-06-27T18:12:01.506502: step 5144, loss 0.0239232, acc 1, learning_rate 0.000214452\n","2023-06-27T18:12:01.638018: step 5145, loss 0.107985, acc 0.9375, learning_rate 0.000214374\n","2023-06-27T18:12:01.751172: step 5146, loss 0.0254042, acc 1, learning_rate 0.000214295\n","2023-06-27T18:12:01.884708: step 5147, loss 0.0338922, acc 1, learning_rate 0.000214217\n","2023-06-27T18:12:01.995436: step 5148, loss 0.0193447, acc 1, learning_rate 0.000214139\n","2023-06-27T18:12:02.125102: step 5149, loss 0.0127956, acc 1, learning_rate 0.00021406\n","2023-06-27T18:12:02.310116: step 5150, loss 0.0283612, acc 1, learning_rate 0.000213982\n","2023-06-27T18:12:02.531881: step 5151, loss 0.0608397, acc 0.96875, learning_rate 0.000213904\n","2023-06-27T18:12:02.738501: step 5152, loss 0.0137391, acc 1, learning_rate 0.000213826\n","2023-06-27T18:12:02.946563: step 5153, loss 0.0242405, acc 1, learning_rate 0.000213748\n","2023-06-27T18:12:03.146970: step 5154, loss 0.147223, acc 0.9375, learning_rate 0.00021367\n","2023-06-27T18:12:03.366283: step 5155, loss 0.0899912, acc 0.96875, learning_rate 0.000213592\n","2023-06-27T18:12:03.573466: step 5156, loss 0.02537, acc 1, learning_rate 0.000213514\n","2023-06-27T18:12:03.785793: step 5157, loss 0.135603, acc 0.96875, learning_rate 0.000213436\n","2023-06-27T18:12:03.985157: step 5158, loss 0.045232, acc 1, learning_rate 0.000213358\n","2023-06-27T18:12:04.181327: step 5159, loss 0.00748242, acc 1, learning_rate 0.000213281\n","2023-06-27T18:12:04.404072: step 5160, loss 0.0963033, acc 0.96875, learning_rate 0.000213203\n","2023-06-27T18:12:04.623703: step 5161, loss 0.065079, acc 0.96875, learning_rate 0.000213125\n","2023-06-27T18:12:04.848090: step 5162, loss 0.228168, acc 0.90625, learning_rate 0.000213048\n","2023-06-27T18:12:05.046617: step 5163, loss 0.0511331, acc 0.96875, learning_rate 0.00021297\n","2023-06-27T18:12:05.240696: step 5164, loss 0.0371202, acc 1, learning_rate 0.000212893\n","2023-06-27T18:12:05.432968: step 5165, loss 0.0379698, acc 1, learning_rate 0.000212815\n","2023-06-27T18:12:05.696599: step 5166, loss 0.109975, acc 0.96875, learning_rate 0.000212738\n","2023-06-27T18:12:05.911324: step 5167, loss 0.114711, acc 0.9375, learning_rate 0.000212661\n","2023-06-27T18:12:06.114448: step 5168, loss 0.0323561, acc 1, learning_rate 0.000212583\n","2023-06-27T18:12:06.310119: step 5169, loss 0.0102509, acc 1, learning_rate 0.000212506\n","2023-06-27T18:12:06.499109: step 5170, loss 0.0443276, acc 0.96875, learning_rate 0.000212429\n","2023-06-27T18:12:06.684433: step 5171, loss 0.0969185, acc 0.9375, learning_rate 0.000212352\n","2023-06-27T18:12:06.869113: step 5172, loss 0.0829034, acc 0.96875, learning_rate 0.000212275\n","2023-06-27T18:12:07.069655: step 5173, loss 0.0315196, acc 1, learning_rate 0.000212198\n","2023-06-27T18:12:07.275500: step 5174, loss 0.0235456, acc 1, learning_rate 0.000212121\n","2023-06-27T18:12:07.455235: step 5175, loss 0.174828, acc 0.9375, learning_rate 0.000212044\n","2023-06-27T18:12:07.629020: step 5176, loss 0.13004, acc 0.9375, learning_rate 0.000211967\n","2023-06-27T18:12:07.814493: step 5177, loss 0.00685892, acc 1, learning_rate 0.00021189\n","2023-06-27T18:12:08.010774: step 5178, loss 0.0101177, acc 1, learning_rate 0.000211814\n","2023-06-27T18:12:08.195759: step 5179, loss 0.0765378, acc 0.96875, learning_rate 0.000211737\n","2023-06-27T18:12:08.379273: step 5180, loss 0.055731, acc 1, learning_rate 0.00021166\n","2023-06-27T18:12:08.565289: step 5181, loss 0.00380907, acc 1, learning_rate 0.000211584\n","2023-06-27T18:12:08.758233: step 5182, loss 0.0109124, acc 1, learning_rate 0.000211507\n","2023-06-27T18:12:08.961436: step 5183, loss 0.00754916, acc 1, learning_rate 0.000211431\n","2023-06-27T18:12:09.179383: step 5184, loss 0.0212393, acc 1, learning_rate 0.000211355\n","2023-06-27T18:12:09.387507: step 5185, loss 0.0175247, acc 1, learning_rate 0.000211278\n","2023-06-27T18:12:09.571725: step 5186, loss 0.132773, acc 0.96875, learning_rate 0.000211202\n","2023-06-27T18:12:09.784944: step 5187, loss 0.0214389, acc 1, learning_rate 0.000211126\n","2023-06-27T18:12:09.960031: step 5188, loss 0.0569073, acc 1, learning_rate 0.000211049\n","2023-06-27T18:12:10.151236: step 5189, loss 0.0206989, acc 1, learning_rate 0.000210973\n","2023-06-27T18:12:10.345604: step 5190, loss 0.0196844, acc 1, learning_rate 0.000210897\n","2023-06-27T18:12:10.538582: step 5191, loss 0.068298, acc 0.96875, learning_rate 0.000210821\n","2023-06-27T18:12:10.725182: step 5192, loss 0.0501823, acc 0.96875, learning_rate 0.000210745\n","2023-06-27T18:12:10.934077: step 5193, loss 0.0398709, acc 0.96875, learning_rate 0.000210669\n","2023-06-27T18:12:11.115575: step 5194, loss 0.0233238, acc 1, learning_rate 0.000210593\n","2023-06-27T18:12:11.302703: step 5195, loss 0.0441516, acc 1, learning_rate 0.000210517\n","2023-06-27T18:12:11.515241: step 5196, loss 0.00635889, acc 1, learning_rate 0.000210442\n","2023-06-27T18:12:11.707649: step 5197, loss 0.0265216, acc 1, learning_rate 0.000210366\n","2023-06-27T18:12:11.914364: step 5198, loss 0.276812, acc 0.9375, learning_rate 0.00021029\n","2023-06-27T18:12:12.102986: step 5199, loss 0.0524908, acc 1, learning_rate 0.000210215\n","\n","Evaluation:\n","2023-06-27T18:12:13.258989: step 5200, loss 0.811284, acc 0.801672\n","\n","Saved model checkpoint to /content/gdrive/MyDrive/lightweighted-cnn/train/runs/1687888658/checkpoints/model-5200\n","\n","2023-06-27T18:12:13.483294: step 5200, loss 0.11176, acc 0.96875, learning_rate 0.000210139\n","2023-06-27T18:12:13.605963: step 5201, loss 0.0419704, acc 0.96875, learning_rate 0.000210064\n","2023-06-27T18:12:13.736174: step 5202, loss 0.165595, acc 0.96875, learning_rate 0.000209988\n","2023-06-27T18:12:13.853140: step 5203, loss 0.00756342, acc 1, learning_rate 0.000209913\n","2023-06-27T18:12:13.975797: step 5204, loss 0.0332485, acc 1, learning_rate 0.000209837\n","2023-06-27T18:12:14.102444: step 5205, loss 0.0299637, acc 1, learning_rate 0.000209762\n","2023-06-27T18:12:14.232907: step 5206, loss 0.0305317, acc 1, learning_rate 0.000209687\n","2023-06-27T18:12:14.345849: step 5207, loss 0.053742, acc 0.96875, learning_rate 0.000209611\n","2023-06-27T18:12:14.464389: step 5208, loss 0.0254379, acc 1, learning_rate 0.000209536\n","2023-06-27T18:12:14.587900: step 5209, loss 0.0170262, acc 1, learning_rate 0.000209461\n","2023-06-27T18:12:14.705765: step 5210, loss 0.108331, acc 1, learning_rate 0.000209386\n","2023-06-27T18:12:14.830328: step 5211, loss 0.0239142, acc 1, learning_rate 0.000209311\n","2023-06-27T18:12:14.945101: step 5212, loss 0.0337104, acc 1, learning_rate 0.000209236\n","2023-06-27T18:12:15.057769: step 5213, loss 0.124107, acc 0.96875, learning_rate 0.000209161\n","2023-06-27T18:12:15.195695: step 5214, loss 0.0159782, acc 1, learning_rate 0.000209086\n","2023-06-27T18:12:15.304718: step 5215, loss 0.00723621, acc 1, learning_rate 0.000209012\n","2023-06-27T18:12:15.445231: step 5216, loss 0.22756, acc 0.9375, learning_rate 0.000208937\n","2023-06-27T18:12:15.567316: step 5217, loss 0.0246979, acc 1, learning_rate 0.000208862\n","2023-06-27T18:12:15.687149: step 5218, loss 0.117749, acc 0.96875, learning_rate 0.000208787\n","2023-06-27T18:12:15.809776: step 5219, loss 0.00723219, acc 1, learning_rate 0.000208713\n","2023-06-27T18:12:15.931006: step 5220, loss 0.0110537, acc 1, learning_rate 0.000208638\n","2023-06-27T18:12:16.050692: step 5221, loss 0.0514502, acc 1, learning_rate 0.000208564\n","2023-06-27T18:12:16.184390: step 5222, loss 0.0226434, acc 1, learning_rate 0.000208489\n","2023-06-27T18:12:16.307721: step 5223, loss 0.0956746, acc 0.96875, learning_rate 0.000208415\n","2023-06-27T18:12:16.448856: step 5224, loss 0.0524937, acc 1, learning_rate 0.000208341\n","2023-06-27T18:12:16.565570: step 5225, loss 0.062408, acc 0.96875, learning_rate 0.000208266\n","2023-06-27T18:12:16.678905: step 5226, loss 0.0710877, acc 0.96875, learning_rate 0.000208192\n","2023-06-27T18:12:16.807270: step 5227, loss 0.00937698, acc 1, learning_rate 0.000208118\n","2023-06-27T18:12:16.918299: step 5228, loss 0.040144, acc 1, learning_rate 0.000208044\n","2023-06-27T18:12:17.045303: step 5229, loss 0.179428, acc 0.96875, learning_rate 0.00020797\n","2023-06-27T18:12:17.178701: step 5230, loss 0.0316605, acc 1, learning_rate 0.000207896\n","2023-06-27T18:12:17.307779: step 5231, loss 0.059169, acc 0.96875, learning_rate 0.000207822\n","2023-06-27T18:12:17.440441: step 5232, loss 0.0673363, acc 0.96875, learning_rate 0.000207748\n","2023-06-27T18:12:17.552798: step 5233, loss 0.0677834, acc 0.96875, learning_rate 0.000207674\n","2023-06-27T18:12:17.671307: step 5234, loss 0.0758213, acc 0.96875, learning_rate 0.0002076\n","2023-06-27T18:12:17.811686: step 5235, loss 0.0630474, acc 1, learning_rate 0.000207526\n","2023-06-27T18:12:17.924517: step 5236, loss 0.0347591, acc 1, learning_rate 0.000207453\n","2023-06-27T18:12:18.053848: step 5237, loss 0.0345855, acc 1, learning_rate 0.000207379\n","2023-06-27T18:12:18.172135: step 5238, loss 0.0691234, acc 0.96875, learning_rate 0.000207305\n","2023-06-27T18:12:18.289231: step 5239, loss 0.0697761, acc 0.9375, learning_rate 0.000207232\n","2023-06-27T18:12:18.411477: step 5240, loss 0.048345, acc 0.96875, learning_rate 0.000207158\n","2023-06-27T18:12:18.521207: step 5241, loss 0.0234424, acc 1, learning_rate 0.000207085\n","2023-06-27T18:12:18.633817: step 5242, loss 0.00834806, acc 1, learning_rate 0.000207011\n","2023-06-27T18:12:18.758259: step 5243, loss 0.0280487, acc 1, learning_rate 0.000206938\n","2023-06-27T18:12:18.871887: step 5244, loss 0.121521, acc 0.9375, learning_rate 0.000206864\n","2023-06-27T18:12:18.987105: step 5245, loss 0.093476, acc 0.9375, learning_rate 0.000206791\n","2023-06-27T18:12:19.103035: step 5246, loss 0.00861818, acc 1, learning_rate 0.000206718\n","2023-06-27T18:12:19.231837: step 5247, loss 0.168594, acc 0.9375, learning_rate 0.000206645\n","2023-06-27T18:12:19.363568: step 5248, loss 0.0226733, acc 1, learning_rate 0.000206572\n","2023-06-27T18:12:19.475898: step 5249, loss 0.181224, acc 0.9375, learning_rate 0.000206499\n","2023-06-27T18:12:19.602057: step 5250, loss 0.0591382, acc 0.96875, learning_rate 0.000206426\n","2023-06-27T18:12:19.730749: step 5251, loss 0.00765526, acc 1, learning_rate 0.000206353\n","2023-06-27T18:12:19.846292: step 5252, loss 0.0879563, acc 0.96875, learning_rate 0.00020628\n","2023-06-27T18:12:19.983799: step 5253, loss 0.0209001, acc 1, learning_rate 0.000206207\n","2023-06-27T18:12:20.089628: step 5254, loss 0.114177, acc 0.9375, learning_rate 0.000206134\n","2023-06-27T18:12:20.210266: step 5255, loss 0.00130906, acc 1, learning_rate 0.000206061\n","2023-06-27T18:12:20.327215: step 5256, loss 0.0791028, acc 0.9375, learning_rate 0.000205988\n","2023-06-27T18:12:20.444819: step 5257, loss 0.0546486, acc 0.96875, learning_rate 0.000205916\n","2023-06-27T18:12:20.585911: step 5258, loss 0.0330214, acc 1, learning_rate 0.000205843\n","2023-06-27T18:12:20.711368: step 5259, loss 0.029166, acc 1, learning_rate 0.000205771\n","2023-06-27T18:12:20.829888: step 5260, loss 0.0586209, acc 0.96875, learning_rate 0.000205698\n","2023-06-27T18:12:20.952322: step 5261, loss 0.053266, acc 0.96875, learning_rate 0.000205626\n","2023-06-27T18:12:21.071036: step 5262, loss 0.00261742, acc 1, learning_rate 0.000205553\n","2023-06-27T18:12:21.195014: step 5263, loss 0.00562225, acc 1, learning_rate 0.000205481\n","2023-06-27T18:12:21.333760: step 5264, loss 0.0412957, acc 1, learning_rate 0.000205408\n","2023-06-27T18:12:21.459987: step 5265, loss 0.0775377, acc 0.96875, learning_rate 0.000205336\n","2023-06-27T18:12:21.594757: step 5266, loss 0.104429, acc 0.96875, learning_rate 0.000205264\n","2023-06-27T18:12:21.709355: step 5267, loss 0.0226835, acc 1, learning_rate 0.000205192\n","2023-06-27T18:12:21.833898: step 5268, loss 0.0125045, acc 1, learning_rate 0.00020512\n","2023-06-27T18:12:21.958899: step 5269, loss 0.0205279, acc 1, learning_rate 0.000205047\n","2023-06-27T18:12:22.082614: step 5270, loss 0.00844806, acc 1, learning_rate 0.000204975\n","2023-06-27T18:12:22.195964: step 5271, loss 0.0873908, acc 0.96875, learning_rate 0.000204903\n","2023-06-27T18:12:22.330535: step 5272, loss 0.0344027, acc 1, learning_rate 0.000204832\n","2023-06-27T18:12:22.454023: step 5273, loss 0.0332879, acc 1, learning_rate 0.00020476\n","2023-06-27T18:12:22.576444: step 5274, loss 0.0437767, acc 0.96875, learning_rate 0.000204688\n","2023-06-27T18:12:22.695556: step 5275, loss 0.0234713, acc 1, learning_rate 0.000204616\n","2023-06-27T18:12:22.814894: step 5276, loss 0.0371804, acc 1, learning_rate 0.000204544\n","2023-06-27T18:12:22.948773: step 5277, loss 0.0272201, acc 1, learning_rate 0.000204473\n","2023-06-27T18:12:23.067226: step 5278, loss 0.0465861, acc 1, learning_rate 0.000204401\n","2023-06-27T18:12:23.230025: step 5279, loss 0.130064, acc 0.90625, learning_rate 0.000204329\n","2023-06-27T18:12:23.427209: step 5280, loss 0.0104308, acc 1, learning_rate 0.000204258\n","2023-06-27T18:12:23.635158: step 5281, loss 0.0586483, acc 0.96875, learning_rate 0.000204186\n","2023-06-27T18:12:23.829800: step 5282, loss 0.0249672, acc 1, learning_rate 0.000204115\n","2023-06-27T18:12:24.036411: step 5283, loss 0.0642061, acc 0.96875, learning_rate 0.000204043\n","2023-06-27T18:12:24.250719: step 5284, loss 0.00616636, acc 1, learning_rate 0.000203972\n","2023-06-27T18:12:24.481677: step 5285, loss 0.132465, acc 0.9375, learning_rate 0.000203901\n","2023-06-27T18:12:24.687884: step 5286, loss 0.0238822, acc 1, learning_rate 0.00020383\n","2023-06-27T18:12:24.880378: step 5287, loss 0.0851673, acc 0.96875, learning_rate 0.000203758\n","2023-06-27T18:12:25.083866: step 5288, loss 0.00521206, acc 1, learning_rate 0.000203687\n","2023-06-27T18:12:25.265643: step 5289, loss 0.00623001, acc 1, learning_rate 0.000203616\n","2023-06-27T18:12:25.442004: step 5290, loss 0.0308047, acc 1, learning_rate 0.000203545\n","2023-06-27T18:12:25.648855: step 5291, loss 0.0438082, acc 1, learning_rate 0.000203474\n","2023-06-27T18:12:25.855175: step 5292, loss 0.148575, acc 0.9375, learning_rate 0.000203403\n","2023-06-27T18:12:26.044446: step 5293, loss 0.0418298, acc 1, learning_rate 0.000203332\n","2023-06-27T18:12:26.247734: step 5294, loss 0.0175302, acc 1, learning_rate 0.000203261\n","2023-06-27T18:12:26.464890: step 5295, loss 0.0618351, acc 0.96875, learning_rate 0.000203191\n","2023-06-27T18:12:26.658814: step 5296, loss 0.0457624, acc 0.96875, learning_rate 0.00020312\n","2023-06-27T18:12:26.862855: step 5297, loss 0.0902784, acc 0.9375, learning_rate 0.000203049\n","2023-06-27T18:12:27.041615: step 5298, loss 0.0463135, acc 1, learning_rate 0.000202978\n","2023-06-27T18:12:27.214110: step 5299, loss 0.151556, acc 0.96875, learning_rate 0.000202908\n","\n","Evaluation:\n","2023-06-27T18:12:28.479463: step 5300, loss 0.814308, acc 0.801458\n","\n","Saved model checkpoint to /content/gdrive/MyDrive/lightweighted-cnn/train/runs/1687888658/checkpoints/model-5300\n","\n","2023-06-27T18:12:28.825367: step 5300, loss 0.122213, acc 0.96875, learning_rate 0.000202837\n","2023-06-27T18:12:29.004959: step 5301, loss 0.00884772, acc 1, learning_rate 0.000202767\n","2023-06-27T18:12:29.186093: step 5302, loss 0.0198078, acc 1, learning_rate 0.000202696\n","2023-06-27T18:12:29.382111: step 5303, loss 0.0707211, acc 0.96875, learning_rate 0.000202626\n","2023-06-27T18:12:29.575477: step 5304, loss 0.0159413, acc 1, learning_rate 0.000202555\n","2023-06-27T18:12:29.764090: step 5305, loss 0.112641, acc 0.9375, learning_rate 0.000202485\n","2023-06-27T18:12:29.932528: step 5306, loss 0.0450221, acc 1, learning_rate 0.000202415\n","2023-06-27T18:12:30.126652: step 5307, loss 0.00945961, acc 1, learning_rate 0.000202345\n","2023-06-27T18:12:30.318570: step 5308, loss 0.056203, acc 0.96875, learning_rate 0.000202274\n","2023-06-27T18:12:30.511053: step 5309, loss 0.068139, acc 0.96875, learning_rate 0.000202204\n","2023-06-27T18:12:30.708769: step 5310, loss 0.0322477, acc 1, learning_rate 0.000202134\n","2023-06-27T18:12:30.915333: step 5311, loss 0.215423, acc 0.90625, learning_rate 0.000202064\n","2023-06-27T18:12:31.095360: step 5312, loss 0.0454898, acc 0.96875, learning_rate 0.000201994\n","2023-06-27T18:12:31.304851: step 5313, loss 0.0545237, acc 1, learning_rate 0.000201924\n","2023-06-27T18:12:31.495358: step 5314, loss 0.159649, acc 0.90625, learning_rate 0.000201854\n","2023-06-27T18:12:31.682886: step 5315, loss 0.0164899, acc 1, learning_rate 0.000201785\n","2023-06-27T18:12:31.869835: step 5316, loss 0.145342, acc 0.96875, learning_rate 0.000201715\n","2023-06-27T18:12:32.037111: step 5317, loss 0.0486347, acc 0.96875, learning_rate 0.000201645\n","2023-06-27T18:12:32.204651: step 5318, loss 0.0641133, acc 0.96875, learning_rate 0.000201575\n","2023-06-27T18:12:32.410048: step 5319, loss 0.162637, acc 0.96875, learning_rate 0.000201506\n","2023-06-27T18:12:32.621790: step 5320, loss 0.0951822, acc 0.96875, learning_rate 0.000201436\n","2023-06-27T18:12:32.810819: step 5321, loss 0.0625154, acc 0.96875, learning_rate 0.000201366\n","2023-06-27T18:12:33.004874: step 5322, loss 0.0144148, acc 1, learning_rate 0.000201297\n","2023-06-27T18:12:33.209725: step 5323, loss 0.0113748, acc 1, learning_rate 0.000201228\n","2023-06-27T18:12:33.412928: step 5324, loss 0.0286988, acc 1, learning_rate 0.000201158\n","2023-06-27T18:12:33.626325: step 5325, loss 0.0465364, acc 1, learning_rate 0.000201089\n","2023-06-27T18:12:33.803956: step 5326, loss 0.0214914, acc 1, learning_rate 0.000201019\n","2023-06-27T18:12:34.002601: step 5327, loss 0.0257747, acc 1, learning_rate 0.00020095\n","2023-06-27T18:12:34.191894: step 5328, loss 0.0889842, acc 0.96875, learning_rate 0.000200881\n","2023-06-27T18:12:34.357248: step 5329, loss 0.0504107, acc 0.96875, learning_rate 0.000200812\n","2023-06-27T18:12:34.474466: step 5330, loss 0.0556374, acc 0.96875, learning_rate 0.000200743\n","2023-06-27T18:12:34.617201: step 5331, loss 0.0231108, acc 1, learning_rate 0.000200674\n","2023-06-27T18:12:34.744374: step 5332, loss 0.031432, acc 1, learning_rate 0.000200605\n","2023-06-27T18:12:34.863734: step 5333, loss 0.0113417, acc 1, learning_rate 0.000200536\n","2023-06-27T18:12:34.995923: step 5334, loss 0.0339575, acc 1, learning_rate 0.000200467\n","2023-06-27T18:12:35.108069: step 5335, loss 0.0123865, acc 1, learning_rate 0.000200398\n","2023-06-27T18:12:35.220953: step 5336, loss 0.1011, acc 0.9375, learning_rate 0.000200329\n","2023-06-27T18:12:35.348679: step 5337, loss 0.0264405, acc 1, learning_rate 0.00020026\n","2023-06-27T18:12:35.473084: step 5338, loss 0.094216, acc 0.9375, learning_rate 0.000200191\n","2023-06-27T18:12:35.624983: step 5339, loss 0.014495, acc 1, learning_rate 0.000200123\n","2023-06-27T18:12:35.773359: step 5340, loss 0.0107336, acc 1, learning_rate 0.000200054\n","2023-06-27T18:12:35.899230: step 5341, loss 0.0186721, acc 1, learning_rate 0.000199985\n","2023-06-27T18:12:36.013922: step 5342, loss 0.116103, acc 0.96875, learning_rate 0.000199917\n","2023-06-27T18:12:36.124075: step 5343, loss 0.0411524, acc 0.96875, learning_rate 0.000199848\n","2023-06-27T18:12:36.247571: step 5344, loss 0.0244355, acc 1, learning_rate 0.00019978\n","2023-06-27T18:12:36.358331: step 5345, loss 0.036726, acc 0.96875, learning_rate 0.000199711\n","2023-06-27T18:12:36.478422: step 5346, loss 0.14064, acc 0.96875, learning_rate 0.000199643\n","2023-06-27T18:12:36.615726: step 5347, loss 0.0188675, acc 1, learning_rate 0.000199575\n","2023-06-27T18:12:36.732350: step 5348, loss 0.0696204, acc 0.96875, learning_rate 0.000199506\n","2023-06-27T18:12:36.871360: step 5349, loss 0.00418581, acc 1, learning_rate 0.000199438\n","2023-06-27T18:12:37.002940: step 5350, loss 0.00376474, acc 1, learning_rate 0.00019937\n","2023-06-27T18:12:37.121318: step 5351, loss 0.0951563, acc 0.9375, learning_rate 0.000199302\n","2023-06-27T18:12:37.231954: step 5352, loss 0.012241, acc 1, learning_rate 0.000199234\n","2023-06-27T18:12:37.363992: step 5353, loss 0.0709161, acc 0.96875, learning_rate 0.000199166\n","2023-06-27T18:12:37.489732: step 5354, loss 0.0354053, acc 1, learning_rate 0.000199098\n","2023-06-27T18:12:37.617096: step 5355, loss 0.0302705, acc 1, learning_rate 0.00019903\n","2023-06-27T18:12:37.741797: step 5356, loss 0.0954062, acc 0.9375, learning_rate 0.000198962\n","2023-06-27T18:12:37.873719: step 5357, loss 0.120604, acc 0.96875, learning_rate 0.000198894\n","2023-06-27T18:12:37.989755: step 5358, loss 0.0100733, acc 1, learning_rate 0.000198826\n","2023-06-27T18:12:38.130955: step 5359, loss 0.0684359, acc 1, learning_rate 0.000198758\n","2023-06-27T18:12:38.245177: step 5360, loss 0.0178434, acc 1, learning_rate 0.000198691\n","2023-06-27T18:12:38.371874: step 5361, loss 0.0264993, acc 1, learning_rate 0.000198623\n","2023-06-27T18:12:38.505674: step 5362, loss 0.0233437, acc 1, learning_rate 0.000198555\n","2023-06-27T18:12:38.621762: step 5363, loss 0.144543, acc 0.9375, learning_rate 0.000198488\n","2023-06-27T18:12:38.741055: step 5364, loss 0.0192231, acc 1, learning_rate 0.00019842\n","2023-06-27T18:12:38.873430: step 5365, loss 0.0749895, acc 1, learning_rate 0.000198353\n","2023-06-27T18:12:39.015354: step 5366, loss 0.0252055, acc 1, learning_rate 0.000198285\n","2023-06-27T18:12:39.122171: step 5367, loss 0.0286934, acc 1, learning_rate 0.000198218\n","2023-06-27T18:12:39.255339: step 5368, loss 0.0702793, acc 0.96875, learning_rate 0.000198151\n","2023-06-27T18:12:39.370549: step 5369, loss 0.0480497, acc 1, learning_rate 0.000198083\n","2023-06-27T18:12:39.497374: step 5370, loss 0.0500755, acc 0.96875, learning_rate 0.000198016\n","2023-06-27T18:12:39.618496: step 5371, loss 0.0100125, acc 1, learning_rate 0.000197949\n","2023-06-27T18:12:39.736383: step 5372, loss 0.0258423, acc 1, learning_rate 0.000197882\n","2023-06-27T18:12:39.863872: step 5373, loss 0.0723605, acc 0.96875, learning_rate 0.000197814\n","2023-06-27T18:12:39.985561: step 5374, loss 0.0519322, acc 0.96875, learning_rate 0.000197747\n","2023-06-27T18:12:40.100273: step 5375, loss 0.00658008, acc 1, learning_rate 0.00019768\n","2023-06-27T18:12:40.218185: step 5376, loss 0.068278, acc 0.96875, learning_rate 0.000197613\n","2023-06-27T18:12:40.334898: step 5377, loss 0.127623, acc 0.96875, learning_rate 0.000197546\n","2023-06-27T18:12:40.477216: step 5378, loss 0.093293, acc 0.96875, learning_rate 0.00019748\n","2023-06-27T18:12:40.597139: step 5379, loss 0.0587958, acc 0.96875, learning_rate 0.000197413\n","2023-06-27T18:12:40.714679: step 5380, loss 0.209617, acc 0.90625, learning_rate 0.000197346\n","2023-06-27T18:12:40.851798: step 5381, loss 0.0669747, acc 0.96875, learning_rate 0.000197279\n","2023-06-27T18:12:40.972198: step 5382, loss 0.0821126, acc 0.96875, learning_rate 0.000197212\n","2023-06-27T18:12:41.081981: step 5383, loss 0.0151609, acc 1, learning_rate 0.000197146\n","2023-06-27T18:12:41.194721: step 5384, loss 0.0269111, acc 0.96875, learning_rate 0.000197079\n","2023-06-27T18:12:41.326050: step 5385, loss 0.0109663, acc 1, learning_rate 0.000197013\n","2023-06-27T18:12:41.437558: step 5386, loss 0.0151314, acc 1, learning_rate 0.000196946\n","2023-06-27T18:12:41.570076: step 5387, loss 0.176497, acc 0.90625, learning_rate 0.00019688\n","2023-06-27T18:12:41.680602: step 5388, loss 0.067849, acc 0.96875, learning_rate 0.000196813\n","2023-06-27T18:12:41.805244: step 5389, loss 0.0416831, acc 1, learning_rate 0.000196747\n","2023-06-27T18:12:41.944063: step 5390, loss 0.0132711, acc 1, learning_rate 0.00019668\n","2023-06-27T18:12:42.057045: step 5391, loss 0.0705819, acc 0.96875, learning_rate 0.000196614\n","2023-06-27T18:12:42.175559: step 5392, loss 0.0274502, acc 1, learning_rate 0.000196548\n","2023-06-27T18:12:42.302770: step 5393, loss 0.0340074, acc 0.96875, learning_rate 0.000196482\n","2023-06-27T18:12:42.416766: step 5394, loss 0.10314, acc 0.96875, learning_rate 0.000196416\n","2023-06-27T18:12:42.548204: step 5395, loss 0.038145, acc 0.96875, learning_rate 0.000196349\n","2023-06-27T18:12:42.669572: step 5396, loss 0.0661414, acc 0.96875, learning_rate 0.000196283\n","2023-06-27T18:12:42.787234: step 5397, loss 0.00852985, acc 1, learning_rate 0.000196217\n","2023-06-27T18:12:42.917245: step 5398, loss 0.0388195, acc 0.96875, learning_rate 0.000196151\n","2023-06-27T18:12:43.024783: step 5399, loss 0.0677657, acc 0.96875, learning_rate 0.000196085\n","\n","Evaluation:\n","2023-06-27T18:12:43.753573: step 5400, loss 0.81169, acc 0.801672\n","\n","Saved model checkpoint to /content/gdrive/MyDrive/lightweighted-cnn/train/runs/1687888658/checkpoints/model-5400\n","\n","2023-06-27T18:12:44.001362: step 5400, loss 0.1401, acc 0.9375, learning_rate 0.00019602\n","2023-06-27T18:12:44.119526: step 5401, loss 0.00405202, acc 1, learning_rate 0.000195954\n","2023-06-27T18:12:44.244874: step 5402, loss 0.0629304, acc 0.96875, learning_rate 0.000195888\n","2023-06-27T18:12:44.446955: step 5403, loss 0.031961, acc 1, learning_rate 0.000195822\n","2023-06-27T18:12:44.637437: step 5404, loss 0.0942291, acc 0.96875, learning_rate 0.000195756\n","2023-06-27T18:12:44.855809: step 5405, loss 0.0366444, acc 1, learning_rate 0.000195691\n","2023-06-27T18:12:45.072027: step 5406, loss 0.149901, acc 0.96875, learning_rate 0.000195625\n","2023-06-27T18:12:45.267417: step 5407, loss 0.0517736, acc 0.96875, learning_rate 0.00019556\n","2023-06-27T18:12:45.477143: step 5408, loss 0.029011, acc 0.96875, learning_rate 0.000195494\n","2023-06-27T18:12:45.713936: step 5409, loss 0.0323402, acc 1, learning_rate 0.000195429\n","2023-06-27T18:12:45.936026: step 5410, loss 0.0214688, acc 1, learning_rate 0.000195363\n","2023-06-27T18:12:46.148575: step 5411, loss 0.00620108, acc 1, learning_rate 0.000195298\n","2023-06-27T18:12:46.366279: step 5412, loss 0.0159093, acc 1, learning_rate 0.000195232\n","2023-06-27T18:12:46.590327: step 5413, loss 0.0943287, acc 0.9375, learning_rate 0.000195167\n","2023-06-27T18:12:46.802325: step 5414, loss 0.0189035, acc 1, learning_rate 0.000195102\n","2023-06-27T18:12:47.001800: step 5415, loss 0.00913807, acc 1, learning_rate 0.000195037\n","2023-06-27T18:12:47.194562: step 5416, loss 0.0220102, acc 1, learning_rate 0.000194971\n","2023-06-27T18:12:47.402566: step 5417, loss 0.15124, acc 0.96875, learning_rate 0.000194906\n","2023-06-27T18:12:47.602142: step 5418, loss 0.0250686, acc 1, learning_rate 0.000194841\n","2023-06-27T18:12:47.791258: step 5419, loss 0.157849, acc 0.9375, learning_rate 0.000194776\n","2023-06-27T18:12:47.977936: step 5420, loss 0.0381657, acc 1, learning_rate 0.000194711\n","2023-06-27T18:12:48.171419: step 5421, loss 0.108444, acc 0.9375, learning_rate 0.000194646\n","2023-06-27T18:12:48.387783: step 5422, loss 0.063519, acc 0.96875, learning_rate 0.000194581\n","2023-06-27T18:12:48.573324: step 5423, loss 0.0492648, acc 0.96875, learning_rate 0.000194517\n","2023-06-27T18:12:48.761709: step 5424, loss 0.0464625, acc 1, learning_rate 0.000194452\n","2023-06-27T18:12:48.960389: step 5425, loss 0.103615, acc 0.9375, learning_rate 0.000194387\n","2023-06-27T18:12:49.159100: step 5426, loss 0.00653418, acc 1, learning_rate 0.000194322\n","2023-06-27T18:12:49.332245: step 5427, loss 0.00980141, acc 1, learning_rate 0.000194258\n","2023-06-27T18:12:49.535995: step 5428, loss 0.0714116, acc 0.96875, learning_rate 0.000194193\n","2023-06-27T18:12:49.732235: step 5429, loss 0.0683613, acc 0.96875, learning_rate 0.000194128\n","2023-06-27T18:12:49.946671: step 5430, loss 0.0123696, acc 1, learning_rate 0.000194064\n","2023-06-27T18:12:50.115151: step 5431, loss 0.0674201, acc 1, learning_rate 0.000193999\n","2023-06-27T18:12:50.322654: step 5432, loss 0.0516984, acc 0.96875, learning_rate 0.000193935\n","2023-06-27T18:12:50.503877: step 5433, loss 0.0348207, acc 0.96875, learning_rate 0.00019387\n","2023-06-27T18:12:50.760039: step 5434, loss 0.037347, acc 1, learning_rate 0.000193806\n","2023-06-27T18:12:50.937111: step 5435, loss 0.0182227, acc 1, learning_rate 0.000193742\n","2023-06-27T18:12:51.129030: step 5436, loss 0.031451, acc 1, learning_rate 0.000193677\n","2023-06-27T18:12:51.302898: step 5437, loss 0.107265, acc 1, learning_rate 0.000193613\n","2023-06-27T18:12:51.477160: step 5438, loss 0.0522192, acc 0.96875, learning_rate 0.000193549\n","2023-06-27T18:12:51.668025: step 5439, loss 0.157516, acc 0.96875, learning_rate 0.000193485\n","2023-06-27T18:12:51.851701: step 5440, loss 0.121257, acc 0.96875, learning_rate 0.000193421\n","2023-06-27T18:12:52.028724: step 5441, loss 0.0162077, acc 1, learning_rate 0.000193357\n","2023-06-27T18:12:52.207599: step 5442, loss 0.0326973, acc 1, learning_rate 0.000193293\n","2023-06-27T18:12:52.400183: step 5443, loss 0.0963914, acc 0.96875, learning_rate 0.000193229\n","2023-06-27T18:12:52.588404: step 5444, loss 0.153395, acc 0.90625, learning_rate 0.000193165\n","2023-06-27T18:12:52.765539: step 5445, loss 0.0384966, acc 1, learning_rate 0.000193101\n","2023-06-27T18:12:52.962786: step 5446, loss 0.0359152, acc 1, learning_rate 0.000193037\n","2023-06-27T18:12:53.155530: step 5447, loss 0.0546694, acc 1, learning_rate 0.000192973\n","2023-06-27T18:12:53.335619: step 5448, loss 0.0352793, acc 1, learning_rate 0.000192909\n","2023-06-27T18:12:53.537549: step 5449, loss 0.189966, acc 0.90625, learning_rate 0.000192846\n","2023-06-27T18:12:53.754203: step 5450, loss 0.0432, acc 0.96875, learning_rate 0.000192782\n","2023-06-27T18:12:53.937951: step 5451, loss 0.0204464, acc 1, learning_rate 0.000192718\n","2023-06-27T18:12:54.125395: step 5452, loss 0.0287088, acc 1, learning_rate 0.000192655\n","2023-06-27T18:12:54.301209: step 5453, loss 0.185095, acc 0.96875, learning_rate 0.000192591\n","2023-06-27T18:12:54.509434: step 5454, loss 0.0476468, acc 1, learning_rate 0.000192528\n","2023-06-27T18:12:54.686042: step 5455, loss 0.127872, acc 0.9375, learning_rate 0.000192464\n","2023-06-27T18:12:54.874954: step 5456, loss 0.0627381, acc 0.96875, learning_rate 0.000192401\n","2023-06-27T18:12:55.029929: step 5457, loss 0.0253997, acc 1, learning_rate 0.000192338\n","2023-06-27T18:12:55.237109: step 5458, loss 0.0271478, acc 1, learning_rate 0.000192274\n","2023-06-27T18:12:55.367555: step 5459, loss 0.0284517, acc 1, learning_rate 0.000192211\n","2023-06-27T18:12:55.498698: step 5460, loss 0.0722354, acc 1, learning_rate 0.000192148\n","2023-06-27T18:12:55.617766: step 5461, loss 0.0825475, acc 0.96875, learning_rate 0.000192085\n","2023-06-27T18:12:55.758734: step 5462, loss 0.0975934, acc 0.96875, learning_rate 0.000192022\n","2023-06-27T18:12:55.873831: step 5463, loss 0.00661353, acc 1, learning_rate 0.000191958\n","2023-06-27T18:12:55.999938: step 5464, loss 0.0211111, acc 1, learning_rate 0.000191895\n","2023-06-27T18:12:56.124085: step 5465, loss 0.090748, acc 0.96875, learning_rate 0.000191832\n","2023-06-27T18:12:56.241588: step 5466, loss 0.0457073, acc 0.96875, learning_rate 0.000191769\n","2023-06-27T18:12:56.351788: step 5467, loss 0.0492116, acc 1, learning_rate 0.000191706\n","2023-06-27T18:12:56.487229: step 5468, loss 0.0104091, acc 1, learning_rate 0.000191644\n","2023-06-27T18:12:56.620896: step 5469, loss 0.0886082, acc 0.96875, learning_rate 0.000191581\n","2023-06-27T18:12:56.749774: step 5470, loss 0.069539, acc 1, learning_rate 0.000191518\n","2023-06-27T18:12:56.869043: step 5471, loss 0.135025, acc 0.96875, learning_rate 0.000191455\n","2023-06-27T18:12:56.992265: step 5472, loss 0.0465112, acc 1, learning_rate 0.000191392\n","2023-06-27T18:12:57.106487: step 5473, loss 0.0960035, acc 0.96875, learning_rate 0.00019133\n","2023-06-27T18:12:57.226716: step 5474, loss 0.0156903, acc 1, learning_rate 0.000191267\n","2023-06-27T18:12:57.352990: step 5475, loss 0.0516169, acc 1, learning_rate 0.000191205\n","2023-06-27T18:12:57.489666: step 5476, loss 0.0211616, acc 1, learning_rate 0.000191142\n","2023-06-27T18:12:57.617150: step 5477, loss 0.0840632, acc 0.96875, learning_rate 0.00019108\n","2023-06-27T18:12:57.740461: step 5478, loss 0.0475646, acc 1, learning_rate 0.000191017\n","2023-06-27T18:12:57.850283: step 5479, loss 0.0201534, acc 1, learning_rate 0.000190955\n","2023-06-27T18:12:57.980886: step 5480, loss 0.0740455, acc 0.96875, learning_rate 0.000190892\n","2023-06-27T18:12:58.103553: step 5481, loss 0.125113, acc 0.9375, learning_rate 0.00019083\n","2023-06-27T18:12:58.224377: step 5482, loss 0.0738122, acc 0.96875, learning_rate 0.000190768\n","2023-06-27T18:12:58.353174: step 5483, loss 0.0174843, acc 1, learning_rate 0.000190705\n","2023-06-27T18:12:58.489844: step 5484, loss 0.0105392, acc 1, learning_rate 0.000190643\n","2023-06-27T18:12:58.612959: step 5485, loss 0.0214139, acc 1, learning_rate 0.000190581\n","2023-06-27T18:12:58.728242: step 5486, loss 0.0276715, acc 1, learning_rate 0.000190519\n","2023-06-27T18:12:58.856703: step 5487, loss 0.120991, acc 0.9375, learning_rate 0.000190457\n","2023-06-27T18:12:58.971486: step 5488, loss 0.0493644, acc 0.96875, learning_rate 0.000190395\n","2023-06-27T18:12:59.093171: step 5489, loss 0.211038, acc 0.96875, learning_rate 0.000190333\n","2023-06-27T18:12:59.213216: step 5490, loss 0.0131929, acc 1, learning_rate 0.000190271\n","2023-06-27T18:12:59.335889: step 5491, loss 0.0882304, acc 1, learning_rate 0.000190209\n","2023-06-27T18:12:59.466487: step 5492, loss 0.00862962, acc 1, learning_rate 0.000190147\n","2023-06-27T18:12:59.576560: step 5493, loss 0.0326857, acc 1, learning_rate 0.000190085\n","2023-06-27T18:12:59.688124: step 5494, loss 0.0884593, acc 0.96875, learning_rate 0.000190024\n","2023-06-27T18:12:59.819135: step 5495, loss 0.0618164, acc 0.96875, learning_rate 0.000189962\n","2023-06-27T18:12:59.945639: step 5496, loss 0.00926658, acc 1, learning_rate 0.0001899\n","2023-06-27T18:13:00.055121: step 5497, loss 0.0356823, acc 0.96875, learning_rate 0.000189839\n","2023-06-27T18:13:00.175866: step 5498, loss 0.0568704, acc 1, learning_rate 0.000189777\n","2023-06-27T18:13:00.290236: step 5499, loss 0.00906841, acc 1, learning_rate 0.000189715\n","\n","Evaluation:\n","2023-06-27T18:13:01.068542: step 5500, loss 0.825064, acc 0.799528\n","\n","Saved model checkpoint to /content/gdrive/MyDrive/lightweighted-cnn/train/runs/1687888658/checkpoints/model-5500\n","\n","2023-06-27T18:13:01.281760: step 5500, loss 0.26861, acc 0.90625, learning_rate 0.000189654\n","2023-06-27T18:13:01.398153: step 5501, loss 0.0256308, acc 1, learning_rate 0.000189592\n","2023-06-27T18:13:01.504050: step 5502, loss 0.00912313, acc 1, learning_rate 0.000189531\n","2023-06-27T18:13:01.649086: step 5503, loss 0.0890135, acc 0.96875, learning_rate 0.00018947\n","2023-06-27T18:13:01.764910: step 5504, loss 0.0314124, acc 1, learning_rate 0.000189408\n","2023-06-27T18:13:01.872185: step 5505, loss 0.0153221, acc 1, learning_rate 0.000189347\n","2023-06-27T18:13:01.995165: step 5506, loss 0.100731, acc 0.9375, learning_rate 0.000189286\n","2023-06-27T18:13:02.114200: step 5507, loss 0.105208, acc 0.90625, learning_rate 0.000189224\n","2023-06-27T18:13:02.242124: step 5508, loss 0.0879978, acc 0.96875, learning_rate 0.000189163\n","2023-06-27T18:13:02.363078: step 5509, loss 0.0104953, acc 1, learning_rate 0.000189102\n","2023-06-27T18:13:02.494643: step 5510, loss 0.0181039, acc 1, learning_rate 0.000189041\n","2023-06-27T18:13:02.633521: step 5511, loss 0.0270894, acc 1, learning_rate 0.00018898\n","2023-06-27T18:13:02.769474: step 5512, loss 0.0352063, acc 1, learning_rate 0.000188919\n","2023-06-27T18:13:02.884150: step 5513, loss 0.0773258, acc 0.96875, learning_rate 0.000188858\n","2023-06-27T18:13:02.995209: step 5514, loss 0.0195377, acc 1, learning_rate 0.000188797\n","2023-06-27T18:13:03.122727: step 5515, loss 0.0224352, acc 1, learning_rate 0.000188736\n","2023-06-27T18:13:03.235898: step 5516, loss 0.125968, acc 0.96875, learning_rate 0.000188675\n","2023-06-27T18:13:03.371932: step 5517, loss 0.0540665, acc 1, learning_rate 0.000188614\n","2023-06-27T18:13:03.491655: step 5518, loss 0.0268293, acc 1, learning_rate 0.000188554\n","2023-06-27T18:13:03.613219: step 5519, loss 0.0617124, acc 0.96875, learning_rate 0.000188493\n","2023-06-27T18:13:03.732969: step 5520, loss 0.0787899, acc 0.96875, learning_rate 0.000188432\n","2023-06-27T18:13:03.854429: step 5521, loss 0.0597801, acc 0.96875, learning_rate 0.000188372\n","2023-06-27T18:13:03.988541: step 5522, loss 0.0472161, acc 0.96875, learning_rate 0.000188311\n","2023-06-27T18:13:04.101984: step 5523, loss 0.0994623, acc 0.96875, learning_rate 0.00018825\n","2023-06-27T18:13:04.220812: step 5524, loss 0.0594153, acc 0.96875, learning_rate 0.00018819\n","2023-06-27T18:13:04.358431: step 5525, loss 0.0696207, acc 0.96875, learning_rate 0.000188129\n","2023-06-27T18:13:04.475190: step 5526, loss 0.0303483, acc 1, learning_rate 0.000188069\n","2023-06-27T18:13:04.595460: step 5527, loss 0.0420037, acc 1, learning_rate 0.000188009\n","2023-06-27T18:13:04.727471: step 5528, loss 0.0134591, acc 1, learning_rate 0.000187948\n","2023-06-27T18:13:04.846806: step 5529, loss 0.079301, acc 0.96875, learning_rate 0.000187888\n","2023-06-27T18:13:04.968110: step 5530, loss 0.120159, acc 0.96875, learning_rate 0.000187828\n","2023-06-27T18:13:05.085694: step 5531, loss 0.0576554, acc 0.96875, learning_rate 0.000187767\n","2023-06-27T18:13:05.211666: step 5532, loss 0.117172, acc 0.90625, learning_rate 0.000187707\n","2023-06-27T18:13:05.375520: step 5533, loss 0.0266576, acc 1, learning_rate 0.000187647\n","2023-06-27T18:13:05.566171: step 5534, loss 0.0535521, acc 1, learning_rate 0.000187587\n","2023-06-27T18:13:05.769995: step 5535, loss 0.0575834, acc 0.96875, learning_rate 0.000187527\n","2023-06-27T18:13:05.960883: step 5536, loss 0.0476899, acc 1, learning_rate 0.000187467\n","2023-06-27T18:13:06.138694: step 5537, loss 0.0816316, acc 0.96875, learning_rate 0.000187407\n","2023-06-27T18:13:06.335161: step 5538, loss 0.139551, acc 0.9375, learning_rate 0.000187347\n","2023-06-27T18:13:06.533695: step 5539, loss 0.0265346, acc 1, learning_rate 0.000187287\n","2023-06-27T18:13:06.760936: step 5540, loss 0.0515384, acc 1, learning_rate 0.000187227\n","2023-06-27T18:13:06.977281: step 5541, loss 0.0187203, acc 1, learning_rate 0.000187167\n","2023-06-27T18:13:07.179891: step 5542, loss 0.0154588, acc 1, learning_rate 0.000187108\n","2023-06-27T18:13:07.375701: step 5543, loss 0.0351311, acc 1, learning_rate 0.000187048\n","2023-06-27T18:13:07.569613: step 5544, loss 0.0154662, acc 1, learning_rate 0.000186988\n","2023-06-27T18:13:07.783971: step 5545, loss 0.0537677, acc 0.96875, learning_rate 0.000186929\n","2023-06-27T18:13:07.986926: step 5546, loss 0.0104577, acc 1, learning_rate 0.000186869\n","2023-06-27T18:13:08.198671: step 5547, loss 0.0127081, acc 1, learning_rate 0.000186809\n","2023-06-27T18:13:08.394755: step 5548, loss 0.0824079, acc 0.96875, learning_rate 0.00018675\n","2023-06-27T18:13:08.588507: step 5549, loss 0.134812, acc 0.9375, learning_rate 0.00018669\n","2023-06-27T18:13:08.783289: step 5550, loss 0.103592, acc 0.96875, learning_rate 0.000186631\n","2023-06-27T18:13:08.975670: step 5551, loss 0.00934998, acc 1, learning_rate 0.000186572\n","2023-06-27T18:13:09.172016: step 5552, loss 0.02147, acc 1, learning_rate 0.000186512\n","2023-06-27T18:13:09.377035: step 5553, loss 0.0284611, acc 1, learning_rate 0.000186453\n","2023-06-27T18:13:09.577594: step 5554, loss 0.0156676, acc 1, learning_rate 0.000186394\n","2023-06-27T18:13:09.765238: step 5555, loss 0.0167878, acc 1, learning_rate 0.000186334\n","2023-06-27T18:13:09.946351: step 5556, loss 0.047371, acc 0.96875, learning_rate 0.000186275\n","2023-06-27T18:13:10.157740: step 5557, loss 0.0546872, acc 0.96875, learning_rate 0.000186216\n","2023-06-27T18:13:10.371278: step 5558, loss 0.0590899, acc 0.96875, learning_rate 0.000186157\n","2023-06-27T18:13:10.550236: step 5559, loss 0.114459, acc 0.96875, learning_rate 0.000186098\n","2023-06-27T18:13:10.811526: step 5560, loss 0.108351, acc 0.96875, learning_rate 0.000186039\n","2023-06-27T18:13:11.009375: step 5561, loss 0.0165674, acc 1, learning_rate 0.00018598\n","2023-06-27T18:13:11.214630: step 5562, loss 0.188006, acc 0.90625, learning_rate 0.000185921\n","2023-06-27T18:13:11.406902: step 5563, loss 0.0118839, acc 1, learning_rate 0.000185862\n","2023-06-27T18:13:11.639637: step 5564, loss 0.0326969, acc 1, learning_rate 0.000185803\n","2023-06-27T18:13:11.845844: step 5565, loss 0.0715577, acc 0.96875, learning_rate 0.000185744\n","2023-06-27T18:13:12.048206: step 5566, loss 0.038592, acc 0.96875, learning_rate 0.000185685\n","2023-06-27T18:13:12.272654: step 5567, loss 0.0202547, acc 1, learning_rate 0.000185627\n","2023-06-27T18:13:12.484427: step 5568, loss 0.0444175, acc 0.96875, learning_rate 0.000185568\n","2023-06-27T18:13:12.676560: step 5569, loss 0.0199857, acc 1, learning_rate 0.000185509\n","2023-06-27T18:13:12.849628: step 5570, loss 0.0262655, acc 1, learning_rate 0.000185451\n","2023-06-27T18:13:13.039740: step 5571, loss 0.0313454, acc 1, learning_rate 0.000185392\n","2023-06-27T18:13:13.204093: step 5572, loss 0.0065542, acc 1, learning_rate 0.000185333\n","2023-06-27T18:13:13.366250: step 5573, loss 0.0119313, acc 1, learning_rate 0.000185275\n","2023-06-27T18:13:13.548644: step 5574, loss 0.0830473, acc 0.9375, learning_rate 0.000185216\n","2023-06-27T18:13:13.752595: step 5575, loss 0.0108621, acc 1, learning_rate 0.000185158\n","2023-06-27T18:13:13.957722: step 5576, loss 0.00117464, acc 1, learning_rate 0.0001851\n","2023-06-27T18:13:14.172002: step 5577, loss 0.151695, acc 0.96875, learning_rate 0.000185041\n","2023-06-27T18:13:14.359096: step 5578, loss 0.122195, acc 0.96875, learning_rate 0.000184983\n","2023-06-27T18:13:14.562165: step 5579, loss 0.0952913, acc 0.9375, learning_rate 0.000184925\n","2023-06-27T18:13:14.746836: step 5580, loss 0.0171566, acc 1, learning_rate 0.000184866\n","2023-06-27T18:13:14.959852: step 5581, loss 0.123577, acc 0.9375, learning_rate 0.000184808\n","2023-06-27T18:13:15.137528: step 5582, loss 0.0082558, acc 1, learning_rate 0.00018475\n","2023-06-27T18:13:15.325012: step 5583, loss 0.129138, acc 0.9375, learning_rate 0.000184692\n","2023-06-27T18:13:15.504484: step 5584, loss 0.135158, acc 0.9375, learning_rate 0.000184634\n","2023-06-27T18:13:15.706992: step 5585, loss 0.0520499, acc 0.96875, learning_rate 0.000184576\n","2023-06-27T18:13:15.910608: step 5586, loss 0.00982592, acc 1, learning_rate 0.000184518\n","2023-06-27T18:13:16.121732: step 5587, loss 0.00429458, acc 1, learning_rate 0.00018446\n","2023-06-27T18:13:16.309674: step 5588, loss 0.0332507, acc 1, learning_rate 0.000184402\n","2023-06-27T18:13:16.427467: step 5589, loss 0.112275, acc 0.9375, learning_rate 0.000184344\n","2023-06-27T18:13:16.562494: step 5590, loss 0.0415028, acc 1, learning_rate 0.000184286\n","2023-06-27T18:13:16.685986: step 5591, loss 0.0111257, acc 1, learning_rate 0.000184229\n","2023-06-27T18:13:16.812505: step 5592, loss 0.00231845, acc 1, learning_rate 0.000184171\n","2023-06-27T18:13:16.945901: step 5593, loss 0.0121361, acc 1, learning_rate 0.000184113\n","2023-06-27T18:13:17.064975: step 5594, loss 0.0068564, acc 1, learning_rate 0.000184055\n","2023-06-27T18:13:17.200388: step 5595, loss 0.0295328, acc 0.96875, learning_rate 0.000183998\n","2023-06-27T18:13:17.331699: step 5596, loss 0.0375963, acc 1, learning_rate 0.00018394\n","2023-06-27T18:13:17.446289: step 5597, loss 0.0193159, acc 1, learning_rate 0.000183883\n","2023-06-27T18:13:17.568044: step 5598, loss 0.174729, acc 0.9375, learning_rate 0.000183825\n","2023-06-27T18:13:17.679052: step 5599, loss 0.0255468, acc 1, learning_rate 0.000183768\n","\n","Evaluation:\n","2023-06-27T18:13:18.417194: step 5600, loss 0.82252, acc 0.799743\n","\n","Saved model checkpoint to /content/gdrive/MyDrive/lightweighted-cnn/train/runs/1687888658/checkpoints/model-5600\n","\n","2023-06-27T18:13:18.637742: step 5600, loss 0.0274587, acc 1, learning_rate 0.00018371\n","2023-06-27T18:13:18.769861: step 5601, loss 0.0659462, acc 0.96875, learning_rate 0.000183653\n","2023-06-27T18:13:18.890299: step 5602, loss 0.0229682, acc 1, learning_rate 0.000183595\n","2023-06-27T18:13:19.002342: step 5603, loss 0.0598717, acc 1, learning_rate 0.000183538\n","2023-06-27T18:13:19.118435: step 5604, loss 0.0671854, acc 1, learning_rate 0.000183481\n","2023-06-27T18:13:19.250261: step 5605, loss 0.011042, acc 1, learning_rate 0.000183424\n","2023-06-27T18:13:19.373771: step 5606, loss 0.0693272, acc 0.96875, learning_rate 0.000183366\n","2023-06-27T18:13:19.510043: step 5607, loss 0.0152265, acc 1, learning_rate 0.000183309\n","2023-06-27T18:13:19.629309: step 5608, loss 0.0104764, acc 1, learning_rate 0.000183252\n","2023-06-27T18:13:19.744520: step 5609, loss 0.0677154, acc 0.96875, learning_rate 0.000183195\n","2023-06-27T18:13:19.866244: step 5610, loss 0.0780349, acc 0.96875, learning_rate 0.000183138\n","2023-06-27T18:13:19.988563: step 5611, loss 0.0298387, acc 1, learning_rate 0.000183081\n","2023-06-27T18:13:20.106425: step 5612, loss 0.0955675, acc 0.9375, learning_rate 0.000183024\n","2023-06-27T18:13:20.231837: step 5613, loss 0.0350811, acc 1, learning_rate 0.000182967\n","2023-06-27T18:13:20.344285: step 5614, loss 0.0565426, acc 0.96875, learning_rate 0.00018291\n","2023-06-27T18:13:20.450754: step 5615, loss 0.00573051, acc 1, learning_rate 0.000182853\n","2023-06-27T18:13:20.592676: step 5616, loss 0.0352933, acc 1, learning_rate 0.000182796\n","2023-06-27T18:13:20.713719: step 5617, loss 0.0871652, acc 0.9375, learning_rate 0.00018274\n","2023-06-27T18:13:20.831006: step 5618, loss 0.00999813, acc 1, learning_rate 0.000182683\n","2023-06-27T18:13:20.949664: step 5619, loss 0.0343299, acc 1, learning_rate 0.000182626\n","2023-06-27T18:13:21.058646: step 5620, loss 0.00223182, acc 1, learning_rate 0.00018257\n","2023-06-27T18:13:21.175345: step 5621, loss 0.0170547, acc 1, learning_rate 0.000182513\n","2023-06-27T18:13:21.305356: step 5622, loss 0.0674724, acc 0.96875, learning_rate 0.000182456\n","2023-06-27T18:13:21.428567: step 5623, loss 0.146801, acc 0.90625, learning_rate 0.0001824\n","2023-06-27T18:13:21.557583: step 5624, loss 0.0589178, acc 1, learning_rate 0.000182343\n","2023-06-27T18:13:21.686761: step 5625, loss 0.0476026, acc 1, learning_rate 0.000182287\n","2023-06-27T18:13:21.807669: step 5626, loss 0.0322145, acc 1, learning_rate 0.00018223\n","2023-06-27T18:13:21.922181: step 5627, loss 0.0119156, acc 1, learning_rate 0.000182174\n","2023-06-27T18:13:22.061923: step 5628, loss 0.10114, acc 0.96875, learning_rate 0.000182118\n","2023-06-27T18:13:22.186463: step 5629, loss 0.00516288, acc 1, learning_rate 0.000182061\n","2023-06-27T18:13:22.305569: step 5630, loss 0.0294834, acc 1, learning_rate 0.000182005\n","2023-06-27T18:13:22.421149: step 5631, loss 0.0577427, acc 1, learning_rate 0.000181949\n","2023-06-27T18:13:22.530137: step 5632, loss 0.0650487, acc 1, learning_rate 0.000181893\n","2023-06-27T18:13:22.655942: step 5633, loss 0.0353046, acc 1, learning_rate 0.000181836\n","2023-06-27T18:13:22.782828: step 5634, loss 0.00789763, acc 1, learning_rate 0.00018178\n","2023-06-27T18:13:22.901495: step 5635, loss 0.0470383, acc 1, learning_rate 0.000181724\n","2023-06-27T18:13:23.030000: step 5636, loss 0.0835869, acc 0.96875, learning_rate 0.000181668\n","2023-06-27T18:13:23.142301: step 5637, loss 0.0109392, acc 1, learning_rate 0.000181612\n","2023-06-27T18:13:23.260914: step 5638, loss 0.111236, acc 0.96875, learning_rate 0.000181556\n","2023-06-27T18:13:23.389140: step 5639, loss 0.00599285, acc 1, learning_rate 0.0001815\n","2023-06-27T18:13:23.504304: step 5640, loss 0.0399896, acc 0.96875, learning_rate 0.000181444\n","2023-06-27T18:13:23.632311: step 5641, loss 0.0380021, acc 1, learning_rate 0.000181389\n","2023-06-27T18:13:23.748866: step 5642, loss 0.0343061, acc 1, learning_rate 0.000181333\n","2023-06-27T18:13:23.862381: step 5643, loss 0.051112, acc 1, learning_rate 0.000181277\n","2023-06-27T18:13:24.006624: step 5644, loss 0.10433, acc 0.9375, learning_rate 0.000181221\n","2023-06-27T18:13:24.132864: step 5645, loss 0.0863614, acc 0.9375, learning_rate 0.000181166\n","2023-06-27T18:13:24.249934: step 5646, loss 0.0892359, acc 0.96875, learning_rate 0.00018111\n","2023-06-27T18:13:24.371491: step 5647, loss 0.0199746, acc 1, learning_rate 0.000181054\n","2023-06-27T18:13:24.491190: step 5648, loss 0.143715, acc 0.90625, learning_rate 0.000180999\n","2023-06-27T18:13:24.630962: step 5649, loss 0.0635137, acc 1, learning_rate 0.000180943\n","2023-06-27T18:13:24.753161: step 5650, loss 0.00828896, acc 1, learning_rate 0.000180888\n","2023-06-27T18:13:24.872331: step 5651, loss 0.0885544, acc 0.96875, learning_rate 0.000180832\n","2023-06-27T18:13:24.981079: step 5652, loss 0.022751, acc 1, learning_rate 0.000180777\n","2023-06-27T18:13:25.114233: step 5653, loss 0.175109, acc 0.9375, learning_rate 0.000180721\n","2023-06-27T18:13:25.232474: step 5654, loss 0.142006, acc 0.9375, learning_rate 0.000180666\n","2023-06-27T18:13:25.365860: step 5655, loss 0.0117405, acc 1, learning_rate 0.000180611\n","2023-06-27T18:13:25.485443: step 5656, loss 0.0638599, acc 0.96875, learning_rate 0.000180555\n","2023-06-27T18:13:25.610692: step 5657, loss 0.100015, acc 0.9375, learning_rate 0.0001805\n","2023-06-27T18:13:25.761679: step 5658, loss 0.0995293, acc 0.96875, learning_rate 0.000180445\n","2023-06-27T18:13:25.892017: step 5659, loss 0.0195103, acc 1, learning_rate 0.00018039\n","2023-06-27T18:13:26.007856: step 5660, loss 0.0351055, acc 1, learning_rate 0.000180335\n","2023-06-27T18:13:26.128681: step 5661, loss 0.0770631, acc 0.96875, learning_rate 0.00018028\n","2023-06-27T18:13:26.251086: step 5662, loss 0.204217, acc 0.9375, learning_rate 0.000180225\n","2023-06-27T18:13:26.422090: step 5663, loss 0.0144191, acc 1, learning_rate 0.00018017\n","2023-06-27T18:13:26.612946: step 5664, loss 0.0497208, acc 1, learning_rate 0.000180115\n","2023-06-27T18:13:26.809577: step 5665, loss 0.0691195, acc 0.96875, learning_rate 0.00018006\n","2023-06-27T18:13:27.002820: step 5666, loss 0.0159337, acc 1, learning_rate 0.000180005\n","2023-06-27T18:13:27.194917: step 5667, loss 0.0605851, acc 0.96875, learning_rate 0.00017995\n","2023-06-27T18:13:27.402208: step 5668, loss 0.0133904, acc 1, learning_rate 0.000179895\n","2023-06-27T18:13:27.608120: step 5669, loss 0.0996545, acc 0.96875, learning_rate 0.00017984\n","2023-06-27T18:13:27.807247: step 5670, loss 0.018419, acc 1, learning_rate 0.000179786\n","2023-06-27T18:13:27.992875: step 5671, loss 0.105153, acc 0.90625, learning_rate 0.000179731\n","2023-06-27T18:13:28.177497: step 5672, loss 0.0397972, acc 0.96875, learning_rate 0.000179676\n","2023-06-27T18:13:28.403260: step 5673, loss 0.0424635, acc 0.96875, learning_rate 0.000179622\n","2023-06-27T18:13:28.629889: step 5674, loss 0.0893997, acc 0.96875, learning_rate 0.000179567\n","2023-06-27T18:13:28.844705: step 5675, loss 0.0356318, acc 0.96875, learning_rate 0.000179512\n","2023-06-27T18:13:29.058882: step 5676, loss 0.0122366, acc 1, learning_rate 0.000179458\n","2023-06-27T18:13:29.275038: step 5677, loss 0.071896, acc 0.96875, learning_rate 0.000179403\n","2023-06-27T18:13:29.466528: step 5678, loss 0.0226933, acc 1, learning_rate 0.000179349\n","2023-06-27T18:13:29.662286: step 5679, loss 0.00411633, acc 1, learning_rate 0.000179295\n","2023-06-27T18:13:29.861643: step 5680, loss 0.0242598, acc 1, learning_rate 0.00017924\n","2023-06-27T18:13:30.072052: step 5681, loss 0.210286, acc 0.9375, learning_rate 0.000179186\n","2023-06-27T18:13:30.271080: step 5682, loss 0.0768867, acc 0.96875, learning_rate 0.000179132\n","2023-06-27T18:13:30.472528: step 5683, loss 0.0538856, acc 0.96875, learning_rate 0.000179077\n","2023-06-27T18:13:30.672179: step 5684, loss 0.0314799, acc 1, learning_rate 0.000179023\n","2023-06-27T18:13:30.875656: step 5685, loss 0.0384895, acc 1, learning_rate 0.000178969\n","2023-06-27T18:13:31.060464: step 5686, loss 0.161503, acc 0.9375, learning_rate 0.000178915\n","2023-06-27T18:13:31.236973: step 5687, loss 0.0527135, acc 0.96875, learning_rate 0.000178861\n","2023-06-27T18:13:31.434856: step 5688, loss 0.00765659, acc 1, learning_rate 0.000178807\n","2023-06-27T18:13:31.660149: step 5689, loss 0.0149951, acc 1, learning_rate 0.000178752\n","2023-06-27T18:13:31.844146: step 5690, loss 0.0344306, acc 0.96875, learning_rate 0.000178698\n","2023-06-27T18:13:32.018756: step 5691, loss 0.0303098, acc 1, learning_rate 0.000178644\n","2023-06-27T18:13:32.205798: step 5692, loss 0.0331082, acc 1, learning_rate 0.000178591\n","2023-06-27T18:13:32.429799: step 5693, loss 0.0140343, acc 1, learning_rate 0.000178537\n","2023-06-27T18:13:32.607776: step 5694, loss 0.0863282, acc 0.96875, learning_rate 0.000178483\n","2023-06-27T18:13:32.807666: step 5695, loss 0.0493067, acc 1, learning_rate 0.000178429\n","2023-06-27T18:13:32.994354: step 5696, loss 0.0106648, acc 1, learning_rate 0.000178375\n","2023-06-27T18:13:33.204818: step 5697, loss 0.00619625, acc 1, learning_rate 0.000178321\n","2023-06-27T18:13:33.401875: step 5698, loss 0.0355947, acc 1, learning_rate 0.000178268\n","2023-06-27T18:13:33.599127: step 5699, loss 0.0108284, acc 1, learning_rate 0.000178214\n","\n","Evaluation:\n","2023-06-27T18:13:34.961282: step 5700, loss 0.826955, acc 0.798456\n","\n","Saved model checkpoint to /content/gdrive/MyDrive/lightweighted-cnn/train/runs/1687888658/checkpoints/model-5700\n","\n","2023-06-27T18:13:35.330306: step 5700, loss 0.0483834, acc 0.96875, learning_rate 0.00017816\n","2023-06-27T18:13:35.531973: step 5701, loss 0.0179167, acc 1, learning_rate 0.000178107\n","2023-06-27T18:13:35.719676: step 5702, loss 0.0870855, acc 0.96875, learning_rate 0.000178053\n","2023-06-27T18:13:35.911451: step 5703, loss 0.0945774, acc 0.9375, learning_rate 0.000178\n","2023-06-27T18:13:36.109095: step 5704, loss 0.026628, acc 1, learning_rate 0.000177946\n","2023-06-27T18:13:36.310133: step 5705, loss 0.0397078, acc 0.96875, learning_rate 0.000177893\n","2023-06-27T18:13:36.510274: step 5706, loss 0.0572053, acc 0.96875, learning_rate 0.000177839\n","2023-06-27T18:13:36.702352: step 5707, loss 0.115312, acc 0.96875, learning_rate 0.000177786\n","2023-06-27T18:13:36.898916: step 5708, loss 0.0419851, acc 0.96875, learning_rate 0.000177733\n","2023-06-27T18:13:37.092499: step 5709, loss 0.103525, acc 0.9375, learning_rate 0.000177679\n","2023-06-27T18:13:37.293179: step 5710, loss 0.0654794, acc 0.96875, learning_rate 0.000177626\n","2023-06-27T18:13:37.421881: step 5711, loss 0.0410797, acc 0.96875, learning_rate 0.000177573\n","2023-06-27T18:13:37.536721: step 5712, loss 0.00790358, acc 1, learning_rate 0.00017752\n","2023-06-27T18:13:37.655975: step 5713, loss 0.011945, acc 1, learning_rate 0.000177467\n","2023-06-27T18:13:37.792731: step 5714, loss 0.0399892, acc 1, learning_rate 0.000177413\n","2023-06-27T18:13:37.920587: step 5715, loss 0.0443275, acc 0.96875, learning_rate 0.00017736\n","2023-06-27T18:13:38.035469: step 5716, loss 0.0221627, acc 1, learning_rate 0.000177307\n","2023-06-27T18:13:38.160488: step 5717, loss 0.02704, acc 1, learning_rate 0.000177254\n","2023-06-27T18:13:38.282117: step 5718, loss 0.0291448, acc 1, learning_rate 0.000177201\n","2023-06-27T18:13:38.410856: step 5719, loss 0.0365055, acc 1, learning_rate 0.000177148\n","2023-06-27T18:13:38.531540: step 5720, loss 0.103353, acc 0.96875, learning_rate 0.000177095\n","2023-06-27T18:13:38.667788: step 5721, loss 0.0324938, acc 1, learning_rate 0.000177043\n","2023-06-27T18:13:38.793852: step 5722, loss 0.0563837, acc 0.96875, learning_rate 0.00017699\n","2023-06-27T18:13:38.925069: step 5723, loss 0.153292, acc 0.9375, learning_rate 0.000176937\n","2023-06-27T18:13:39.044044: step 5724, loss 0.0351052, acc 1, learning_rate 0.000176884\n","2023-06-27T18:13:39.160078: step 5725, loss 0.0200441, acc 1, learning_rate 0.000176832\n","2023-06-27T18:13:39.281765: step 5726, loss 0.0125822, acc 1, learning_rate 0.000176779\n","2023-06-27T18:13:39.398647: step 5727, loss 0.0634567, acc 0.96875, learning_rate 0.000176726\n","2023-06-27T18:13:39.513183: step 5728, loss 0.0184396, acc 1, learning_rate 0.000176674\n","2023-06-27T18:13:39.637967: step 5729, loss 0.0755794, acc 0.9375, learning_rate 0.000176621\n","2023-06-27T18:13:39.758648: step 5730, loss 0.0563257, acc 0.96875, learning_rate 0.000176568\n","2023-06-27T18:13:39.893773: step 5731, loss 0.0121095, acc 1, learning_rate 0.000176516\n","2023-06-27T18:13:40.006972: step 5732, loss 0.0188376, acc 1, learning_rate 0.000176463\n","2023-06-27T18:13:40.129062: step 5733, loss 0.0664878, acc 0.96875, learning_rate 0.000176411\n","2023-06-27T18:13:40.252963: step 5734, loss 0.00573775, acc 1, learning_rate 0.000176359\n","2023-06-27T18:13:40.377895: step 5735, loss 0.0220403, acc 1, learning_rate 0.000176306\n","2023-06-27T18:13:40.499136: step 5736, loss 0.0149549, acc 1, learning_rate 0.000176254\n","2023-06-27T18:13:40.623412: step 5737, loss 0.0376659, acc 0.96875, learning_rate 0.000176202\n","2023-06-27T18:13:40.759166: step 5738, loss 0.0411607, acc 1, learning_rate 0.000176149\n","2023-06-27T18:13:40.894792: step 5739, loss 0.208909, acc 0.96875, learning_rate 0.000176097\n","2023-06-27T18:13:41.017287: step 5740, loss 0.0413494, acc 1, learning_rate 0.000176045\n","2023-06-27T18:13:41.129690: step 5741, loss 0.0287566, acc 1, learning_rate 0.000175993\n","2023-06-27T18:13:41.249278: step 5742, loss 0.0211924, acc 1, learning_rate 0.000175941\n","2023-06-27T18:13:41.369593: step 5743, loss 0.379906, acc 0.875, learning_rate 0.000175889\n","2023-06-27T18:13:41.490538: step 5744, loss 0.0984264, acc 0.96875, learning_rate 0.000175837\n","2023-06-27T18:13:41.602718: step 5745, loss 0.0120633, acc 1, learning_rate 0.000175785\n","2023-06-27T18:13:41.714410: step 5746, loss 0.0445097, acc 0.96875, learning_rate 0.000175733\n","2023-06-27T18:13:41.843322: step 5747, loss 0.0425445, acc 1, learning_rate 0.000175681\n","2023-06-27T18:13:41.980795: step 5748, loss 0.0584923, acc 1, learning_rate 0.000175629\n","2023-06-27T18:13:42.094465: step 5749, loss 0.0824336, acc 0.96875, learning_rate 0.000175577\n","2023-06-27T18:13:42.226696: step 5750, loss 0.0749651, acc 0.96875, learning_rate 0.000175525\n","2023-06-27T18:13:42.343204: step 5751, loss 0.060897, acc 0.96875, learning_rate 0.000175473\n","2023-06-27T18:13:42.460348: step 5752, loss 0.0160112, acc 1, learning_rate 0.000175422\n","2023-06-27T18:13:42.585104: step 5753, loss 0.104802, acc 0.9375, learning_rate 0.00017537\n","2023-06-27T18:13:42.700036: step 5754, loss 0.0338837, acc 1, learning_rate 0.000175318\n","2023-06-27T18:13:42.816259: step 5755, loss 0.0656897, acc 1, learning_rate 0.000175267\n","2023-06-27T18:13:42.934340: step 5756, loss 0.006121, acc 1, learning_rate 0.000175215\n","2023-06-27T18:13:43.061941: step 5757, loss 0.0737318, acc 0.96875, learning_rate 0.000175163\n","2023-06-27T18:13:43.189133: step 5758, loss 0.00729329, acc 1, learning_rate 0.000175112\n","2023-06-27T18:13:43.307452: step 5759, loss 0.0301876, acc 0.96875, learning_rate 0.00017506\n","2023-06-27T18:13:43.438811: step 5760, loss 0.0921864, acc 0.9375, learning_rate 0.000175009\n","2023-06-27T18:13:43.552840: step 5761, loss 0.0124158, acc 1, learning_rate 0.000174957\n","2023-06-27T18:13:43.677248: step 5762, loss 0.0617894, acc 1, learning_rate 0.000174906\n","2023-06-27T18:13:43.805451: step 5763, loss 0.0463783, acc 0.96875, learning_rate 0.000174855\n","2023-06-27T18:13:43.927167: step 5764, loss 0.062893, acc 0.96875, learning_rate 0.000174803\n","2023-06-27T18:13:44.054216: step 5765, loss 0.054553, acc 0.96875, learning_rate 0.000174752\n","2023-06-27T18:13:44.168151: step 5766, loss 0.0232608, acc 1, learning_rate 0.000174701\n","2023-06-27T18:13:44.297643: step 5767, loss 0.149701, acc 0.9375, learning_rate 0.00017465\n","2023-06-27T18:13:44.433941: step 5768, loss 0.0230897, acc 1, learning_rate 0.000174598\n","2023-06-27T18:13:44.558737: step 5769, loss 0.0621284, acc 0.96875, learning_rate 0.000174547\n","2023-06-27T18:13:44.681837: step 5770, loss 0.102107, acc 0.9375, learning_rate 0.000174496\n","2023-06-27T18:13:44.799746: step 5771, loss 0.0847503, acc 0.96875, learning_rate 0.000174445\n","2023-06-27T18:13:44.917282: step 5772, loss 0.0270321, acc 1, learning_rate 0.000174394\n","2023-06-27T18:13:45.049890: step 5773, loss 0.0218021, acc 1, learning_rate 0.000174343\n","2023-06-27T18:13:45.183154: step 5774, loss 0.00325869, acc 1, learning_rate 0.000174292\n","2023-06-27T18:13:45.291835: step 5775, loss 0.0381958, acc 1, learning_rate 0.000174241\n","2023-06-27T18:13:45.409857: step 5776, loss 0.0113003, acc 1, learning_rate 0.00017419\n","2023-06-27T18:13:45.531517: step 5777, loss 0.0109591, acc 1, learning_rate 0.000174139\n","2023-06-27T18:13:45.643001: step 5778, loss 0.0976347, acc 0.96875, learning_rate 0.000174088\n","2023-06-27T18:13:45.812439: step 5779, loss 0.124563, acc 0.9375, learning_rate 0.000174038\n","2023-06-27T18:13:45.934590: step 5780, loss 0.122444, acc 0.96875, learning_rate 0.000173987\n","2023-06-27T18:13:46.065492: step 5781, loss 0.0637949, acc 0.96875, learning_rate 0.000173936\n","2023-06-27T18:13:46.188037: step 5782, loss 0.0223743, acc 1, learning_rate 0.000173885\n","2023-06-27T18:13:46.305937: step 5783, loss 0.047097, acc 1, learning_rate 0.000173835\n","2023-06-27T18:13:46.445913: step 5784, loss 0.0316132, acc 1, learning_rate 0.000173784\n","2023-06-27T18:13:46.574711: step 5785, loss 0.0226176, acc 1, learning_rate 0.000173734\n","2023-06-27T18:13:46.684643: step 5786, loss 0.061051, acc 0.96875, learning_rate 0.000173683\n","2023-06-27T18:13:46.802166: step 5787, loss 0.0159003, acc 1, learning_rate 0.000173632\n","2023-06-27T18:13:46.932482: step 5788, loss 0.0270169, acc 1, learning_rate 0.000173582\n","2023-06-27T18:13:47.066928: step 5789, loss 0.180157, acc 0.9375, learning_rate 0.000173531\n","2023-06-27T18:13:47.196649: step 5790, loss 0.104346, acc 0.9375, learning_rate 0.000173481\n","2023-06-27T18:13:47.351708: step 5791, loss 0.127969, acc 0.96875, learning_rate 0.000173431\n","2023-06-27T18:13:47.547642: step 5792, loss 0.00752833, acc 1, learning_rate 0.00017338\n","2023-06-27T18:13:47.756134: step 5793, loss 0.103496, acc 0.9375, learning_rate 0.00017333\n","2023-06-27T18:13:47.972128: step 5794, loss 0.0281485, acc 1, learning_rate 0.00017328\n","2023-06-27T18:13:48.172916: step 5795, loss 0.044583, acc 0.96875, learning_rate 0.000173229\n","2023-06-27T18:13:48.385190: step 5796, loss 0.024183, acc 1, learning_rate 0.000173179\n","2023-06-27T18:13:48.577326: step 5797, loss 0.00464745, acc 1, learning_rate 0.000173129\n","2023-06-27T18:13:48.801913: step 5798, loss 0.039863, acc 1, learning_rate 0.000173079\n","2023-06-27T18:13:49.000374: step 5799, loss 0.00539824, acc 1, learning_rate 0.000173029\n","\n","Evaluation:\n","2023-06-27T18:13:50.340100: step 5800, loss 0.830132, acc 0.803388\n","\n","Saved model checkpoint to /content/gdrive/MyDrive/lightweighted-cnn/train/runs/1687888658/checkpoints/model-5800\n","\n","2023-06-27T18:13:50.720790: step 5800, loss 0.0757367, acc 0.96875, learning_rate 0.000172979\n","2023-06-27T18:13:50.938196: step 5801, loss 0.0128919, acc 1, learning_rate 0.000172929\n","2023-06-27T18:13:51.141780: step 5802, loss 0.0777519, acc 0.96875, learning_rate 0.000172879\n","2023-06-27T18:13:51.343495: step 5803, loss 0.0113221, acc 1, learning_rate 0.000172829\n","2023-06-27T18:13:51.546177: step 5804, loss 0.0737708, acc 0.96875, learning_rate 0.000172779\n","2023-06-27T18:13:51.742883: step 5805, loss 0.0183653, acc 1, learning_rate 0.000172729\n","2023-06-27T18:13:51.927860: step 5806, loss 0.00562662, acc 1, learning_rate 0.000172679\n","2023-06-27T18:13:52.140953: step 5807, loss 0.0128944, acc 1, learning_rate 0.000172629\n","2023-06-27T18:13:52.321397: step 5808, loss 0.0294516, acc 1, learning_rate 0.000172579\n","2023-06-27T18:13:52.509029: step 5809, loss 0.0249003, acc 1, learning_rate 0.00017253\n","2023-06-27T18:13:52.700273: step 5810, loss 0.01481, acc 1, learning_rate 0.00017248\n","2023-06-27T18:13:52.872585: step 5811, loss 0.109467, acc 0.96875, learning_rate 0.00017243\n","2023-06-27T18:13:53.061664: step 5812, loss 0.0432185, acc 1, learning_rate 0.00017238\n","2023-06-27T18:13:53.282478: step 5813, loss 0.136266, acc 0.96875, learning_rate 0.000172331\n","2023-06-27T18:13:53.468693: step 5814, loss 0.124477, acc 0.96875, learning_rate 0.000172281\n","2023-06-27T18:13:53.652730: step 5815, loss 0.0521385, acc 0.96875, learning_rate 0.000172232\n","2023-06-27T18:13:53.841974: step 5816, loss 0.158626, acc 0.90625, learning_rate 0.000172182\n","2023-06-27T18:13:54.019089: step 5817, loss 0.0199695, acc 1, learning_rate 0.000172133\n","2023-06-27T18:13:54.201187: step 5818, loss 0.0781242, acc 0.9375, learning_rate 0.000172083\n","2023-06-27T18:13:54.433744: step 5819, loss 0.0501436, acc 1, learning_rate 0.000172034\n","2023-06-27T18:13:54.648595: step 5820, loss 0.0315878, acc 1, learning_rate 0.000171984\n","2023-06-27T18:13:54.851999: step 5821, loss 0.0708827, acc 0.96875, learning_rate 0.000171935\n","2023-06-27T18:13:55.050597: step 5822, loss 0.264557, acc 0.90625, learning_rate 0.000171886\n","2023-06-27T18:13:55.242266: step 5823, loss 0.0310744, acc 1, learning_rate 0.000171836\n","2023-06-27T18:13:55.428074: step 5824, loss 0.119783, acc 0.90625, learning_rate 0.000171787\n","2023-06-27T18:13:55.622982: step 5825, loss 0.0385218, acc 1, learning_rate 0.000171738\n","2023-06-27T18:13:55.861821: step 5826, loss 0.021141, acc 1, learning_rate 0.000171689\n","2023-06-27T18:13:56.048685: step 5827, loss 0.0264091, acc 1, learning_rate 0.00017164\n","2023-06-27T18:13:56.261818: step 5828, loss 0.0282824, acc 1, learning_rate 0.00017159\n","2023-06-27T18:13:56.466106: step 5829, loss 0.0321771, acc 1, learning_rate 0.000171541\n","2023-06-27T18:13:56.664367: step 5830, loss 0.0294539, acc 1, learning_rate 0.000171492\n","2023-06-27T18:13:56.861181: step 5831, loss 0.0540921, acc 1, learning_rate 0.000171443\n","2023-06-27T18:13:57.024850: step 5832, loss 0.0305047, acc 1, learning_rate 0.000171394\n","2023-06-27T18:13:57.196801: step 5833, loss 0.0784105, acc 0.9375, learning_rate 0.000171345\n","2023-06-27T18:13:57.362015: step 5834, loss 0.084108, acc 0.96875, learning_rate 0.000171296\n","2023-06-27T18:13:57.550833: step 5835, loss 0.00479396, acc 1, learning_rate 0.000171247\n","2023-06-27T18:13:57.729086: step 5836, loss 0.00482916, acc 1, learning_rate 0.000171199\n","2023-06-27T18:13:57.936567: step 5837, loss 0.0849018, acc 0.9375, learning_rate 0.00017115\n","2023-06-27T18:13:58.109709: step 5838, loss 0.0156244, acc 1, learning_rate 0.000171101\n","2023-06-27T18:13:58.258417: step 5839, loss 0.00108437, acc 1, learning_rate 0.000171052\n"]}],"source":["! python3.6 Nadamax_optmized_train.py"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":657,"status":"ok","timestamp":1687891439859,"user":{"displayName":"Milad Mahaki","userId":"06106732680968882418"},"user_tz":-210},"id":"PFQNE40h4YB1","outputId":"c548b784-7e53-4a1b-d08e-2f70d415c2bd"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/gdrive/MyDrive/lightweighted-cnn/train/output\n"]}],"source":["cd output"]},{"cell_type":"code","execution_count":68,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":455},"executionInfo":{"elapsed":1539,"status":"ok","timestamp":1687891905303,"user":{"displayName":"Milad Mahaki","userId":"06106732680968882418"},"user_tz":-210},"id":"VikXys4o4aGt","outputId":"e2f9381a-7451-4546-8615-1d7b37ee6cba"},"outputs":[{"data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAj4AAAG2CAYAAAB/OYyEAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABhyElEQVR4nO3deVxU5f4H8M/MwMywyLCvsoo7CgiCqLkkRuq1NCu1BSKzW2la3F8lZZJaYZvXupFey6Uylyw1u5pmmJlFmiDumuaCqYDrDKAOwpzfH+SRkQEZGGZhPu/Xa145Z55zzvccJs6H55zzHIkgCAKIiIiI7IDU0gUQERERmQuDDxEREdkNBh8iIiKyGww+REREZDcYfIiIiMhuMPgQERGR3WDwISIiIrvB4ENERER2g8GHiIiI7AaDDxEREdkNiwafrVu3Yvjw4QgMDIREIsGaNWsaPe8vv/wCBwcHxMTEtFh9RERE1LpYNPhUVFQgOjoaOTk5Rs13+fJlpKamYtCgQS1UGREREbVGEmt5SKlEIsHq1asxYsSI27YdM2YM2rdvD5lMhjVr1qCwsLDF6yMiIiLb52DpAoy1aNEiHDt2DEuWLMHrr79+2/ZarRZarVZ8r9PpcPHiRXh5eUEikbRkqURERGQigiCgrKwMgYGBkEqbfsLKpoLPkSNHMGXKFPz8889wcGhc6dnZ2Zg+fXoLV0ZERETmcOrUKbRt27bJ89tM8KmursZDDz2E6dOno0OHDo2eLzMzExkZGeJ7tVqNkJAQnDp1Cm5ubi1RKhEREZmYRqNBcHAw2rRp06zl2EzwKSsrw86dO7Fr1y5MnDgRQM1pK0EQ4ODggO+//x533nlnnfkUCgUUCkWd6W5ubgw+RERENqa5l6nYTPBxc3PD3r179aZ99NFH2Lx5M7766iuEh4dbqDIiIiKyFRYNPuXl5Th69Kj4/vjx4ygsLISnpydCQkKQmZmJ06dP47PPPoNUKkVUVJTe/L6+vlAqlXWmExERERli0eCzc+dODBw4UHx/41qctLQ0LF68GGfPnkVRUZGlyiMiIqJWxmrG8TEXjUYDlUoFtVrNa3yIiFqp6upqXL9+3dJlkJHkcnm9t6qb6vhtM9f4EBER3Y4gCCguLsbly5ctXQo1gVQqRXh4OORyeYutg8GHiIhajRuhx9fXF87Ozhyo1obodDqcOXMGZ8+eRUhISIv97Bh8iIioVaiurhZDj5eXl6XLoSbw8fHBmTNnUFVVBUdHxxZZh0UfUkpERGQqN67pcXZ2tnAl1FQ3TnFVV1e32DoYfIiIqFXh6S3bZY6fHYMPERER2Q0GHyIiIrIbDD5ERERWIi8vDzKZDMOGDbN0Ka0Wgw8REZGVWLBgAZ599lls3boVZ86csVgdlZWVFlt3S2PwISIisgLl5eVYsWIFnn76aQwbNgyLFy/W+/zbb79Fz549oVQq4e3tjZEjR4qfabVavPTSSwgODoZCoUBkZCQWLFgAAFi8eDHc3d31lrVmzRq9C4lfe+01xMTE4JNPPkF4eDiUSiUAYMOGDejbty/c3d3h5eWFf/zjH/jzzz/1lvXXX39h7Nix8PT0hIuLC+Lj47F9+3acOHECUqkUO3fu1Gs/Z84chIaGQqfTNXeXNQnH8SEiolZLEARcvd5yt0bXx8lRZvQdSl9++SU6deqEjh074pFHHsFzzz2HzMxMSCQSrFu3DiNHjsQrr7yCzz77DJWVlVi/fr04b2pqKvLy8vDBBx8gOjoax48fx/nz541a/9GjR/H1119j1apVkMlkAICKigpkZGSge/fuKC8vx7Rp0zBy5EgUFhZCKpWivLwc/fv3R1BQENauXQt/f38UFBRAp9MhLCwMycnJWLRoEeLj48X1LFq0CI899li9j6ZoaQw+RETUal29Xo0u0zaafb0HZqTAWW7cIXbBggV45JFHAAB333031Go1fvrpJwwYMABvvPEGxowZg+nTp4vto6OjAQB//PEHvvzyS2zatAnJyckAgIiICKNrrqysxGeffQYfHx9x2qhRo/TaLFy4ED4+Pjhw4ACioqKwdOlSnDt3Dr///js8PT0BAJGRkWL7J554Ak899RRmz54NhUKBgoIC7N27F998843R9ZkKT3URERFZ2OHDh7Fjxw6MHTsWAODg4IDRo0eLp6sKCwsxaNAgg/MWFhZCJpOhf//+zaohNDRUL/QAwJEjRzB27FhERETAzc0NYWFhAICioiJx3bGxsWLoudWIESMgk8mwevVqADWn3QYOHCguxxLY40NERK2Wk6MMB2akWGS9xliwYAGqqqoQGBgoThMEAQqFAh9++CGcnJzqX1cDnwE1D/4UBEFvmqEn17u4uNSZNnz4cISGhuLjjz9GYGAgdDodoqKixIufb7duuVyO1NRULFq0CPfddx+WLl2K999/v8F5WhqDDxERtVoSicToU07mVlVVhc8++wzvvfce7rrrLr3PRowYgWXLlqF79+7Izc1Fenp6nfm7desGnU6Hn376STzVVZuPjw/KyspQUVEhhpvCwsLb1nXhwgUcPnwYH3/8Me644w4AwLZt2/TadO/eHZ988gkuXrxYb6/PE088gaioKHz00UeoqqrCfffdd9t1tySLnuraunUrhg8fjsDAQEgkEqxZs6bB9tu2bUOfPn3g5eUFJycndOrUCf/+97/NUywREVEL+N///odLly5h3LhxiIqK0nuNGjUKCxYsQFZWFpYtW4asrCwcPHgQe/fuxVtvvQUACAsLQ1paGh5//HGsWbMGx48fx5YtW/Dll18CABITE+Hs7IyXX34Zf/75J5YuXVrnjjFDPDw84OXlhfnz5+Po0aPYvHkzMjIy9NqMHTsW/v7+GDFiBH755RccO3YMX3/9NfLy8sQ2nTt3Rq9evfDSSy9h7Nixt+0lamkWDT4VFRWIjo5GTk5Oo9q7uLhg4sSJ2Lp1Kw4ePIipU6di6tSpmD9/fgtXSkRE1DIWLFiA5ORkqFSqOp+NGjUKO3fuhKenJ1auXIm1a9ciJiYGd955J3bs2CG2mzt3Lu6//34888wz6NSpE8aPH4+KigoAgKenJ5YsWYL169ejW7duWLZsGV577bXb1iWVSrF8+XLk5+cjKioKzz//PN555x29NnK5HN9//z18fX0xdOhQdOvWDbNmzRLvCrth3LhxqKysxOOPP96EPWRaEuHWE38WIpFIsHr1aowYMcKo+e677z64uLjg888/b1R7jUYDlUoFtVoNNze3JlRKRETW6Nq1azh+/LjeODRkHWbOnImVK1diz549DbZr6GdoquO3Td/VtWvXLvz666/NvpKdiIiITK+8vBz79u3Dhx9+iGeffdbS5QCw0eDTtm1bKBQKxMfHY8KECXjiiSfqbavVaqHRaPReRERE1PImTpyIuLg4DBgwwCpOcwE2Gnx+/vln7Ny5E/PmzcOcOXOwbNmyettmZ2dDpVKJr+DgYDNWSkREZL8WL14MrVaLFStW1Lnux1Ks+x6/eoSHhwOouYWvpKQEr732mjjo060yMzP1rkLXaDQMP0RERHbKJoNPbTqdDlqttt7PFQoFFAqFGSsiIiJLspJ7dqgJzPGzs2jwKS8vx9GjR8X3x48fR2FhITw9PRESEoLMzEycPn0an332GQAgJycHISEh6NSpE4CacYDeffddTJo0ySL1ExGR9XB0dAQAXLlyxeJjxVDT3BgRuiVPi1k0+OzcuRMDBw4U3984JZWWlobFixfj7Nmz4vNAgJrenczMTBw/fhwODg5o164d3nrrLfzzn/80e+1ERGRdZDIZ3N3dUVpaCgBwdnY2+gnpZDk6nQ7nzp2Ds7MzHBxaLp5YzTg+5sJxfIiIWi9BEFBcXIzLly9buhRqAqlUivDwcMjl8jqfmer4bfPX+BAREd0gkUgQEBAAX19fgw/iJOsml8shlbbsDecMPkRE1OrIZDKruX2arItNjuNDRERE1BQMPkRERGQ3GHyIiIjIbjD4EBERkd1g8CEiIiK7weBDREREdoPBh4iIiOwGgw8RERHZDQYfIiIishsMPkRERGQ3GHyIiIjIbjD4EBERkd1g8CEiIiK7weBDREREdsOiwWfr1q0YPnw4AgMDIZFIsGbNmgbbr1q1CoMHD4aPjw/c3NyQlJSEjRs3mqdYIiIisnkWDT4VFRWIjo5GTk5Oo9pv3boVgwcPxvr165Gfn4+BAwdi+PDh2LVrVwtXSkRERK2BRBAEwdJFAIBEIsHq1asxYsQIo+br2rUrRo8ejWnTpjWqvUajgUqlglqthpubWxMqJSIiInMz1fHbwYQ1mZ1Op0NZWRk8PT3rbaPVaqHVasX3Go3GHKURERGRFbLpi5vfffddlJeX48EHH6y3TXZ2NlQqlfgKDg42Y4VERERkTWw2+CxduhTTp0/Hl19+CV9f33rbZWZmQq1Wi69Tp06ZsUoiIiKyJjZ5qmv58uV44oknsHLlSiQnJzfYVqFQQKFQmKkyIiIismY21+OzbNkypKenY9myZRg2bJilyyEiIiIbYtEen/Lychw9elR8f/z4cRQWFsLT0xMhISHIzMzE6dOn8dlnnwGoOb2VlpaG999/H4mJiSguLgYAODk5QaVSWWQbiIiIyHZYtMdn586diI2NRWxsLAAgIyMDsbGx4q3pZ8+eRVFRkdh+/vz5qKqqwoQJExAQECC+Jk+ebJH6iYiIyLZYzTg+5sJxfIiIiGyPqY7fNneNDxEREVFTMfgQERGR3WDwISIiIrvB4ENERER2g8GHiIiI7AaDDxEREdkNBh8iIiKyGww+REREZDcYfIiIiMhuMPgQERGR3WDwISIiIrvB4ENERER2g8GHiIiI7AaDDxEREdkNBh8iIiKyGxYNPlu3bsXw4cMRGBgIiUSCNWvWNNj+7NmzeOihh9ChQwdIpVI899xzZqmTiIiIWgeLBp+KigpER0cjJyenUe21Wi18fHwwdepUREdHt3B1RERE1No4WHLlQ4YMwZAhQxrdPiwsDO+//z4AYOHChS1VFhEREbVSFg0+5qDVaqHVasX3Go3GgtUQERGRJbX6i5uzs7OhUqnEV3BwsKVLIiIiIgtp9cEnMzMTarVafJ06dcrSJREREZGFtPpTXQqFAgqFwtJlEBERkRVo9T0+RERERDdYtMenvLwcR48eFd8fP34chYWF8PT0REhICDIzM3H69Gl89tlnYpvCwkJx3nPnzqGwsBByuRxdunQxd/lERERkYySCIAiWWvmWLVswcODAOtPT0tKwePFiPPbYYzhx4gS2bNkifiaRSOq0Dw0NxYkTJxq1To1GA5VKBbVaDTc3t6aWTkRERGZkquO3RYOPJTD4EBER2R5THb95jQ8RERHZDQYfIiIishsMPkRERGQ3GHyIiIjIbjD4EBERkd1g8CEiIiK7weBDREREdoPBh4iIiOwGgw8RERHZDQYfIiIishsMPkRERGQ3GHyIiIjIbjD4EBERkd1g8CEiIiK7weBDREREdoPBh4iIiOyGRYPP1q1bMXz4cAQGBkIikWDNmjW3nWfLli3o0aMHFAoFIiMjsXjx4havk4iIiFoHiwafiooKREdHIycnp1Htjx8/jmHDhmHgwIEoLCzEc889hyeeeAIbN25s4UqJiIioNXCw5MqHDBmCIUOGNLr9vHnzEB4ejvfeew8A0LlzZ2zbtg3//ve/kZKS0lJltmonL1TAQSZFkLuTpUtptKOl5Xhl9V68MTIK3+0tRv+OPgj1csGf58ohAeDtqsDPR87DVemA6LYqhHq5iPOeK9Pi8pVKRPq6YlXBaVRW69DBrw0ulGuhuVaFgR194ObkiPyTl+AokyDI3Rnl2iq083HBDwdLcbhYA582Cng4yzGwky8cZTf/dvjzXDnaKBzg66YEAFRoq/DnuXK4Khyw88QlKOUy7Dl1GTtPXsID8W1RrL6GEbFBaOfjCkEQ8MPBUqzdfQZxIe5Yu/sMugWp0NHfDQEqJbRVOkT6umLZjiKcVV+Fi9wBzw/ugN6zNuM/Y2Nx6UolooJU8HSW47djF6BwlMLLRYGii1fQwa8Nvs7/C7v/uoxeEV7ifkiM8IT6ynUkhHvi1KWr8HB2xL7TGnRvq8LBYg2iAlVYU3gaqwpOAwDujQlE+bUqRPq6YtOBEkQHu+PAGQ26BLohyN0JZ9RXce16NYI9nOEgk+CzvJPo6NcGAgCpBOgc4IaLFZVwc3KEwkGKwlOXcV+PtogL8cC+M2pcrKhEmJcz/rp0FX+UlOGPknJcqazCwI6+6N7WHYt/PQ6pRIK7uvpjbeFpOMsd4OggxfUqHTr6t4EgCDh2vgLbj11EZbUOADCsewCi26qQf/ISNu4vAQBEeLvAu40CVyursfe0Gnd18UPRxStwlEnRO9IL87cew11d/HClshqhXs7Y85cae/5SY1AnX7RROkAqkeCs+hr2n1GjW1sVugaqoLl6HTuOX0RbT2f8evQ8qnQCVE6OkEqADn5t8No9XfFZ3kn8UVKGootXEKBS/v29coWjTIK9p9UIUDnh4FkNyrVVGNTJDz8cLBG/Wz3DPNDOxxX7z2iw97Qa0cHuOFpShorKagyJ8sfhkjLodAJOXbqKap0Ab1cFgtyV2P2XGgDQ0a8N7o0NxNwf/4REAgR7OuPq9WooHWS4r0cQth+/iDZKB5y6eAW/n7iE6GB3tPd1xb7Taly7Xg25gxRhXi74/kAJgtydcPryVcikEiR39sXG/SWI8HFB+bUqXL5yHd3aqnDyQgXOl1eKdXYNVKFaEHDwrAZXKqvF7YoKcoOPqwIAcObyNUgkwKHiMgBArwhPuCkdcelKJX4/cQkJ4Z5o6+6EXacui/+/+rZRINjTGacvXUWwpxPkDlL8cvQC7urih/PlWhQUXQb+/p2gcnJAWw9n/PTHOXi7ynG+vBIAMCTKH3tPq+Eok6KySgfNtesou1YFAOgS4IYDZzUAgDZKB5Rdq4KrwgFtPZxwuKQMDlIJQr1cIJdJ4eumgIvCAVXVOvx+4hIqtFW4JzoQFyoqcb1ah5+PnEc7Hxf8ea4CABAT7I79Z9Roo3REgEoJV4UDPF3kUF+9jiOl5Si/VoXYEHf8+ucFdG+rwp6/f5YAkBThhXAfFyzdXgQXuQzOCge093XF3tNqSCUSqK9eR68IT1RW6aC+eh1/nqvAXV388NuxCwjzdkG/9j7YefIigtydcfCsBuqr1+HlKsexcxUo11ahXwcfbP3jHKQSQCcA0cHuKLt2HeFeLijWXMP+MzX7RO4gRXRbFXzdlFi35yz83ZS4VlWNth5OmDAgEkO6BRj/C94MJIIgCJYuAgAkEglWr16NESNG1NumX79+6NGjB+bMmSNOW7RoEZ577jmo1WqD82i1Wmi1WvG9RqNBcHAw1Go13NzcTFW+TarQVqFrVk1v2bE3h0IqlVi4osYJm7LOqPb7p6fAReGgN+/TA9ph7pY/Dba/P64tvsr/S2/a5EHt8X7uEb1pj/YKxcwRUQCAUs01JLyZCwA4MWsYAOCuf/+EP0rKb1vfvukp+P3ERaQv+t2IrSIism43fheaikajgUqlavbx26Yubi4uLoafn5/eND8/P2g0Gly9etXgPNnZ2VCpVOIrODjYHKXahNKym4Gw2jryb4s4V2s7b6gv9ACoE3oA1Ak9APD5byfFfx/8+6/U2hoTegCgRHMN6/ecbVRbIiJqHpsKPk2RmZkJtVotvk6dOmXpkqxSK849ZqFrxg7U6QTouP+JiMzCotf4GMvf3x8lJSV600pKSuDm5gYnJ8PXqCgUCigUCnOUZ3Ns48SWjWhGcNEJgJWccSYiavVsqscnKSkJubm5etM2bdqEpKQkC1VEVKNZPT6C0KpPNRIRWROLBp/y8nIUFhaisLAQQM3t6oWFhSgqKgJQc5oqNTVVbP/UU0/h2LFjePHFF3Ho0CF89NFH+PLLL/H8889bovxWRWhOl4UZWWvPSHNOVekEnuoiIjIXiwafnTt3IjY2FrGxsQCAjIwMxMbGYtq0aQCAs2fPiiEIAMLDw7Fu3Tps2rQJ0dHReO+99/DJJ5/wVvYmktjgua6mBARzZIrmXePTvPmJiKjxLHqNz4ABAxr8C97QqMwDBgzArl27WrAq+3Trj6GqWgcHWcO5uHabxrSvWU9N74ZMKkG1ToBUUjOUwa20VdVwkEohu+UW+6YEhGqdDlcra8YiMbXKKh2kEuBqrbFJrl2vrlN3Q8quXccVbZXJayMiorps6uJmajnbjpxHcpeaoQLe2XgIH/98HOsn9UWkbxuD7c+VaTHw3S0Y2s0f98YEIW3hDsy4NwoPJYY0uJ5HFmzHifNX8P3z/TDk/Z8RoFJixT/1r9GqPU7PgRkpcJbf/Jo2pWMkefZW42dqpA5Tv6szrdOrG4xaxkOfbDdVOUREdBs2dXEztZynluSL/8758U9UVunw7sY/6m3/xfaTKNdW4cudf+GpJfmo0gl4efXe267nl6MXcPryVXyx/SSKLl7B9uMXG2y/9Y/zeu95SoiIiJqDwceOSWrd0N6sOGHGLMLcQ0REzcHgY8ds8eJmW7n7jIiIrBODDzWbOaMIb/smIqLmYPAhAM0bH6dlx9bRX7a1juNDRES2gcGHmo09PkREZCsYfAhA88KLOTth2ONDRETNwXF87Fjti5sFoWb8nE9S48VpVToBnV/dgKvXawbnuzcmEJeuXMfWP87pLefG58DNMXi6t1Vhz1/qetf95vpDevM4OcowumcwFv96Qq/dU0sKxH/HhrhjYVrPxm8gERHRLRh8SM8Tn+0U//3DwRK9z74pPNPo5TQUegy5er26Tui51a6iyxzHh4iImoWnusimMPZQY6icHE22rN7tvPBY7zA82S/CZMtsrg5+rnrvn0/u0Oh5Px+XgP4dfMT3XzyRqPd5lwC3JtXk7arA0icSIb/l0TW7s+5q0vJu+CGjP2bd1018/2ivUKOX8fOLA7F0fCLu7upv8PMva40er3CQ6r2v7fNxCXghpaP4/rHeYfj++X4Y2NHHYHtDnBxlesur7dDMu/FDRn9s+b8BODTzbnz0cA+M6tEWbkrDfRRfPJGI98fE6E1b/UxvTLozUm/awRl333b4kun3dMX3z/er9/OtLwzE4vSe2Picfpt37u+Or55KwrLxvfSmH3797oZXaEEMPmRT2ONDjfHWqO4mW1akryteu6cr7vr7kS7WoPMt4cRJ3vhf5Xe098HYhJuPlukV4aX3+TMD2zWpppSufugd6V3nsTXNDaGRvq6Q1nr2XTsfF6OXEezpjN7tvJEQ7mnw89rTgz2d6wTLG+5o74MJA2+GiqR2Xujg1wYp9QQqQ54ddHP+O9r7wFl+MwgpHWWI9HVFmLcLlI4yDO0WgPcejIa7s7zOcuQyKfpEeuPemCC96V0C3ZBxV0e9aU5yGfq1bzicpfUOQwc/w48oAoAQL2cM6OiLjv76bR6ID0Z8mCeS2ul/jxQOMlgrBh87ZujhoNaOuYcaw5Rf7Rth25q+erIW/H9X2sRlt+igFmb+H7/2qPYNt6thTHW3bkqTf5L1zNjY2u0Zgw/ZFAYfaoymHrwNscrvnAmPbbcuqsnBpwX3U+1lN+cPtpYqsTnbbuo/QKX1LM4av8aWwuBDNoWnusjcrPEbd+tf9cb/b3FzhluPu00/Dv/dM2bF/482pjZj6jfXlhrzqJ76gpQ1/1zMzSqCT05ODsLCwqBUKpGYmIgdO3bU2/b69euYMWMG2rVrB6VSiejoaGzYsMGM1bYettghyuBD5nbjK2dNX736/qpvilsPlKbsLTOV2rveCsszKpjcGkCaujn1zWfK78Zta7DCn0VjWDz4rFixAhkZGcjKykJBQQGio6ORkpKC0tJSg+2nTp2K//73v/jPf/6DAwcO4KmnnsLIkSOxa9cuM1duPqVl1/DRlqM4V6Y12TKvVlZj/tZjJlueufR960dLl0A2wLS/j60o8fyt+eGk/vmbe+Bsib1lqtBp6vAqXuNjxHLrtG3E/jZ03U5934H6e3xuvx5j2WjusXzwmT17NsaPH4/09HR06dIF8+bNg7OzMxYuXGiw/eeff46XX34ZQ4cORUREBJ5++mkMHToU7733npkrN5/xn+7E2xsO48nPd96+cSPN3nT4tuPmENmqUC/n27bxbaNo1LJ0upr/mvNUgc9tauvb3lvvfXSwu1HLb2j/NGbfGRJjoIaeYR63nS/I3em2bUzV03vrHUn1UTjePDTe2cm3Zl4DdzyF/L2vmlPd4L/vFoxo4G61AX/fLl/7ezEiNlD8t9Lx9ofyXhGG72irXYOxbPEGGcDCAxhWVlYiPz8fmZmZ4jSpVIrk5GTk5eUZnEer1UKpVOpNc3JywrZt2+ptr9Xe7CnRaDQmqNy8dv89GOCuossmW+bOk5dMtiyynIEdfXCktBx/Xbpq6VL0DOsegG5BKsz67pDBz59P7gAnuVQcwfuFlI54Z+PhZq3T00WO6LYqDOjoi/Z+bTBlSKc66x/azR9P94/E0XNlSO7sh8W/nMCOExfh7ixH9yAV2igd4KdSIn3R7+I89Z3G+GZCH+w/o8HLq/fqTXd3dsTlK9cB1Bwsz6qvoleEF74/UGJoMbg3JhA+rgpEBanQNdANBUWXcE90EL4u+Avuzo5Y/MsJPNgzGF4ucuT9eQECgOHRgZBJJTh+vgId/NqgV4QX5j3SA16uCuz9S41dpy7j2901A45GeLvg2PkKAICrouZXfucAN+Q81AP+qprfpcvG98L/9pzBkKgARPq2wfPJHbDo1+PidtQ2675u2LC/GHd18Uf+yUt4IL4tTpyvwP1xwTX7q9bu+u+j8XXmf/Hujnh7w82f9apnemPOD3+ga6AKg7v4IfHNXAA14900NK5MU9zR3hvvPRCNs+qr2HnyEnpFeKFvpHeddkpHGT4fl4AqnYD4UA+sKTyjNwbQqmd648zlq+jk//ewArU2+psJfXBvzi/i+59eGIAXVu7BjhMXDdY0494oxIZ4IKWB8JE5pDM6+LXBoM6++OXoBXy7+wym3xNVax0D8dLXe/TGOPr5xYGYsLQA2X+PgfRkv3Y4V6aFyskRgzr74cSFCvSN9Mb6vWdxT61b4v/3bF/8UVKGUC9nlGi00AkCAlS3D6cAMP/RODz5eT6+ftrwOEjWwqLB5/z586iuroafn/4P3M/PD4cOGf6FmZKSgtmzZ6Nfv35o164dcnNzsWrVKlRXVxtsn52djenTp5u8diJrMGd0LFTOjuKjQurjqnBAubaq2et774FovL7uAC7dckB894Fo/N/K3eL7nId6AEC9wWd8v3AoHGRi8Okb6d1g8Jk4MBIf/ni0wdoKXh2s9/6p/u3qrP+jh+MAAN3aqgAAzw5qb3BZCWGe4oGqvs6GUC9nRAe71wk+hdPuEn8eL97dEYM61/x+M/QzcpRJ8P6YWL1p7f/uWXjk74PYP7rf/Mv+xrIAYGi3AL357o6qed8zrOYv+xvB5/G+4Zi6Zh8AoHPAzV6LYd1vzp/UzktvHJbJye0xObk9xn+2E5tuCWxjEkIw5u9xgG6M2VN7LKDaQdHTRX/8mbdHdceDPYP1go+fmxLZ99WMu6Stuvl7fP3kOxDs2bQelU8fT0DawrrXikokEoyKa9vgvDfWdUetcW9uHTSxR4gHeoQY7s2KDnZHsKcTTl2s+WMk1MsFYxKCb36fbmnvqnC47aCMTnKZ+H24P64t7r9lG/zclFicrj8YYrCnM9ZO7Cu+lztIMf3em2HpRi/ho0lhevNFBakQFaRqsJ4bbu3vuaurP07MGtaoeS3J4qe6jPX++++jffv26NSpE+RyOSZOnIj09HRIpYY3JTMzE2q1WnydOnXKzBUTtRxJI/8PNtVpGlP1bEsl+lctWHOPuXDLf22NNe/bW9U7Bk2t729jNsfcm9yccXxsmS19t2qzaPDx9vaGTCZDSYn+XxQlJSXw9zc8EqaPjw/WrFmDiooKnDx5EocOHYKrqysiIgwPJ69QKODm5qb3ImotzP17RyIxzXn9muXUem/Fl0nWd6AyxQHM3AdBY392TamveWPa1LPMpi/SLG63zbU/N+YOMGoZFg0+crkccXFxyM3NFafpdDrk5uYiKanhc4RKpRJBQUGoqqrC119/jXvvvbelyyWyOo29u8faftXeGnSs+S/HG71lreEvdYvv5iYWoNMZt/PN/X2y1zFyrPkPloZY/OnsGRkZSEtLQ3x8PBISEjBnzhxUVFQgPT0dAJCamoqgoCBkZ2cDALZv347Tp08jJiYGp0+fxmuvvQadTocXX3zRkptBZBGN/QVvqt/LEhP9qpOaqOfIHG6e6jJ+J1rD8VB/1GOj5zZ+fUbPYfvscZttmcWDz+jRo3Hu3DlMmzYNxcXFiImJwYYNG8QLnouKivSu37l27RqmTp2KY8eOwdXVFUOHDsXnn38Od3d3C22BeWmrqsWHvxVduAKpFGjrcfP2U0EQsPe0Gu18XOGiqP/He7S0vMVrpZZn7sHmTLU6Y0OP2TNSrfW1pr/mjY2tpj7V1dQfo7FlNCuem+DHXWdk7dr/bj1fJyvoQmwaiwcfAJg4cSImTpxo8LMtW7bove/fvz8OHDhghqqs07NLd2F+ajyuVFah3zs1g/kdfWMIHGQ14fB/e87i2WW70N7XFZsy+htcxunLV1F2rfl3+JDlNTYQhHu74MBZ0wzlYGidbkrjfpXcuggnecNPcvZyqft06pbU1t0JN+4J8nOrueW7jUL/KeMy2e13vmut/RKgUuKs+preHXYNjd1iKh61nuwd2Igxc2oLcFfevtEtGhof6caT2uUOUlRW6RDiqT9mUO09qnC4+Qdv7W3waMR3wVXpADelAzTXqho9XtMNwZ7Gj2PkccvT00O9nFF08Yr4vvYT6r1czftdbkkR3i3//W0JVhF8qPFujAVyobxSnFZZrRODz+pdpwEARxro0dl3Wt2CFVJTqZwcob5ad9yUhtz4y/KLJxLx8CfbDbbp38EHM++Nwq9/nseUVTdvvb4nOhBr/77lGai5/XveT38aXXdbDyckd/bD1GGd8fq6g1j4WN2xWwAgLSkUzgoHuCkdIf17eODMIZ1wsaIS7XxcDc4T5O6ESYMiMTK2Lfae1iDCxwXvbDyM/h18sKvoEjR/B/j5j8YZnH9Rek9xTJ63R3Vv9DZN/UcXbNxfDCe5AybeGQkAiApyw+N9wvF1wV9I7xMGN2XNwSxreBdM/1b/j7GZ93bFkdJyJIbfHDTu83GJ+PemP/DsoEhUVQuY+9OfeDGlY6NrMtbb93dHwclLuDvKH0vGJeLLnacwdVhno5bxwl2dcKSkHNuPGx6DxpB/9o/AyQsVGFLrdvtZ93XD7r/USP77dvw1z/RBzo9H8a+7OujN6yCT4oWUjqjQVumFtH90D8Cvf55HYrgXhkQFYEzP8+gR6oEXv9ojtpk8qD3cnR1RdPEKotuqsPKp3vgg9wieH2x4yIJbrXwqCZ/+egKv/qNLo7f11voSwmtu63/n/pphHx7rHQYAGNTJF2MTQhDdVoX7erTF7lNq9OtQd/wgW/HtxL6Yt/VPvJTSydKlNIlEaE39uI2g0WigUqmgVqtt5g6vW8f/ODFrGE5dvII73q7p8TkwIwXO8poM+/ji37H5UKnYzpDv9xfjyc/zW7Biqs+hmXej06uGny13Ytaw247HAwAvD+0kjn9Tu7fv3pxfsPvU5Trt909PEU97Dnx3C47/PZjdrevLGt4F6X3Csf+MGsM+qBkQ9EaYueGDsbGY8e0BnC/XistoyI3ld2+r0htTpKG2N9xu2d1f2ygGH0uPHTLsg5+x/4zGKmppCV/n/4V//T1OkzVt343vTKiXM356YaCFq6GWZqrjt82N40PNZysXlbZGpt71jflZShp5vYqhJZnqu9Lav3Gt/c/HVr55ZGcYfOxQaz8IWTNT3/7ZmAdK1r4AuqEDWKNCFKz71nOyT/xKkjEYfGyU3i2qtf63b8yZSx64LMcSPT61Nbdngt8dw1p7j4idXRFBrRyDjx3iwctyLLHrG/vzbky7Jo/jwy8dtSCevidjMPhYiCAIqKrW1ZluaJoxy6yu9YdZVbVO/Eut9nL5x5vlWOIXtF6PYCP6Jmx1NFZLau09Iq1768jeMPhYyDNfFCDhzVyUXbt5+3Kp5hqip3+PzFV7G5izfhOX7sLWP86J7xPezMXTSwpQeOoyOk/bgP/+9CeqqnUY9+nOZtdPTWOKSNGcYCJrIHjdCGUNZTOpBHCUWcevDQcrqQMAZI252MqGmXugTGO18t1PJmY9vznszHf7inGxohIb9998QOuneSdQUVmNZTuKmrTMdXvP6r2/WFGJDfuLMeXrPbheLSD7u0M49vetzPagfwefej/zcHas97OWdOvxY9o/usDLRY5F6T0BAEO73Xw4r5+bAkvGJcK3jQL+NwbRUzogtXcougWpMCTK8IN8AeDxPuGIC/XAgI4+kNcaCO6DsbHwdlXgnftrxrR59u8xatooHHBfbBAAoINfG7G9IAhY/HdtADCwky9yHu4Bb1c53nsguvHb3Yg2d3etf3sM+Tg1Dt6ucrw/Jsao+VrCO/dHw9tVgTdHdrN0KS1iWLcARHi7YGxCiKVL0fP2qO7wdlXg/TGxli6FbAgHMLSw2l3kxvSWN/UJv628R170Q0Z/RPq6GhwbRhAESCQS8bNJg9rjg9wjAIDkzr744WBpneUdzx6K8Mz1etMSwz3Fgd1eGdoZPx89r9fj1hgDO/kivU+Y2Nvy0cNxYn03/rv95UHie6CmZ2btxD4NnjabNryLOH9t3du64/dXBonT/3VXR2QM7iAuF6jbezGgoy+OZw8V28QEu+P3V5JNftpu3qNxWPLbSUxds69R7eNCPVukjqboEuimt19bGye5DLn/6m912/dgz2A8EN/W6uoi68bgY0WamkluF4Ls8ZdCQ13ft+6Phk7/1DdPUxlazq3Tbp5yMvzfxtZTX5v61mfMslrqO2XsYq3pu21NtbQEa90+a62LrBdPdVmYuR9e19SeIltjzC9DU1wfYC/7tal4bCIia8Hg0wrYy+krYxgTZqR6jRs/462htSl39jAPEBGZF4OPFWmpXgN7PLgacxdKk3sjBIP/JCIiK8bgY02aePTkQbcuY8KMJW/VtZdTQHaymURkA6wi+OTk5CAsLAxKpRKJiYnYsWNHg+3nzJmDjh07wsnJCcHBwXj++edx7do1M1VrYg30Giz57SSeXlL3KephU9ah/ztbxPczvz3QqKd6A8Ddc35uQpG2x5hrfBpzcbMhtXvoak51NWkxVs1U28QLUInIWlg8+KxYsQIZGRnIyspCQUEBoqOjkZKSgtLSurcUA8DSpUsxZcoUZGVl4eDBg1iwYAFWrFiBl19+2cyVt7ypa/bhu33Ft223YucpM1RjW7xc5I1ue3et8XAeSgxu1Dyd/NsgrXeY+F6AgEd6hTZ6nTf4tlEaPY85eP69/wZ0rH8spJbQN9IbAOAil5l1vURkP4y+nT0sLAyPP/44HnvsMYSENH8wq9mzZ2P8+PFIT08HAMybNw/r1q3DwoULMWXKlDrtf/31V/Tp0wcPPfSQWM/YsWOxffv2ZtdiaS017H1r/WN73/QUXL5SicoqHa5UVkPpKIW7sxw6QYDS8fYHzsJpg6Gt0sHPTYnfMgfByVEGlbMjNv+rP+587yexXWK4p958bkoHrJnQB0pHGSYu3QWgpmfk7ih/TB3WGa+vOyi2lTtIUVmlE9dXW3JnXzhZ6QF+20sDcaG8EsGezmZdb6iXC35+cSA8jAiuRETGMLrH57nnnsOqVasQERGBwYMHY/ny5dBqtU1aeWVlJfLz85GcnHyzIKkUycnJyMvLMzhP7969kZ+fL54OO3bsGNavX4+hQ4c2qQZr0hpPlbQkV4UD2no4I8LHFVFBKkT6toG3q6LRvSjuznL4/T0isr9KCdXfozlH+Ljqtbv1GqBwH9d6g1WXQLda8wGhtYKDu7P+wdynjaJRdVqCs9zBpKHHmOwd7OkMVwWHGCOiltGk4FNYWIgdO3agc+fOePbZZxEQEICJEyeioKDAqGWdP38e1dXV8PPz05vu5+eH4mLDp3geeughzJgxA3379oWjoyPatWuHAQMG1HuqS6vVQqPR6L2sCcd/sX6ttceMiMgeNfkanx49euCDDz7AmTNnkJWVhU8++QQ9e/ZETEwMFi5c2GKnbbZs2YI333wTH330EQoKCrBq1SqsW7cOM2fONNg+OzsbKpVKfAUHN+4aDqL6mC4HMVEREZlbk/uTr1+/jtWrV2PRokXYtGkTevXqhXHjxuGvv/7Cyy+/jB9++AFLly5tcBne3t6QyWQoKSnRm15SUgJ/f8MPLHz11Vfx6KOP4oknngAAdOvWDRUVFXjyySfxyiuvQCrVz3KZmZnIyMgQ32s0GqsNP+z7sU6N6fFpqaDfWrDXjIishdHBp6CgAIsWLcKyZcsglUqRmpqKf//73+jUqZPYZuTIkejZs2cDS6khl8sRFxeH3NxcjBgxAgCg0+mQm5uLiRMnGpznypUrdcKNTFZzvYWhg49CoYBCYb3XUtTWUsdOHnRaHnMPEZFtMDr49OzZE4MHD8bcuXMxYsQIODo61mkTHh6OMWPGNGp5GRkZSEtLQ3x8PBISEjBnzhxUVFSId3mlpqYiKCgI2dnZAIDhw4dj9uzZiI2NRWJiIo4ePYpXX30Vw4cPFwOQLREE4Kz6Ku758BdcrawWp+f8eNRk69h32rqua7J1hoJkfbmnoTzEQEpEZH5GB59jx44hNLTh8UpcXFywaNGiRi1v9OjROHfuHKZNm4bi4mLExMRgw4YN4gXPRUVFej08U6dOhUQiwdSpU3H69Gn4+Phg+PDheOONN4zdFKuRlL25zrR3Nh62QCVkSFKEl957Q3mlc0DN3VyBKidxWkpXfxwpLa93uTHB7qYoT9Q30gu7T12GUyNu5Tc3Ca9nIiIrYXTwKS0tRXFxMRITE/Wmb9++HTKZDPHx8UYXMXHixHpPbW3ZskXvvYODA7KyspCVlWX0eqyRvZ8h6RXhid+OXdSb5iKXoaJW71dzuCkdoLlW1eT5B3T0wZP92tX7+XeT78D+Mxokd/YFAIR5u+D1EVH4/cRFzBwRhfs++rXOPD9k9MPOE5dwf4+2Ta7LkGfvbI8AlRP6dzDvoINERLbE6Lu6JkyYgFOn6o4UfPr0aUyYMMEkRZH9WP5kUp1p7z0YY/5C6vFwYijkDvX/b9I5wA33x7XVeyTDI71C8f6YWLgp654GBoBI3zYYkxByy1Phm0/pKMMjvULNPuhgo7DDh4ishNHB58CBA+jRo0ed6bGxsThw4IBJiiIyleb2qPF4TUTUuhgdfBQKRZ3bzwHg7NmzcHDgaKvG4t1AdVn7Rb984CYRke0yOvjcddddyMzMhFqtFqddvnwZL7/8MgYPHtzAnES2p7kZh+P71GBUJCJrYXQXzbvvvot+/fohNDQUsbGxAIDCwkL4+fnh888/N3mBRJbEzh0iotbF6OATFBSEPXv24IsvvsDu3bvh5OSE9PR0jB071uCYPnTTpYpKrCk8jUD3m7c8HzirbmAO+2TSTpJmLsvQbdjMQkREtqtJF+W4uLjgySefNHUtrV7szE11pi35rcgCldiPcB8X7PmrGeHSQMoJ8nCqO7EeIZ7O+PNcRdPX30oYs8+IiFpSk69GPnDgAIqKilBZWak3/Z577ml2UWS/Fj3WE5XVOpMtL+ehHpj2zT6cvHAFmUM7Gz1/7dyz9IlELPv9FKb9o0uj5581qjtm/u8AUpPCjF53a7BkXCJW7DyFqcMav8+IiFpSk0ZuHjlyJPbu3QuJRCJevHnjTpfqatMMPEeWFeTuhFAvZ/z65wWTLG/Fk73wad4JrN9b3GC7gZ18sXF/w22MEezpjEXpCU2ev/YdXL0jvdE70tuo+f3clPjwobrDP9iLvu290be9cfuMiKglGX1X1+TJkxEeHo7S0lI4Oztj//792Lp1K+Lj4+uMskzUFLwRioiIWorRPT55eXnYvHkzvL29IZVKIZVK0bdvX2RnZ2PSpEnYtWtXS9RJZiY1OhLfni0GGhMPrkxERBZm9OGturoabdq0AQB4e3vjzJkzAIDQ0FAcPswHa7YWEkhMeiu3rQ76x4drEhG1Lkb3+ERFRWH37t0IDw9HYmIi3n77bcjlcsyfPx8REREtUSNZgCVzio1mJCIisgFGB5+pU6eioqLm9twZM2bgH//4B+644w54eXlhxYoVJi+QLKMlskdjT3VZ0ykxhjAiotbF6OCTkpIi/jsyMhKHDh3CxYsX4eHhYbOnM8zhwBmNpUswikwqMelpHlv9athq3UREZJhR1/hcv34dDg4O2Ldvn950T09Php7bmPG//ZYuwSizH4xp9jIe6x3W4OeeLnIAQLcgFQDgvQei67RJ7xMGLxc5+nXwEaf5tlHgVSPG0mmK4dGB6Bzghp5hni26HiIiMi+jgo+joyNCQkJMPlZPTk4OwsLCoFQqkZiYiB07dtTbdsCAAZBIJHVew4YNM2lN9uZ49lC083ER33cOcGt2b8dr93QV/y0BINR6fsTx7KEoeLXmobbfPtsXx7OHYlRc2zrLyBreFTunJmNQJ19x2vaXB2Fc3/DmFXcb/xkbi/WT+sJR1gK3txERkcUY/Vv9lVdewcsvv4yLFy+apIAVK1YgIyMDWVlZKCgoQHR0NFJSUlBaWmqw/apVq3D27FnxtW/fPshkMjzwwAMmqaelWPvdQebusbt1fQ2t35i2psReTCKi1sfoa3w+/PBDHD16FIGBgQgNDYWLi4ve5wUFBUYtb/bs2Rg/fjzS09MBAPPmzcO6deuwcOFCTJkypU57T0/9Uw/Lly+Hs7Oz1QcfW8NjPhERtUZGB58RI0aYbOWVlZXIz89HZmamOE0qlSI5ORl5eXmNWsaCBQswZsyYOgHsBq1WC61WK77XaGzrIuPWQiJp3t1agjXd6kVERDbL6OCTlZVlspWfP38e1dXV8PPz05vu5+eHQ4cO3Xb+HTt2YN++fViwYEG9bbKzszF9+vRm12oPakcLdvgQEVFrZNNXbi5YsADdunVDQkL9D6HMzMyEWq0WX6dOnTJjhTfx1BEREZHlGd3jI5VKG7zo05g7vry9vSGTyVBSUqI3vaSkBP7+/g3OW1FRgeXLl2PGjBkNtlMoFFAoFI2uyZQqq3SYvHyXTT6d+sbdciZcIniyioiILM3o4LN69Wq999evX8euXbvw6aefGn1KSS6XIy4uDrm5ueK1QzqdDrm5uZg4cWKD865cuRJarRaPPPKIUes0p68L/sJ3+4rx3b5i9G7nZelyzKq9r6vee2MyVGyIe51pN8bxaaM0+itLREQkMvoocu+999aZdv/996Nr165YsWIFxo0bZ9TyMjIykJaWhvj4eCQkJGDOnDmoqKgQ7/JKTU1FUFAQsrOz9eZbsGABRowYAS8v6w0UmqvXLV1Ck0lQ/3U+KidHqBvYti3/NwD+KmWT1+3npsSvU+6Ea62QE+Hjip9fHCgOekhERNQUJvvzuVevXnjyySeNnm/06NE4d+4cpk2bhuLiYsTExGDDhg3iBc9FRUWQSvUvRTp8+DC2bduG77//3iS1t5TWel1PoLtTg8EnzNvwHXbG3JgV6O5UZ1qwp3PjF0BERGSASYLP1atX8cEHHyAoKKhJ80+cOLHeU1tbtmypM61jx442d3uzrYUgU9drY5tPREStlNHB59aHkQqCgLKyMjg7O2PJkiUmLc7W1R6t2dpHbjYP2wqrRETU+hgdfP7973/rBR+pVAofHx8kJibCw8PDpMWR5TT4CAkz1kFERGRKRgefxx57rAXKaJ1s7fTWrUxZv0QiadbIzURERKZg9ACGixYtwsqVK+tMX7lyJT799FOTFNUabTt63tIl3F4LBhMbz4BERNRKGB18srOz4e1dd0A+X19fvPnmmyYpiqxDrwjDQwXc8feAjG0Uje8w9GmjQEK45+0bEhERtSCjT3UVFRUhPDy8zvTQ0FAUFRWZpKjWwrQjH5vfuL7hcFM6okeoO7Yfu4gL5VqM7NEWASolgj2dMbCTL/rM2tzgMpY/2Quaq9cR6O6Ex/uGw83JEUn1BCoiIqKWZnTw8fX1xZ49exAWFqY3fffu3VY9mKAl2HbsARxlUjyUGAIA6OTvpvfZI71CG7WM2r1GjjIpxiaEmK5AIiIiIxl9qmvs2LGYNGkSfvzxR1RXV6O6uhqbN2/G5MmTMWbMmJao0WbZeIcPERFRq2N0j8/MmTNx4sQJDBo0CA4ONbPrdDqkpqbyGh8iIiKyakYHH7lcjhUrVuD1119HYWEhnJyc0K1bN4SGNu7Uhz1hhw8REZF1afIjK9q3b4/27dubshayMA6zQ0RErZ3R1/iMGjUKb731Vp3pb7/9Nh544AGTFNVaVOlsK0qwh4qIiFo7o4PP1q1bMXTo0DrThwwZgq1bt5qkqNbi9XUHLV1Co7g7O1q6BCIiIrMw+lRXeXk55HJ5nemOjo7QaDQmKYrM68t/JgFo/qmuB+LaonckhzQgIiLrZXSPT7du3bBixYo605cvX44uXbqYpCgyrw5+bUyynHceiMbI2LYmWRYREVFLMDr4vPrqq5g5cybS0tLw6aef4tNPP0Vqaipef/11vPrqq00qIicnB2FhYVAqlUhMTMSOHTsabH/58mVMmDABAQEBUCgU6NChA9avX9+kdRMREZH9MPpU1/Dhw7FmzRq8+eab+Oqrr+Dk5ITo6Ghs3rwZnp7GP4tpxYoVyMjIwLx585CYmIg5c+YgJSUFhw8fhq+vb532lZWVGDx4MHx9ffHVV18hKCgIJ0+ehLu7u9HrJiIiIvvSpNvZhw0bhmHDhgEANBoNli1bhv/7v/9Dfn4+qqurjVrW7NmzMX78eKSnpwMA5s2bh3Xr1mHhwoWYMmVKnfYLFy7ExYsX8euvv8LRseai3Fsfn0FERERkiNGnum7YunUr0tLSEBgYiPfeew933nknfvvtN6OWUVlZifz8fCQnJ98sSCpFcnIy8vLyDM6zdu1aJCUlYcKECfDz80NUVBTefPPNegOXVquFRqPRe5FhgmBbt98TEREZy6gen+LiYixevBgLFiyARqPBgw8+CK1WizVr1jTpwubz58+juroafn5+etP9/Pxw6NAhg/McO3YMmzdvxsMPP4z169fj6NGjeOaZZ3D9+nVkZWXVaZ+dnY3p06cbXVtzVFXrUM0QQUREZHUa3eMzfPhwdOzYEXv27MGcOXNw5swZ/Oc//2nJ2gzS6XTw9fXF/PnzERcXh9GjR+OVV17BvHnzDLbPzMyEWq0WX6dOnWrR+s6XaxH5ynfoOHVDi66HiIiIjNfoHp/vvvsOkyZNwtNPP22yR1V4e3tDJpOhpKREb3pJSQn8/f0NzhMQEABHR0fIZDJxWufOnVFcXIzKyso6YwwpFAooFAqT1NsYy3cUmW1dTfFAXFuszP9LfN/e11X8t6QJj5Nf9FhPvPDVbrz7QLRJ6iMiImpJje7x2bZtG8rKyhAXF4fExER8+OGHOH/+fLNWLpfLERcXh9zcXHGaTqdDbm4ukpKSDM7Tp08fHD16FDqdTpz2xx9/ICAgwODAinTTI71C8E6tgPLS3Z2wKaO/+L4p1/gM7OSL319JxoCOde/AIyIisjaNDj69evXCxx9/jLNnz+Kf//wnli9fjsDAQOh0OmzatAllZWVNKiAjIwMff/wxPv30Uxw8eBBPP/00KioqxLu8UlNTkZmZKbZ/+umncfHiRUyePBl//PEH1q1bhzfffBMTJkxo0vrtieSWp3Hd2sHT1KuSmtJTREREZAlG39Xl4uKCxx9/HNu2bcPevXvxr3/9C7NmzYKvry/uueceowsYPXo03n33XUybNg0xMTEoLCzEhg0bxAuei4qKcPbsWbF9cHAwNm7ciN9//x3du3fHpEmTMHnyZIO3vpNxGF+IiKi1a9I4Pjd07NgRb7/9NrKzs/Htt99i4cKFTVrOxIkTMXHiRIOfbdmypc60pKQko2+dJyIiImryOD61yWQyjBgxAmvXrjXF4shCeMqKiIhaO5MEH2odOIAhERG1dgw+duzW/h3GHiIiau0YfEzs+PkrZluXk6Ps9o1quScmEADg5VJz2//ATvq3oHcNdDNNYURERFaqWRc3U12V1brbNzKRnVOTcaWyGj3f+EGc9vXTvTFq7q8AgOi2Knz4UA+or16Hi8IB4d4uAICfXxqIC+WVCPZ01luepwvHQSIiotaNwcfEzHl5sIvCAS6Kmz/CcG8XxIV6iO89XeQI9nRG8C3zOcsd4OzJHz0REdkfnuoyMUveGMV7soiIiBrG4ENERER2g8HHxCza68IuHyIiogYx+LQizc09tz7Li4iIqLVh8DGh0rJrWFN4xmLr58jLREREDWPwMaH0Rb9bZL3uzo4AgH7tffSm9wz3NGo50cHupiqJiIjIKvGeZhPaf0ZjkfWun3QHNh8qxf1xbQEAP70wAL8cvSC+b6z7YoNQrdPp3RJPRETUmjD42JgRMYF1TqcFujvhkV6h4vtQLxeEerkYvWypVILRPUOaXSMREZG14qkuG8PreIiIiJqOwYeIiIjshlUEn5ycHISFhUGpVCIxMRE7duyot+3ixYshkUj0Xkql0ozVEhERka2yePBZsWIFMjIykJWVhYKCAkRHRyMlJQWlpaX1zuPm5oazZ8+Kr5MnT5qxYiIiIrJVFg8+s2fPxvjx45Geno4uXbpg3rx5cHZ2xsKFC+udRyKRwN/fX3z5+fmZsWIiIiKyVRYNPpWVlcjPz0dycrI4TSqVIjk5GXl5efXOV15ejtDQUAQHB+Pee+/F/v37622r1Wqh0Wj0XrbM101h6RKIiIhslkWDz/nz51FdXV2nx8bPzw/FxcUG5+nYsSMWLlyIb775BkuWLIFOp0Pv3r3x119/GWyfnZ0NlUolvoKDg02+Heb0VL92GBETiP8+GmfpUoiIiGyOxU91GSspKQmpqamIiYlB//79sWrVKvj4+OC///2vwfaZmZlQq9Xi69SpU2au2LScFTLMGROLlK7+li6FiIjI5lh0AENvb2/IZDKUlJToTS8pKYG/f+MO7I6OjoiNjcXRo0cNfq5QKKBQtJ7TQ3yQKBERUdNZtMdHLpcjLi4Oubm54jSdTofc3FwkJSU1ahnV1dXYu3cvAgICWqpMq8LxC4mIiJrO4o+syMjIQFpaGuLj45GQkIA5c+agoqIC6enpAIDU1FQEBQUhOzsbADBjxgz06tULkZGRuHz5Mt555x2cPHkSTzzxhCU3w2yYe4iIiJrO4sFn9OjROHfuHKZNm4bi4mLExMRgw4YN4gXPRUVFkEpvdkxdunQJ48ePR3FxMTw8PBAXF4dff/0VXbp0sdQmmBUfWUFERNR0EkEQBEsXYU4ajQYqlQpqtRpubm4mXXbYlHUmXZ4hx94cCqmU4YeIiOyLqY7fNndXFxEREVFTMfiYUZC7k1Hto4PdkdxZf4wj9vYQERE1HYOPmbyQ0hG/TLnTqHnWPNMbn6TFi+8/SY1voDURERHdDoOPFeOFzERERKbF4ENERER2g8GHiIiI7AaDDxEREdkNBh8iIiKyGww+JnKxotLSJRAREdFtMPiYSJVOZ5LljIwNAgBMujPSJMsjIiKimyz+rC57UzhtMGJmbBLffzf5DjjKJPBxVeLq9Wr4tlFgwsB2aOfjasEqiYiIWicGHzNzd5brve8ccPN5Iyo4AgAifduYtSYiIiJ7wVNdJiIBBxskIiKydgw+REREZDcYfIiIiMhuWEXwycnJQVhYGJRKJRITE7Fjx45Gzbd8+XJIJBKMGDGiZQtsBD5Wi4iIyPpZPPisWLECGRkZyMrKQkFBAaKjo5GSkoLS0tIG5ztx4gT+7//+D3fccYeZKiUiIiJbZ/HgM3v2bIwfPx7p6eno0qUL5s2bB2dnZyxcuLDeeaqrq/Hwww9j+vTpiIiIMGO1REREZMssGnwqKyuRn5+P5ORkcZpUKkVycjLy8vLqnW/GjBnw9fXFuHHjbrsOrVYLjUaj92oJxpzp+t+zfdEjxB1bXxjYIrUQERGRYRYdx+f8+fOorq6Gn5+f3nQ/Pz8cOnTI4Dzbtm3DggULUFhY2Kh1ZGdnY/r06c0t1aSiglRY9UwfS5dBRERkdyx+qssYZWVlePTRR/Hxxx/D29u7UfNkZmZCrVaLr1OnTrVIbZLbXN0sCEKLrJeIiIgaz6I9Pt7e3pDJZCgpKdGbXlJSAn9//zrt//zzT5w4cQLDhw8Xp+n+fkaWg4MDDh8+jHbt2unNo1AooFAoWqB6IiIisjUW7fGRy+WIi4tDbm6uOE2n0yE3NxdJSUl12nfq1Al79+5FYWGh+LrnnnswcOBAFBYWIjg42JzlExERkY2x+LO6MjIykJaWhvj4eCQkJGDOnDmoqKhAeno6ACA1NRVBQUHIzs6GUqlEVFSU3vzu7u4AUGe6uXEYHyIiIutn8eAzevRonDt3DtOmTUNxcTFiYmKwYcMG8YLnoqIiSKU2dSkSERERWSmLBx8AmDhxIiZOnGjwsy1btjQ47+LFi01fUAvwcJHfvtFtuCqt4sdFRERks3gkNZHbPbLiwfimX380896uOFJajsRwzyYvg4iIiBh8WlRcqAfyT14CADjKmn667tGkMBNVREREZN948QwRERHZDQYfE5Hwvi4iIiKrx+BDREREdoPBh4iIiOwGg4+p8EwXERGR1WPwaUGy293jTkRERGbF4NNCwryc8cbIKPi0UWDGvV0tXQ4RERGB4/iYzK2dOw8nhqK9XxvseHkQJOz5ISIisgrs8WlhDD1ERETWg8GHiIiI7AaDj4mwX4eIiMj6MfgQERGR3WDwISIiIrthFcEnJycHYWFhUCqVSExMxI4dO+ptu2rVKsTHx8Pd3R0uLi6IiYnB559/bsZqDeNFzERERNbP4sFnxYoVyMjIQFZWFgoKChAdHY2UlBSUlpYabO/p6YlXXnkFeXl52LNnD9LT05Geno6NGzeaufKGDejoY+kSiIiI6BYSQRAESxaQmJiInj174sMPPwQA6HQ6BAcH49lnn8WUKVMatYwePXpg2LBhmDlz5m3bajQaqFQqqNVquLm5Nav22sq1VYjKqglfn49LwB3tGXyIiIhMxVTHb4v2+FRWViI/Px/JycniNKlUiuTkZOTl5d12fkEQkJubi8OHD6Nfv34tWept1T7R1dbD2WJ1EBERUf0sOnLz+fPnUV1dDT8/P73pfn5+OHToUL3zqdVqBAUFQavVQiaT4aOPPsLgwYMNttVqtdBqteJ7jUZjmuIbwKt9iIiIrJNNPrKiTZs2KCwsRHl5OXJzc5GRkYGIiAgMGDCgTtvs7GxMnz7d/EUSERGR1bFo8PH29oZMJkNJSYne9JKSEvj7+9c7n1QqRWRkJAAgJiYGBw8eRHZ2tsHgk5mZiYyMDPG9RqNBcHCwaTagFt7URUREZP0seo2PXC5HXFwccnNzxWk6nQ65ublISkpq9HJ0Op3e6azaFAoF3Nzc9F5ERERknyx+qisjIwNpaWmIj49HQkIC5syZg4qKCqSnpwMAUlNTERQUhOzsbAA1p67i4+PRrl07aLVarF+/Hp9//jnmzp1ryc0gIiIiG2Dx4DN69GicO3cO06ZNQ3FxMWJiYrBhwwbxgueioiJIpTc7pioqKvDMM8/gr7/+gpOTEzp16oQlS5Zg9OjRltoEAICElzQTERFZPYuP42NuLTWOz9XKanSetgEA8NMLAxDq5WKyZRMREdm7VjGODxEREZE5MfiYCO/qIiIisn4MPkRERGQ3GHyIiIjIbjD4EBERkd1g8GkBvLWdiIjIOjH4EBERkd1g8CEiIiK7weBDREREdoPBh4iIiOwGgw8RERHZDQafFsBRnImIiKwTgw8RERHZDQYfIiIishsMPkRERGQ3HCxdQGuhcJCiXwcfXK2sQlsPJ0uXQ0RERAZYRY9PTk4OwsLCoFQqkZiYiB07dtTb9uOPP8Ydd9wBDw8PeHh4IDk5ucH25iKRSPBpek98+c8kSHh1MxERkVWyePBZsWIFMjIykJWVhYKCAkRHRyMlJQWlpaUG22/ZsgVjx47Fjz/+iLy8PAQHB+Ouu+7C6dOnzVx5XRKJhKGHiIjIikkEQRAsWUBiYiJ69uyJDz/8EACg0+kQHByMZ599FlOmTLnt/NXV1fDw8MCHH36I1NTU27bXaDRQqVRQq9Vwc3Nrdv1ERETU8kx1/LZoj09lZSXy8/ORnJwsTpNKpUhOTkZeXl6jlnHlyhVcv34dnp6eBj/XarXQaDR6LyIiIrJPFg0+58+fR3V1Nfz8/PSm+/n5obi4uFHLeOmllxAYGKgXnmrLzs6GSqUSX8HBwc2um4iIiGyTxa/xaY5Zs2Zh+fLlWL16NZRKpcE2mZmZUKvV4uvUqVNmrpKIiIishUVvZ/f29oZMJkNJSYne9JKSEvj7+zc477vvvotZs2bhhx9+QPfu3ettp1AooFAoTFIvERER2TaL9vjI5XLExcUhNzdXnKbT6ZCbm4ukpKR653v77bcxc+ZMbNiwAfHx8eYolYiIiFoBiw9gmJGRgbS0NMTHxyMhIQFz5sxBRUUF0tPTAQCpqakICgpCdnY2AOCtt97CtGnTsHTpUoSFhYnXArm6usLV1dVi20FERETWz+LBZ/To0Th37hymTZuG4uJixMTEYMOGDeIFz0VFRZBKb3ZMzZ07F5WVlbj//vv1lpOVlYXXXnvNnKUTERGRjbH4OD7mxnF8iIiIbE+rGMeHiIiIyJwYfIiIiMhuMPgQERGR3WDwISIiIrvB4ENERER2g8GHiIiI7AaDDxEREdkNBh8iIiKyGww+REREZDcYfIiIiMhuMPgQERGR3WDwISIiIrvB4ENERER2g8GHiIiI7AaDDxEREdkNqwg+OTk5CAsLg1KpRGJiInbs2FFv2/3792PUqFEICwuDRCLBnDlzzFcoERER2TSLB58VK1YgIyMDWVlZKCgoQHR0NFJSUlBaWmqw/ZUrVxAREYFZs2bB39/fzNUSERGRLbN48Jk9ezbGjx+P9PR0dOnSBfPmzYOzszMWLlxosH3Pnj3xzjvvYMyYMVAoFGauloiIiGyZRYNPZWUl8vPzkZycLE6TSqVITk5GXl6eSdah1Wqh0Wj0XkRERGSfLBp8zp8/j+rqavj5+elN9/PzQ3FxsUnWkZ2dDZVKJb6Cg4NNslwiIiKyPRY/1dXSMjMzoVarxdepU6csXRIRERFZiIMlV+7t7Q2ZTIaSkhK96SUlJSa7cFmhUPBaICIiIgJg4R4fuVyOuLg45ObmitN0Oh1yc3ORlJRkwcqIiIioNbJojw8AZGRkIC0tDfHx8UhISMCcOXNQUVGB9PR0AEBqaiqCgoKQnZ0NoOaC6AMHDoj/Pn36NAoLC+Hq6orIyEiLbQcRERFZP4sHn9GjR+PcuXOYNm0aiouLERMTgw0bNogXPBcVFUEqvdkxdebMGcTGxorv3333Xbz77rvo378/tmzZYu7yiYiIyIZIBEEQLF2EOWk0GqhUKqjVari5uVm6HCIiImoEUx2/W/1dXUREREQ3MPgQERGR3WDwISIiIrvB4ENERER2g8GHiIiI7AaDDxEREdkNBh8iIiKyGww+REREZDcYfIiIiMhuMPgQERGR3WDwISIiIrvB4ENERER2g8GHiIiI7AaDDxEREdkNBh8iIiKyGww+REREZDesIvjk5OQgLCwMSqUSiYmJ2LFjR4PtV65ciU6dOkGpVKJbt25Yv369mSolIiIiW2bx4LNixQpkZGQgKysLBQUFiI6ORkpKCkpLSw22//XXXzF27FiMGzcOu3btwogRIzBixAjs27fPzJUTERGRrZEIgiBYsoDExET07NkTH374IQBAp9MhODgYzz77LKZMmVKn/ejRo1FRUYH//e9/4rRevXohJiYG8+bNu+36NBoNVCoV1Go13NzcTLchRERE1GJMdfx2MGFNRqusrER+fj4yMzPFaVKpFMnJycjLyzM4T15eHjIyMvSmpaSkYM2aNQbba7VaaLVa8b1arQZQswOJiIjINtw4bje3v8aiwef8+fOorq6Gn5+f3nQ/Pz8cOnTI4DzFxcUG2xcXFxtsn52djenTp9eZHhwc3MSqiYiIyFLKysqgUqmaPL9Fg485ZGZm6vUQ6XQ6XLx4EV5eXpBIJCZdl0ajQXBwME6dOsXTaI3EfWY87rOm4X4zHveZ8bjPjNfYfSYIAsrKyhAYGNis9Vk0+Hh7e0Mmk6GkpERveklJCfz9/Q3O4+/vb1R7hUIBhUKhN83d3b3pRTeCm5sbv/BG4j4zHvdZ03C/GY/7zHjcZ8ZrzD5rTk/PDRa9q0sulyMuLg65ubniNJ1Oh9zcXCQlJRmcJykpSa89AGzatKne9kREREQ3WPxUV0ZGBtLS0hAfH4+EhATMmTMHFRUVSE9PBwCkpqYiKCgI2dnZAIDJkyejf//+eO+99zBs2DAsX74cO3fuxPz58y25GURERGQDLB58Ro8ejXPnzmHatGkoLi5GTEwMNmzYIF7AXFRUBKn0ZsdU7969sXTpUkydOhUvv/wy2rdvjzVr1iAqKspSmyBSKBTIysqqc2qN6sd9Zjzus6bhfjMe95nxuM+MZ+59ZvFxfIiIiIjMxeIjNxMRERGZC4MPERER2Q0GHyIiIrIbDD5ERERkNxh8TCQnJwdhYWFQKpVITEzEjh07LF2S2WzduhXDhw9HYGAgJBJJneemCYKAadOmISAgAE5OTkhOTsaRI0f02ly8eBEPP/ww3Nzc4O7ujnHjxqG8vFyvzZ49e3DHHXdAqVQiODgYb7/9dktvWovJzs5Gz5490aZNG/j6+mLEiBE4fPiwXptr165hwoQJ8PLygqurK0aNGlVn8M6ioiIMGzYMzs7O8PX1xQsvvICqqiq9Nlu2bEGPHj2gUCgQGRmJxYsXt/TmtYi5c+eie/fu4iBnSUlJ+O6778TPub9ub9asWZBIJHjuuefEadxvdb322muQSCR6r06dOomfc58Zdvr0aTzyyCPw8vKCk5MTunXrhp07d4qfW82xQKBmW758uSCXy4WFCxcK+/fvF8aPHy+4u7sLJSUlli7NLNavXy+88sorwqpVqwQAwurVq/U+nzVrlqBSqYQ1a9YIu3fvFu655x4hPDxcuHr1qtjm7rvvFqKjo4XffvtN+Pnnn4XIyEhh7Nix4udqtVrw8/MTHn74YWHfvn3CsmXLBCcnJ+G///2vuTbTpFJSUoRFixYJ+/btEwoLC4WhQ4cKISEhQnl5udjmqaeeEoKDg4Xc3Fxh586dQq9evYTevXuLn1dVVQlRUVFCcnKysGvXLmH9+vWCt7e3kJmZKbY5duyY4OzsLGRkZAgHDhwQ/vOf/wgymUzYsGGDWbfXFNauXSusW7dO+OOPP4TDhw8LL7/8suDo6Cjs27dPEATur9vZsWOHEBYWJnTv3l2YPHmyOJ37ra6srCyha9euwtmzZ8XXuXPnxM+5z+q6ePGiEBoaKjz22GPC9u3bhWPHjgkbN24Ujh49KraxlmMBg48JJCQkCBMmTBDfV1dXC4GBgUJ2drYFq7KMW4OPTqcT/P39hXfeeUecdvnyZUGhUAjLli0TBEEQDhw4IAAQfv/9d7HNd999J0gkEuH06dOCIAjCRx99JHh4eAharVZs89JLLwkdO3Zs4S0yj9LSUgGA8NNPPwmCULOPHB0dhZUrV4ptDh48KAAQ8vLyBEGoCZxSqVQoLi4W28ydO1dwc3MT99OLL74odO3aVW9do0ePFlJSUlp6k8zCw8ND+OSTT7i/bqOsrExo3769sGnTJqF///5i8OF+MywrK0uIjo42+Bn3mWEvvfSS0Ldv33o/t6ZjAU91NVNlZSXy8/ORnJwsTpNKpUhOTkZeXp4FK7MOx48fR3Fxsd7+UalUSExMFPdPXl4e3N3dER8fL7ZJTk6GVCrF9u3bxTb9+vWDXC4X26SkpODw4cO4dOmSmbam5ajVagCAp6cnACA/Px/Xr1/X22+dOnVCSEiI3n7r1q2bONgnULNPNBoN9u/fL7apvYwbbWz9u1ldXY3ly5ejoqICSUlJ3F+3MWHCBAwbNqzOtnG/1e/IkSMIDAxEREQEHn74YRQVFQHgPqvP2rVrER8fjwceeAC+vr6IjY3Fxx9/LH5uTccCBp9mOn/+PKqrq/W+4ADg5+eH4uJiC1VlPW7sg4b2T3FxMXx9ffU+d3BwgKenp14bQ8uovQ5bpdPp8Nxzz6FPnz7iCOTFxcWQy+V1Hqh763673T6pr41Go8HVq1dbYnNa1N69e+Hq6gqFQoGnnnoKq1evRpcuXbi/GrB8+XIUFBSIj/2pjfvNsMTERCxevBgbNmzA3Llzcfz4cdxxxx0oKyvjPqvHsWPHMHfuXLRv3x4bN27E008/jUmTJuHTTz8FYF3HAos/soLI3k2YMAH79u3Dtm3bLF2K1evYsSMKCwuhVqvx1VdfIS0tDT/99JOly7Jap06dwuTJk7Fp0yYolUpLl2MzhgwZIv67e/fuSExMRGhoKL788ks4OTlZsDLrpdPpEB8fjzfffBMAEBsbi3379mHevHlIS0uzcHX62OPTTN7e3pDJZHWu6C8pKYG/v7+FqrIeN/ZBQ/vH398fpaWlep9XVVXh4sWLem0MLaP2OmzRxIkT8b///Q8//vgj2rZtK0739/dHZWUlLl++rNf+1v12u31SXxs3Nzeb/AUul8sRGRmJuLg4ZGdnIzo6Gu+//z73Vz3y8/NRWlqKHj16wMHBAQ4ODvjpp5/wwQcfwMHBAX5+ftxvjeDu7o4OHTrg6NGj/K7VIyAgAF26dNGb1rlzZ/EUoTUdCxh8mkkulyMuLg65ubniNJ1Oh9zcXCQlJVmwMusQHh4Of39/vf2j0Wiwfft2cf8kJSXh8uXLyM/PF9ts3rwZOp0OiYmJYputW7fi+vXrYptNmzahY8eO8PDwMNPWmI4gCJg4cSJWr16NzZs3Izw8XO/zuLg4ODo66u23w4cPo6ioSG+/7d27V+8XxaZNm+Dm5ib+AkpKStJbxo02reW7qdPpoNVqub/qMWjQIOzduxeFhYXiKz4+Hg8//LD4b+632ysvL8eff/6JgIAAftfq0adPnzpDcvzxxx8IDQ0FYGXHgkZfBk31Wr58uaBQKITFixcLBw4cEJ588knB3d1d74r+1qysrEzYtWuXsGvXLgGAMHv2bGHXrl3CyZMnBUGouYXR3d1d+Oabb4Q9e/YI9957r8FbGGNjY4Xt27cL27ZtE9q3b693C+Ply5cFPz8/4dFHHxX27dsnLF++XHB2drbZ29mffvppQaVSCVu2bNG7ZfbKlStim6eeekoICQkRNm/eLOzcuVNISkoSkpKSxM9v3DJ71113CYWFhcKGDRsEHx8fg7fMvvDCC8LBgweFnJwcm71ldsqUKcJPP/0kHD9+XNizZ48wZcoUQSKRCN9//70gCNxfjVX7ri5B4H4z5F//+pewZcsW4fjx48Ivv/wiJCcnC97e3kJpaakgCNxnhuzYsUNwcHAQ3njjDeHIkSPCF198ITg7OwtLliwR21jLsYDBx0T+85//CCEhIYJcLhcSEhKE3377zdIlmc2PP/4oAKjzSktLEwSh5jbGV199VfDz8xMUCoUwaNAg4fDhw3rLuHDhgjB27FjB1dVVcHNzE9LT04WysjK9Nrt37xb69u0rKBQKISgoSJg1a5a5NtHkDO0vAMKiRYvENlevXhWeeeYZwcPDQ3B2dhZGjhwpnD17Vm85J06cEIYMGSI4OTkJ3t7ewr/+9S/h+vXrem1+/PFHISYmRpDL5UJERITeOmzJ448/LoSGhgpyuVzw8fERBg0aJIYeQeD+aqxbgw/3W12jR48WAgICBLlcLgQFBQmjR4/WG4+G+8ywb7/9VoiKihIUCoXQqVMnYf78+XqfW8uxQCIIgtDoviwiIiIiG8ZrfIiIiMhuMPgQERGR3WDwISIiIrvB4ENERER2g8GHiIiI7AaDDxEREdkNBh8iIiKyGww+REREZDcYfIjIapw7dw5PP/00QkJCoFAo4O/vj5SUFPzyyy8AAIlEgjVr1li2SCKyaQ6WLoCI6IZRo0ahsrISn376KSIiIlBSUoLc3FxcuHDB0qURUSvBHh8isgqXL1/Gzz//jLfeegsDBw5EaGgoEhISkJmZiXvuuQdhYWEAgJEjR0IikYjvAeCbb75Bjx49oFQqERERgenTp6Oqqkr8XCKRYO7cuRgyZAicnJwQERGBr776Svy8srISEydOREBAAJRKJUJDQ5GdnW2uTSciM2LwISKr4OrqCldXV6xZswZarbbO57///jsAYNGiRTh79qz4/ueff0ZqaiomT56MAwcO4L///S8WL16MN954Q2/+V199FaNGjcLu3bvx8MMPY8yYMTh48CAA4IMPPsDatWvx5Zdf4vDhw/jiiy/0ghURtR58SCkRWY2vv/4a48ePx9WrV9GjRw/0798fY8aMQffu3QHU9NysXr0aI0aMEOdJTk7GoEGDkJmZKU5bsmQJXnzxRZw5c0ac76mnnsLcuXPFNr169UKPHj3w0UcfYdKkSdi/fz9++OEHSCQS82wsEVkEe3yIyGqMGjUKZ86cwdq1a3H33Xdjy5Yt6NGjBxYvXlzvPLt378aMGTPEHiNXV1eMHz8eZ8+exZUrV8R2SUlJevMlJSWJPT6PPfYYCgsL0bFjR0yaNAnff/99i2wfEVkegw8RWRWlUonBgwfj1Vdfxa+//orHHnsMWVlZ9bYvLy/H9OnTUVhYKL727t2LI0eOQKlUNmqdPXr0wPHjxzFz5kxcvXoVDz74IO6//35TbRIRWREGHyKyal26dEFFRQUAwNHREdXV1Xqf9+jRA4cPH0ZkZGSdl1R681fcb7/9pjffb7/9hs6dO4vv3dzcMHr0aHz88cdYsWIFvv76a1y8eLEFt4yILIG3sxORVbhw4QIeeOABPP744+jevTvatGmDnTt34u2338a9994LAAgLC0Nubi769OkDhUIBDw8PTJs2Df/4xz8QEhKC+++/H1KpFLt378a+ffvw+uuvi8tfuXIl4uPj0bdvX3zxxRfYsWMHFixYAACYPXs2AgICEBsbC6lUipUrV8Lf3x/u7u6W2BVE1JIEIiIrcO3aNWHKlClCjx49BJVKJTg7OwsdO3YUpk6dKly5ckUQBEFYu3atEBkZKTg4OAihoaHivBs2bBB69+4tODk5CW5ubkJCQoIwf/588XMAQk5OjjB48GBBoVAIYWFhwooVK8TP58+fL8TExAguLi6Cm5ubMGjQIKGgoMBs205E5sO7uoio1TN0NxgR2Sde40NERER2g8GHiIiI7AYvbiaiVo9n9InoBvb4EBERkd1g8CEiIiK7weBDREREdoPBh4iIiOwGgw8RERHZDQYfIiIishsMPkRERGQ3GHyIiIjIbjD4EBERkd34fw/jSyU97CS/AAAAAElFTkSuQmCC","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# باز کردن فایل و خواندن داده‌ها\n","data = np.loadtxt('Optimized-Text-CNN-Nadamax.txt', delimiter=',')\n","\n","# استخراج ستون‌های مختلف\n","steps = data[:, 0]\n","# loss = data[:, 1]\n","acc = data[:, 2]\n","\n","# تعریف نمودار\n","fig, ax = plt.subplots()\n","\n","# رسم منحنی‌ها\n","# ax.plot(steps, loss, label='Loss')\n","ax.plot(steps, acc, label='Accuracy')\n","\n","\n","# تنظیمات محور y\n","ax.set_yticks(np.arange(0, 1.5, 0.1))\n","\n","# شطرنجی کردن پس زمینه نمودار\n","# ax.set_facecolor('white')\n","# hatch_pattern = '/\\\\\\\\'\n","# ax.patch.set_hatch(hatch_pattern*10)\n","\n","# تنظیمات نمودار\n","ax.set_xlabel('Steps')\n","ax.set_ylabel('Accuracy')\n","ax.legend()\n","\n","# نمایش نمودار\n","plt.show()\n","\n"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
